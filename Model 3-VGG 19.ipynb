{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input/\"]))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation,Add, ZeroPadding2D ,AveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers,regularizers\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"input/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_json(\"input/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "target_train=train['is_iceberg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=2,stratify = target_train, train_size=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X_input,Y_input,batch_size = 32):\n",
    "    data_aug = ImageDataGenerator(#featurewise_center=True,\n",
    "                             #featurewise_std_normalization=True,\n",
    "                             #zca_whitening=True,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range = 0.2,\n",
    "                             height_shift_range = 0.2,\n",
    "                             zoom_range = 0.2,\n",
    "                             data_format = 'channels_last',\n",
    "                             horizontal_flip = True,\n",
    "                             vertical_flip = True)#,fill_mode = 'constant',cval = 0)\n",
    "    data_aug_batches = data_aug.flow(X_input,Y_input,batch_size = batch_size)\n",
    "    return data_aug_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top=False,weights='imagenet',classes=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x1c7ce9999e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7ce999748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7ce9990f0>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1c7ce98b908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d4fe7a58>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d4fe7668>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1c7ce99e160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7ce986d68>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7ce98b9e8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d4ffa198>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1c7d4db9630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7ce9dbbe0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7ce9efe48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d4b89668>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1c7d500ee48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d503d630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d50a0e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x1c7d50bddd8>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x1c7d50b3278>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.layers#[14].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def vggmodel(input_shape,lr = 0.0001):\n",
    "    #First composite layer\n",
    "    base_model = VGG16(include_top=False,weights='imagenet',input_shape=input_shape,classes=1)\n",
    "    for layer in base_model.layers[:4]:\n",
    "        layer.trainable = False\n",
    "    X = base_model.output\n",
    "    X = GlobalMaxPooling2D()(X)\n",
    "    #Flatten layer\n",
    "    #X = Flatten()(X)\n",
    "    #First dense layer\n",
    "    #X = Dense(1024,activation= 'relu')(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    #X = Dropout(0.2)(X)\n",
    "    #Second dense layer\n",
    "    X = Dense(1024,activation= 'relu')(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(1024,activation= 'relu')(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    #X = Dense(256,activation= 'relu')(X)\n",
    "    #X = BatchNormalization()(X)\n",
    "    #X = Dropout(0.2)(X)\n",
    "    #Decision layer\n",
    "    X = Dense(1,activation = 'sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=base_model.inputs,outputs=X)\n",
    "    optimizer=Adam(lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #optimizer = SGD(lr, decay=0, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_callbacks(filepath = \".model_weights.hdf5\", patience=7):\n",
    "    #es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [msave]\n",
    "\n",
    "#callbacks = get_callbacks(filepath=file_path, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 75, 75, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 75, 75, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 37, 37, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 37, 37, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 37, 37, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 18, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 18, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 18, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 9, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 9, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 16,290,625\n",
      "Trainable params: 16,251,905\n",
      "Non-trainable params: 38,720\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Vggmodel=vggmodel(input_shape = (75,75,3),lr = 0.00001)\n",
    "def fitmodel(model,X_train,y_train,X_valid,y_valid,augment = False,epochs = 50,batch_size = 32,filepath = \".model_weights.hdf5\"):\n",
    "    if augment == False:\n",
    "        result = model.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,shuffle = True,\n",
    "                           validation_data=(X_valid, y_valid),callbacks=get_callbacks(filepath))\n",
    "    else:\n",
    "        result = model.fit_generator(data_augmentation(X_train,y_train,batch_size = batch_size),\n",
    "                                     steps_per_epoch = len(X_train_cv)/batch_size,epochs=epochs,verbose=1,shuffle = True,\n",
    "                                     validation_data=(X_valid, y_valid),callbacks=get_callbacks(filepath))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "41/40 [==============================] - 33s 808ms/step - loss: 0.6880 - acc: 0.5795 - val_loss: 0.5804 - val_acc: 0.7103\n",
      "Epoch 2/100\n",
      "41/40 [==============================] - 26s 629ms/step - loss: 0.5561 - acc: 0.7053 - val_loss: 0.4016 - val_acc: 0.8069\n",
      "Epoch 3/100\n",
      "41/40 [==============================] - 25s 622ms/step - loss: 0.4035 - acc: 0.8093 - val_loss: 0.4357 - val_acc: 0.7664\n",
      "Epoch 4/100\n",
      "41/40 [==============================] - 26s 628ms/step - loss: 0.3543 - acc: 0.8277 - val_loss: 0.2783 - val_acc: 0.8598\n",
      "Epoch 5/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.3117 - acc: 0.8604 - val_loss: 0.2976 - val_acc: 0.8536\n",
      "Epoch 6/100\n",
      "41/40 [==============================] - 26s 622ms/step - loss: 0.3248 - acc: 0.8377 - val_loss: 0.3078 - val_acc: 0.8536\n",
      "Epoch 7/100\n",
      "41/40 [==============================] - 26s 632ms/step - loss: 0.3012 - acc: 0.8589 - val_loss: 0.2761 - val_acc: 0.8785\n",
      "Epoch 8/100\n",
      "41/40 [==============================] - 26s 633ms/step - loss: 0.3004 - acc: 0.8582 - val_loss: 0.2620 - val_acc: 0.8660\n",
      "Epoch 9/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.2801 - acc: 0.8711 - val_loss: 0.2829 - val_acc: 0.8567\n",
      "Epoch 10/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.2633 - acc: 0.8848 - val_loss: 0.2778 - val_acc: 0.8660\n",
      "Epoch 11/100\n",
      "41/40 [==============================] - 26s 629ms/step - loss: 0.2690 - acc: 0.8856 - val_loss: 0.2637 - val_acc: 0.8692\n",
      "Epoch 12/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.2363 - acc: 0.9001 - val_loss: 0.2623 - val_acc: 0.8754\n",
      "Epoch 13/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.2468 - acc: 0.8856 - val_loss: 0.2633 - val_acc: 0.8847\n",
      "Epoch 14/100\n",
      "41/40 [==============================] - 26s 633ms/step - loss: 0.2304 - acc: 0.9016 - val_loss: 0.2603 - val_acc: 0.8847\n",
      "Epoch 15/100\n",
      "41/40 [==============================] - 26s 630ms/step - loss: 0.2364 - acc: 0.8932 - val_loss: 0.2872 - val_acc: 0.8474\n",
      "Epoch 16/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.2471 - acc: 0.8940 - val_loss: 0.2680 - val_acc: 0.8941\n",
      "Epoch 17/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.2503 - acc: 0.8822 - val_loss: 0.2850 - val_acc: 0.8692\n",
      "Epoch 18/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.2190 - acc: 0.9039 - val_loss: 0.3009 - val_acc: 0.8941\n",
      "Epoch 19/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.2304 - acc: 0.8932 - val_loss: 0.2635 - val_acc: 0.8879\n",
      "Epoch 20/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.2035 - acc: 0.9115 - val_loss: 0.2783 - val_acc: 0.8910\n",
      "Epoch 21/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.2183 - acc: 0.9085 - val_loss: 0.2740 - val_acc: 0.8723\n",
      "Epoch 22/100\n",
      "41/40 [==============================] - 26s 633ms/step - loss: 0.2260 - acc: 0.9009 - val_loss: 0.2588 - val_acc: 0.8754\n",
      "Epoch 23/100\n",
      "41/40 [==============================] - 26s 636ms/step - loss: 0.2272 - acc: 0.9051 - val_loss: 0.2527 - val_acc: 0.8941\n",
      "Epoch 24/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1991 - acc: 0.9070 - val_loss: 0.2850 - val_acc: 0.8692\n",
      "Epoch 25/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1920 - acc: 0.9123 - val_loss: 0.2660 - val_acc: 0.8972\n",
      "Epoch 26/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1991 - acc: 0.9138 - val_loss: 0.2704 - val_acc: 0.9034\n",
      "Epoch 27/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1958 - acc: 0.9123 - val_loss: 0.2663 - val_acc: 0.9003\n",
      "Epoch 28/100\n",
      "41/40 [==============================] - 26s 641ms/step - loss: 0.2100 - acc: 0.9154 - val_loss: 0.2625 - val_acc: 0.9003\n",
      "Epoch 29/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.2057 - acc: 0.9169 - val_loss: 0.2761 - val_acc: 0.8785\n",
      "Epoch 30/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1813 - acc: 0.9268 - val_loss: 0.3114 - val_acc: 0.8723\n",
      "Epoch 31/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.2063 - acc: 0.9112 - val_loss: 0.2672 - val_acc: 0.8879\n",
      "Epoch 32/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1754 - acc: 0.9207 - val_loss: 0.2811 - val_acc: 0.8941\n",
      "Epoch 33/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1715 - acc: 0.9276 - val_loss: 0.2575 - val_acc: 0.8910\n",
      "Epoch 34/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1609 - acc: 0.9291 - val_loss: 0.2917 - val_acc: 0.8941\n",
      "Epoch 35/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1854 - acc: 0.9169 - val_loss: 0.3023 - val_acc: 0.8941\n",
      "Epoch 36/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1845 - acc: 0.9154 - val_loss: 0.2699 - val_acc: 0.8692\n",
      "Epoch 37/100\n",
      "41/40 [==============================] - 28s 673ms/step - loss: 0.1772 - acc: 0.9260 - val_loss: 0.2516 - val_acc: 0.9065\n",
      "Epoch 38/100\n",
      "41/40 [==============================] - 26s 627ms/step - loss: 0.1645 - acc: 0.9314 - val_loss: 0.2711 - val_acc: 0.9065\n",
      "Epoch 39/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1607 - acc: 0.9321 - val_loss: 0.2780 - val_acc: 0.8879\n",
      "Epoch 40/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1675 - acc: 0.9207 - val_loss: 0.2873 - val_acc: 0.9034\n",
      "Epoch 41/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1630 - acc: 0.9283 - val_loss: 0.2879 - val_acc: 0.8910\n",
      "Epoch 42/100\n",
      "41/40 [==============================] - 26s 627ms/step - loss: 0.1769 - acc: 0.9268 - val_loss: 0.2983 - val_acc: 0.8972\n",
      "Epoch 43/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1408 - acc: 0.9420 - val_loss: 0.3060 - val_acc: 0.9034\n",
      "Epoch 44/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1451 - acc: 0.9359 - val_loss: 0.3071 - val_acc: 0.9128\n",
      "Epoch 45/100\n",
      "41/40 [==============================] - 26s 627ms/step - loss: 0.1635 - acc: 0.9298 - val_loss: 0.3551 - val_acc: 0.8847\n",
      "Epoch 46/100\n",
      "41/40 [==============================] - 26s 637ms/step - loss: 0.1652 - acc: 0.9314 - val_loss: 0.3052 - val_acc: 0.9034\n",
      "Epoch 47/100\n",
      "41/40 [==============================] - 26s 633ms/step - loss: 0.1435 - acc: 0.9295 - val_loss: 0.3280 - val_acc: 0.8879\n",
      "Epoch 48/100\n",
      "41/40 [==============================] - 26s 630ms/step - loss: 0.1573 - acc: 0.9329 - val_loss: 0.3303 - val_acc: 0.9003\n",
      "Epoch 49/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1761 - acc: 0.9219 - val_loss: 0.3059 - val_acc: 0.8879\n",
      "Epoch 50/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1637 - acc: 0.9306 - val_loss: 0.2914 - val_acc: 0.8910\n",
      "Epoch 51/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1589 - acc: 0.9303 - val_loss: 0.3661 - val_acc: 0.8816\n",
      "Epoch 52/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1378 - acc: 0.9428 - val_loss: 0.3335 - val_acc: 0.9034\n",
      "Epoch 53/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1403 - acc: 0.9420 - val_loss: 0.3460 - val_acc: 0.8847\n",
      "Epoch 54/100\n",
      "41/40 [==============================] - 26s 627ms/step - loss: 0.1351 - acc: 0.9390 - val_loss: 0.3377 - val_acc: 0.9097\n",
      "Epoch 55/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1350 - acc: 0.9451 - val_loss: 0.3662 - val_acc: 0.8847\n",
      "Epoch 56/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1420 - acc: 0.9413 - val_loss: 0.3846 - val_acc: 0.8723\n",
      "Epoch 57/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1448 - acc: 0.9398 - val_loss: 0.3808 - val_acc: 0.8941\n",
      "Epoch 58/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1264 - acc: 0.9466 - val_loss: 0.3393 - val_acc: 0.9003\n",
      "Epoch 59/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1295 - acc: 0.9474 - val_loss: 0.3464 - val_acc: 0.8941\n",
      "Epoch 60/100\n",
      "41/40 [==============================] - 27s 665ms/step - loss: 0.1388 - acc: 0.9398 - val_loss: 0.3110 - val_acc: 0.9034\n",
      "Epoch 61/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1112 - acc: 0.9550 - val_loss: 0.3777 - val_acc: 0.8941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1210 - acc: 0.9466 - val_loss: 0.3316 - val_acc: 0.8910\n",
      "Epoch 63/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1663 - acc: 0.9303 - val_loss: 0.2970 - val_acc: 0.8847\n",
      "Epoch 64/100\n",
      "41/40 [==============================] - 25s 622ms/step - loss: 0.1453 - acc: 0.9348 - val_loss: 0.3391 - val_acc: 0.8847\n",
      "Epoch 65/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1411 - acc: 0.9443 - val_loss: 0.2988 - val_acc: 0.9034\n",
      "Epoch 66/100\n",
      "41/40 [==============================] - 26s 622ms/step - loss: 0.1303 - acc: 0.9481 - val_loss: 0.2865 - val_acc: 0.8972\n",
      "Epoch 67/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1076 - acc: 0.9573 - val_loss: 0.3104 - val_acc: 0.9128\n",
      "Epoch 68/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1150 - acc: 0.9542 - val_loss: 0.3659 - val_acc: 0.9003\n",
      "Epoch 69/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1331 - acc: 0.9474 - val_loss: 0.3057 - val_acc: 0.9034\n",
      "Epoch 70/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1141 - acc: 0.9504 - val_loss: 0.3448 - val_acc: 0.8754\n",
      "Epoch 71/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.1152 - acc: 0.9527 - val_loss: 0.3557 - val_acc: 0.8879\n",
      "Epoch 72/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1608 - acc: 0.9295 - val_loss: 0.3539 - val_acc: 0.8629\n",
      "Epoch 73/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1509 - acc: 0.9367 - val_loss: 0.3508 - val_acc: 0.8754\n",
      "Epoch 74/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1180 - acc: 0.9512 - val_loss: 0.3514 - val_acc: 0.8660\n",
      "Epoch 75/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1149 - acc: 0.9558 - val_loss: 0.3706 - val_acc: 0.8816\n",
      "Epoch 76/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1016 - acc: 0.9565 - val_loss: 0.3796 - val_acc: 0.9003\n",
      "Epoch 77/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1087 - acc: 0.9520 - val_loss: 0.3752 - val_acc: 0.8941\n",
      "Epoch 78/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1140 - acc: 0.9588 - val_loss: 0.3236 - val_acc: 0.8972\n",
      "Epoch 79/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1059 - acc: 0.9481 - val_loss: 0.3465 - val_acc: 0.8785\n",
      "Epoch 80/100\n",
      "41/40 [==============================] - 26s 629ms/step - loss: 0.0996 - acc: 0.9634 - val_loss: 0.3740 - val_acc: 0.8816\n",
      "Epoch 81/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.1177 - acc: 0.9478 - val_loss: 0.3755 - val_acc: 0.8879\n",
      "Epoch 82/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1122 - acc: 0.9542 - val_loss: 0.3615 - val_acc: 0.8972\n",
      "Epoch 83/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.1082 - acc: 0.9558 - val_loss: 0.3808 - val_acc: 0.8972\n",
      "Epoch 84/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.0844 - acc: 0.9657 - val_loss: 0.4174 - val_acc: 0.9065\n",
      "Epoch 85/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.1080 - acc: 0.9558 - val_loss: 0.3619 - val_acc: 0.9003\n",
      "Epoch 86/100\n",
      "41/40 [==============================] - 26s 628ms/step - loss: 0.0818 - acc: 0.9634 - val_loss: 0.4391 - val_acc: 0.8910\n",
      "Epoch 87/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.0936 - acc: 0.9573 - val_loss: 0.4903 - val_acc: 0.8816\n",
      "Epoch 88/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.0782 - acc: 0.9657 - val_loss: 0.3883 - val_acc: 0.9034\n",
      "Epoch 89/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.0877 - acc: 0.9672 - val_loss: 0.5175 - val_acc: 0.8847\n",
      "Epoch 90/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.0899 - acc: 0.9748 - val_loss: 0.4110 - val_acc: 0.8910\n",
      "Epoch 91/100\n",
      "41/40 [==============================] - 26s 628ms/step - loss: 0.0713 - acc: 0.9741 - val_loss: 0.4453 - val_acc: 0.8879\n",
      "Epoch 92/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.0948 - acc: 0.9611 - val_loss: 0.4369 - val_acc: 0.8910\n",
      "Epoch 93/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.0772 - acc: 0.9687 - val_loss: 0.3667 - val_acc: 0.8941\n",
      "Epoch 94/100\n",
      "41/40 [==============================] - 26s 624ms/step - loss: 0.0923 - acc: 0.9611 - val_loss: 0.4236 - val_acc: 0.8847\n",
      "Epoch 95/100\n",
      "41/40 [==============================] - 26s 626ms/step - loss: 0.0899 - acc: 0.9680 - val_loss: 0.4224 - val_acc: 0.9065\n",
      "Epoch 96/100\n",
      "41/40 [==============================] - 26s 625ms/step - loss: 0.0781 - acc: 0.9695 - val_loss: 0.4509 - val_acc: 0.9097\n",
      "Epoch 97/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.0804 - acc: 0.9649 - val_loss: 0.5041 - val_acc: 0.8785\n",
      "Epoch 98/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.0737 - acc: 0.9687 - val_loss: 0.4443 - val_acc: 0.9003\n",
      "Epoch 99/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.0862 - acc: 0.9664 - val_loss: 0.5793 - val_acc: 0.8723\n",
      "Epoch 100/100\n",
      "41/40 [==============================] - 26s 623ms/step - loss: 0.0720 - acc: 0.9680 - val_loss: 0.4415 - val_acc: 0.9034\n"
     ]
    }
   ],
   "source": [
    "result_Vgg = fitmodel(Vggmodel,X_train_cv,y_train_cv,X_valid,y_valid,augment = True,epochs = 100,batch_size = 32,filepath = 'model save/Model 3-VGG 19/first.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-10-0ba0fae71e6a>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-10-0ba0fae71e6a>\"\u001b[1;36m, line \u001b[1;32m11\u001b[0m\n\u001b[1;33m    from keras.optimizers import Adamï¼ŒSGD\u001b[0m\n\u001b[1;37m                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers\n",
    "from keras.optimizers import Adam\n",
    "from keras.optimizers import rmsprop\n",
    "from keras.layers.advanced_activations import LeakyReLU, PReLU\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train=train['is_iceberg']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "train['inc_angle']=pd.to_numeric(train['inc_angle'], errors='coerce')#We have only 133 NAs.\n",
    "train['inc_angle']=train['inc_angle'].fillna(method='pad')\n",
    "X_angle=train['inc_angle']\n",
    "test['inc_angle']=pd.to_numeric(test['inc_angle'], errors='coerce')\n",
    "X_test_angle=test['inc_angle']\n",
    "\n",
    "#Generate the training data\n",
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_band_3=(X_band_1+X_band_2)/2\n",
    "#X_band_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in train[\"inc_angle\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis]\n",
    "                          , X_band_2[:, :, :, np.newaxis]\n",
    "                         , X_band_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n",
    "\n",
    "\n",
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_band_test_3=(X_band_test_1+X_band_test_2)/2\n",
    "#X_band_test_3=np.array([np.full((75, 75), angel).astype(np.float32) for angel in test[\"inc_angle\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis]\n",
    "                          , X_band_test_2[:, :, :, np.newaxis]\n",
    "                         , X_band_test_3[:, :, :, np.newaxis]], axis=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batch_size=64\n",
    "# Define the image transformations here\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.,\n",
    "                         height_shift_range = 0.,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)\n",
    "\n",
    "# Here is the function that merges our two generators\n",
    "# We use the exact same generator with the same random seed for both the y and angle arrays\n",
    "def gen_flow_for_two_inputs(X1, X2, y):\n",
    "    genX1 = gen.flow(X1,y,  batch_size=batch_size)\n",
    "    genX2 = gen.flow(X1,X2, batch_size=batch_size)\n",
    "    while True:\n",
    "            X1i = genX1.next()\n",
    "            X2i = genX2.next()\n",
    "            #Assert arrays are equal - this was for peace of mind, but slows down training\n",
    "            #np.testing.assert_array_equal(X1i[0],X2i[0])\n",
    "            yield [X1i[0], X2i[1]], X1i[1]\n",
    "\n",
    "# Finally create generator\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=10, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]\n",
    "\n",
    "\n",
    "def getVggAngleModel():\n",
    "    input_2 = Input(shape=[1], name=\"angle\")\n",
    "    angle_layer = Dense(1, )(input_2)\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                 input_shape=X_train.shape[1:], classes=1)\n",
    "    x = base_model.get_layer('block5_pool').output\n",
    "    \n",
    "\n",
    "    x = GlobalMaxPooling2D()(x)\n",
    "    merge_one = concatenate([x, angle_layer])\n",
    "    merge_one = Dense(512, activation='relu', name='fc2')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    merge_one = Dense(512, activation='relu', name='fc3')(merge_one)\n",
    "    merge_one = Dropout(0.3)(merge_one)\n",
    "    \n",
    "    predictions = Dense(1, activation='sigmoid')(merge_one)\n",
    "    \n",
    "    model = Model(input=[base_model.input, input_2], output=predictions)\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "#Using K-fold Cross Validation with Data Augmentation.\n",
    "def myAngleCV(X_train, X_angle, X_test):\n",
    "    K=3\n",
    "    folds = list(StratifiedKFold(n_splits=K, shuffle=True).split(X_train, target_train))\n",
    "    y_test_pred_log = 0\n",
    "    y_train_pred_log=0\n",
    "    y_valid_pred_log = 0.0*target_train\n",
    "    for j, (train_idx, test_idx) in enumerate(folds):\n",
    "        print('\\n===================FOLD=',j)\n",
    "        X_train_cv = X_train[train_idx]\n",
    "        y_train_cv = target_train[train_idx]\n",
    "        X_holdout = X_train[test_idx]\n",
    "        Y_holdout= target_train[test_idx]\n",
    "        \n",
    "        #Angle\n",
    "        X_angle_cv=X_angle[train_idx]\n",
    "        X_angle_hold=X_angle[test_idx]\n",
    "\n",
    "        #define file path and get callbacks\n",
    "        file_path = \"%s_aug_model_weights.hdf5\"%j\n",
    "        callbacks = get_callbacks(filepath=file_path, patience=5)\n",
    "        gen_flow = gen_flow_for_two_inputs(X_train_cv, X_angle_cv, y_train_cv)\n",
    "        galaxyModel= getVggAngleModel()\n",
    "        galaxyModel.fit_generator(\n",
    "                gen_flow,\n",
    "                steps_per_epoch=24,\n",
    "                epochs=100,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data=([X_holdout,X_angle_hold], Y_holdout),\n",
    "                callbacks=callbacks)\n",
    "\n",
    "        #Getting the Best Model\n",
    "        galaxyModel.load_weights(filepath=file_path)\n",
    "        #Getting Training Score\n",
    "        score = galaxyModel.evaluate([X_train_cv,X_angle_cv], y_train_cv, verbose=0)\n",
    "        print('Train loss:', score[0])\n",
    "        print('Train accuracy:', score[1])\n",
    "        #Getting Test Score\n",
    "        score = galaxyModel.evaluate([X_holdout,X_angle_hold], Y_holdout, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "\n",
    "        #Getting validation Score.\n",
    "        pred_valid=galaxyModel.predict([X_holdout,X_angle_hold])\n",
    "        y_valid_pred_log[test_idx] = pred_valid.reshape(pred_valid.shape[0])\n",
    "\n",
    "        #Getting Test Scores\n",
    "        temp_test=galaxyModel.predict([X_test, X_test_angle])\n",
    "        y_test_pred_log+=temp_test.reshape(temp_test.shape[0])\n",
    "\n",
    "        #Getting Train Scores\n",
    "        temp_train=galaxyModel.predict([X_train, X_angle])\n",
    "        y_train_pred_log+=temp_train.reshape(temp_train.shape[0])\n",
    "\n",
    "    y_test_pred_log=y_test_pred_log/K\n",
    "    y_train_pred_log=y_train_pred_log/K\n",
    "\n",
    "    print('\\n Train Log Loss Validation= ',log_loss(target_train, y_train_pred_log))\n",
    "    print(' Test Log Loss Validation= ',log_loss(target_train, y_valid_pred_log))\n",
    "    return y_test_pred_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================FOLD= 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\ipykernel_launcher.py:48: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "24/24 [==============================] - 32s 1s/step - loss: 0.6953 - acc: 0.5833 - val_loss: 0.4926 - val_acc: 0.7495\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.5155 - acc: 0.7449 - val_loss: 0.3744 - val_acc: 0.8336\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.3888 - acc: 0.8194 - val_loss: 0.3639 - val_acc: 0.8430\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.3237 - acc: 0.8450 - val_loss: 0.2685 - val_acc: 0.8673\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.3022 - acc: 0.8698 - val_loss: 0.2496 - val_acc: 0.8860\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2476 - acc: 0.8973 - val_loss: 0.3560 - val_acc: 0.8168\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2658 - acc: 0.8857 - val_loss: 0.2267 - val_acc: 0.9065\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2364 - acc: 0.9013 - val_loss: 0.2282 - val_acc: 0.9047\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2382 - acc: 0.9020 - val_loss: 0.3160 - val_acc: 0.8449\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2346 - acc: 0.8958 - val_loss: 0.2820 - val_acc: 0.8654\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2306 - acc: 0.8989 - val_loss: 0.2318 - val_acc: 0.9084\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2253 - acc: 0.9010 - val_loss: 0.2941 - val_acc: 0.8748\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1938 - acc: 0.9184 - val_loss: 0.2277 - val_acc: 0.9065\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2057 - acc: 0.9123 - val_loss: 0.2440 - val_acc: 0.8860\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1971 - acc: 0.9173 - val_loss: 0.2543 - val_acc: 0.8860\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1815 - acc: 0.9239 - val_loss: 0.2425 - val_acc: 0.8991\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1830 - acc: 0.9202 - val_loss: 0.2433 - val_acc: 0.9215\n",
      "Train loss: 0.191277268392\n",
      "Train accuracy: 0.920486435977\n",
      "Test loss: 0.226746345625\n",
      "Test accuracy: 0.906542055295\n",
      "\n",
      "===================FOLD= 1\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 33s 1s/step - loss: 0.7420 - acc: 0.5786 - val_loss: 0.4296 - val_acc: 0.7533\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.4794 - acc: 0.7551 - val_loss: 0.3174 - val_acc: 0.8430\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 30s 1s/step - loss: 0.3393 - acc: 0.8402 - val_loss: 0.2835 - val_acc: 0.8785\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2822 - acc: 0.8667 - val_loss: 0.2645 - val_acc: 0.8879\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2914 - acc: 0.8724 - val_loss: 0.2177 - val_acc: 0.9028\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2624 - acc: 0.8994 - val_loss: 0.2534 - val_acc: 0.8879\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2494 - acc: 0.8962 - val_loss: 0.2460 - val_acc: 0.8935\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2442 - acc: 0.8953 - val_loss: 0.2444 - val_acc: 0.8897\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2104 - acc: 0.9114 - val_loss: 0.2217 - val_acc: 0.9028\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2072 - acc: 0.9134 - val_loss: 0.2195 - val_acc: 0.9028\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2023 - acc: 0.9234 - val_loss: 0.2049 - val_acc: 0.9121\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1942 - acc: 0.9176 - val_loss: 0.2156 - val_acc: 0.9047\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1907 - acc: 0.9278 - val_loss: 0.2116 - val_acc: 0.9009\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1940 - acc: 0.9208 - val_loss: 0.2098 - val_acc: 0.9103\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1828 - acc: 0.9278 - val_loss: 0.2122 - val_acc: 0.9084\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1811 - acc: 0.9337 - val_loss: 0.2065 - val_acc: 0.9103\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1822 - acc: 0.9240 - val_loss: 0.2098 - val_acc: 0.8953\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1593 - acc: 0.9386 - val_loss: 0.2295 - val_acc: 0.9084\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1644 - acc: 0.9369 - val_loss: 0.2043 - val_acc: 0.9121\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1574 - acc: 0.9377 - val_loss: 0.2098 - val_acc: 0.9028\n",
      "Epoch 21/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1457 - acc: 0.9461 - val_loss: 0.2362 - val_acc: 0.9047\n",
      "Epoch 22/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1465 - acc: 0.9435 - val_loss: 0.2690 - val_acc: 0.8953\n",
      "Epoch 23/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1453 - acc: 0.9395 - val_loss: 0.1991 - val_acc: 0.9103\n",
      "Epoch 24/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1205 - acc: 0.9541 - val_loss: 0.1905 - val_acc: 0.9103\n",
      "Epoch 25/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1236 - acc: 0.9498 - val_loss: 0.2218 - val_acc: 0.9103\n",
      "Epoch 26/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1369 - acc: 0.9531 - val_loss: 0.2603 - val_acc: 0.8897\n",
      "Epoch 27/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1346 - acc: 0.9455 - val_loss: 0.1952 - val_acc: 0.9103\n",
      "Epoch 28/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1131 - acc: 0.9539 - val_loss: 0.2873 - val_acc: 0.8953\n",
      "Epoch 29/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1262 - acc: 0.9526 - val_loss: 0.2304 - val_acc: 0.8991\n",
      "Epoch 30/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1333 - acc: 0.9422 - val_loss: 0.2704 - val_acc: 0.9009\n",
      "Epoch 31/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1111 - acc: 0.9552 - val_loss: 0.2433 - val_acc: 0.9159\n",
      "Epoch 32/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1064 - acc: 0.9527 - val_loss: 0.2664 - val_acc: 0.9084\n",
      "Epoch 33/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1063 - acc: 0.9633 - val_loss: 0.2843 - val_acc: 0.8972\n",
      "Epoch 34/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.0898 - acc: 0.9630 - val_loss: 0.2328 - val_acc: 0.9140\n",
      "Train loss: 0.0764470952402\n",
      "Train accuracy: 0.971936389149\n",
      "Test loss: 0.190533665073\n",
      "Test accuracy: 0.910280373498\n",
      "\n",
      "===================FOLD= 2\n",
      "Epoch 1/100\n",
      "24/24 [==============================] - 34s 1s/step - loss: 0.6442 - acc: 0.6121 - val_loss: 0.3414 - val_acc: 0.8371\n",
      "Epoch 2/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.4116 - acc: 0.7967 - val_loss: 0.3091 - val_acc: 0.8614\n",
      "Epoch 3/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2955 - acc: 0.8677 - val_loss: 0.2756 - val_acc: 0.8839\n",
      "Epoch 4/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2573 - acc: 0.8843 - val_loss: 0.3537 - val_acc: 0.8502\n",
      "Epoch 5/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2558 - acc: 0.8811 - val_loss: 0.3268 - val_acc: 0.8633\n",
      "Epoch 6/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2286 - acc: 0.8992 - val_loss: 0.2980 - val_acc: 0.8895\n",
      "Epoch 7/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2243 - acc: 0.9063 - val_loss: 0.3067 - val_acc: 0.8652\n",
      "Epoch 8/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2076 - acc: 0.9112 - val_loss: 0.2605 - val_acc: 0.9101\n",
      "Epoch 9/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.2108 - acc: 0.9109 - val_loss: 0.2778 - val_acc: 0.8876\n",
      "Epoch 10/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1868 - acc: 0.9220 - val_loss: 0.2465 - val_acc: 0.9082\n",
      "Epoch 11/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1913 - acc: 0.9203 - val_loss: 0.2766 - val_acc: 0.9026\n",
      "Epoch 12/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1814 - acc: 0.9213 - val_loss: 0.2627 - val_acc: 0.9082\n",
      "Epoch 13/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1596 - acc: 0.9313 - val_loss: 0.3071 - val_acc: 0.8970\n",
      "Epoch 14/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1720 - acc: 0.9267 - val_loss: 0.2607 - val_acc: 0.9101\n",
      "Epoch 15/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1782 - acc: 0.9283 - val_loss: 0.2563 - val_acc: 0.9026\n",
      "Epoch 16/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1720 - acc: 0.9340 - val_loss: 0.2516 - val_acc: 0.9120\n",
      "Epoch 17/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1547 - acc: 0.9409 - val_loss: 0.2480 - val_acc: 0.9082\n",
      "Epoch 18/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1553 - acc: 0.9323 - val_loss: 0.2714 - val_acc: 0.9120\n",
      "Epoch 19/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1529 - acc: 0.9277 - val_loss: 0.2778 - val_acc: 0.9045\n",
      "Epoch 20/100\n",
      "24/24 [==============================] - 29s 1s/step - loss: 0.1637 - acc: 0.9287 - val_loss: 0.2640 - val_acc: 0.9120\n",
      "Train loss: 0.151602413777\n",
      "Train accuracy: 0.937383177682\n",
      "Test loss: 0.246453694302\n",
      "Test accuracy: 0.908239700821\n",
      "\n",
      " Train Log Loss Validation=  0.145135322851\n",
      " Test Log Loss Validation=  0.221228850137\n"
     ]
    }
   ],
   "source": [
    "preds=myAngleCV(X_train, X_angle, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17434557,  0.33020672,  0.01869651, ...,  0.0418326 ,\n",
       "        0.9970749 ,  0.01072063], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_csv('sub.csv')\n",
    "submission = pd.DataFrame()\n",
    "submission['id']=p['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('sub1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
