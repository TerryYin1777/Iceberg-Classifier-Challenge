{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input/\"]))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation,Add, ZeroPadding2D ,AveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers,regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"input/train.json\")\n",
    "#test = pd.read_json(\"input/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "target_train=train['is_iceberg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis], X_band_test_2[:, :, :, np.newaxis], ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=2,stratify = target_train, train_size=0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X_input,Y_input,batch_size = 32):\n",
    "    data_aug = ImageDataGenerator(#featurewise_center=True,\n",
    "                             #featurewise_std_normalization=True,\n",
    "                             #zca_whitening=True,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range = 0,\n",
    "                             height_shift_range = 0,\n",
    "                             zoom_range = 0,\n",
    "                             data_format = 'channels_last',\n",
    "                             horizontal_flip = True,\n",
    "                             vertical_flip = True,fill_mode = 'constant',cval = 0)\n",
    "    data_aug_batches = data_aug.flow(X_input,Y_input,batch_size = batch_size)\n",
    "    return data_aug_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cbamd_layer(X_input,filter_num =64,kernel_size = (3,3),conv_padding = 'valid',pool_size =(2,2),pool_strides = (2,2),pool_padding = 'valid',dropout_rate = 0.2):\n",
    "    X = Conv2D(filter_num, kernel_size, padding = conv_padding)(X_input)\n",
    "    #X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size,strides = pool_strides,padding = pool_padding)(X)\n",
    "    X = Dropout(rate = dropout_rate)(X)\n",
    "    return X\n",
    "\n",
    "def dense_layer(X_input, units = 1,activation = 'relu',dropout_rate = 0.2):\n",
    "    X = Dense(units = units,activation = activation)(X_input)\n",
    "    X = Dropout(rate = dropout_rate)(X)\n",
    "    return X\n",
    "#kernel_regularizer=regularizers.l2(0.01)\n",
    "def cnnmodel(input_shape,lr = 0.0001):\n",
    "    X_input = Input(input_shape)\n",
    "    #First composite layer\n",
    "    X = basic_cbamd_layer(X_input,\n",
    "                           filter_num =64,\n",
    "                           kernel_size = (5,5),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(3,3),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Second composite layer\n",
    "    X = basic_cbamd_layer(X,\n",
    "                           filter_num =128,\n",
    "                           kernel_size = (3,3),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(3,3),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Third composite layer\n",
    "    X = basic_cbamd_layer(X,\n",
    "                           filter_num =128,\n",
    "                           kernel_size = (3,3),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(2,2),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Forth composite layer\n",
    "    X = basic_cbamd_layer(X,\n",
    "                           filter_num =64,\n",
    "                           kernel_size = (3,3),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(3,3),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Flatten layer\n",
    "    X = Flatten()(X)\n",
    "    #First dense layer\n",
    "    X = dense_layer(X, units = 256,activation = 'relu',dropout_rate = 0.2)\n",
    "    #Second dense layer\n",
    "    X = dense_layer(X, units = 128,activation = 'relu',dropout_rate = 0.2)\n",
    "    #Decision layer\n",
    "    X = dense_layer(X, units = 1,activation = 'sigmoid',dropout_rate = 0)\n",
    "    \n",
    "    model = Model(inputs=X_input,outputs=X)\n",
    "    otimizer=Adam(lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=otimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_callbacks(filepath = \".model_weights.hdf5\", patience=7):\n",
    "    #es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=False)\n",
    "    return [msave]\n",
    "\n",
    "#callbacks = get_callbacks(filepath=file_path, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Cnnmodel=cnnmodel(input_shape = (75,75,3),lr = 0.0001)\n",
    "def fitmodel(model,X_train,y_train,X_valid,y_valid,augment = False,epochs = 50,batch_size = 32,filepath = \".model_weights.hdf5\"):\n",
    "    if augment == False:\n",
    "        result = model.fit(X_train, y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=get_callbacks(filepath))\n",
    "    else:\n",
    "        result = model.fit_generator(data_augmentation(X_train,y_train,batch_size = batch_size),\n",
    "                          steps_per_epoch = len(X_train_cv)/batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=get_callbacks(filepath))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1604 samples, validate on 1604 samples\n",
      "Epoch 1/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.7463 - acc: 0.5355 - val_loss: 0.6867 - val_acc: 0.5611\n",
      "Epoch 2/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.7007 - acc: 0.5418 - val_loss: 0.6660 - val_acc: 0.6633\n",
      "Epoch 3/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.6593 - acc: 0.5717 - val_loss: 0.6125 - val_acc: 0.6739\n",
      "Epoch 4/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.5984 - acc: 0.6365 - val_loss: 0.5647 - val_acc: 0.6802\n",
      "Epoch 5/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.5771 - acc: 0.6471 - val_loss: 0.5454 - val_acc: 0.6939\n",
      "Epoch 6/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.5478 - acc: 0.6808 - val_loss: 0.5299 - val_acc: 0.7101\n",
      "Epoch 7/200\n",
      "1604/1604 [==============================] - 9s 5ms/step - loss: 0.5347 - acc: 0.6951 - val_loss: 0.5218 - val_acc: 0.7400\n",
      "Epoch 8/200\n",
      "1604/1604 [==============================] - 9s 5ms/step - loss: 0.5116 - acc: 0.7151 - val_loss: 0.4991 - val_acc: 0.7712\n",
      "Epoch 9/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4888 - acc: 0.7388 - val_loss: 0.4769 - val_acc: 0.7849\n",
      "Epoch 10/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4754 - acc: 0.7544 - val_loss: 0.4976 - val_acc: 0.7431\n",
      "Epoch 11/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4817 - acc: 0.7550 - val_loss: 0.4599 - val_acc: 0.8049\n",
      "Epoch 12/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4585 - acc: 0.7837 - val_loss: 0.4406 - val_acc: 0.8074\n",
      "Epoch 13/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4331 - acc: 0.7862 - val_loss: 0.3980 - val_acc: 0.8180\n",
      "Epoch 14/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4182 - acc: 0.7993 - val_loss: 0.3947 - val_acc: 0.8248\n",
      "Epoch 15/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.4021 - acc: 0.8111 - val_loss: 0.3718 - val_acc: 0.8298\n",
      "Epoch 16/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3934 - acc: 0.8167 - val_loss: 0.3937 - val_acc: 0.8248\n",
      "Epoch 17/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3944 - acc: 0.8117 - val_loss: 0.3568 - val_acc: 0.8479\n",
      "Epoch 18/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3648 - acc: 0.8329 - val_loss: 0.3593 - val_acc: 0.8385\n",
      "Epoch 19/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3584 - acc: 0.8329 - val_loss: 0.3181 - val_acc: 0.8522\n",
      "Epoch 20/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3516 - acc: 0.8354 - val_loss: 0.3169 - val_acc: 0.8647\n",
      "Epoch 21/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3491 - acc: 0.8441 - val_loss: 0.3246 - val_acc: 0.8410\n",
      "Epoch 22/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3441 - acc: 0.8404 - val_loss: 0.3257 - val_acc: 0.8416\n",
      "Epoch 23/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3404 - acc: 0.8460 - val_loss: 0.3068 - val_acc: 0.8510\n",
      "Epoch 24/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3362 - acc: 0.8435 - val_loss: 0.3222 - val_acc: 0.8448\n",
      "Epoch 25/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3207 - acc: 0.8541 - val_loss: 0.2799 - val_acc: 0.8747\n",
      "Epoch 26/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.3246 - acc: 0.8516 - val_loss: 0.3176 - val_acc: 0.8466\n",
      "Epoch 27/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2998 - acc: 0.8585 - val_loss: 0.2473 - val_acc: 0.8884\n",
      "Epoch 28/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2938 - acc: 0.8616 - val_loss: 0.2428 - val_acc: 0.8921\n",
      "Epoch 29/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2935 - acc: 0.8647 - val_loss: 0.2521 - val_acc: 0.8753\n",
      "Epoch 30/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2825 - acc: 0.8691 - val_loss: 0.2322 - val_acc: 0.8878\n",
      "Epoch 31/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2739 - acc: 0.8778 - val_loss: 0.2372 - val_acc: 0.8965\n",
      "Epoch 32/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2893 - acc: 0.8628 - val_loss: 0.2682 - val_acc: 0.8897\n",
      "Epoch 33/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2728 - acc: 0.8815 - val_loss: 0.2251 - val_acc: 0.8903\n",
      "Epoch 34/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2705 - acc: 0.8753 - val_loss: 0.2127 - val_acc: 0.9034\n",
      "Epoch 35/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2560 - acc: 0.8778 - val_loss: 0.2072 - val_acc: 0.9059\n",
      "Epoch 36/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2445 - acc: 0.8884 - val_loss: 0.2091 - val_acc: 0.9040\n",
      "Epoch 37/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2668 - acc: 0.8791 - val_loss: 0.2159 - val_acc: 0.9021\n",
      "Epoch 38/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2468 - acc: 0.8928 - val_loss: 0.2009 - val_acc: 0.9071\n",
      "Epoch 39/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2372 - acc: 0.8834 - val_loss: 0.1961 - val_acc: 0.9165\n",
      "Epoch 40/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2313 - acc: 0.8984 - val_loss: 0.2411 - val_acc: 0.8840\n",
      "Epoch 41/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2303 - acc: 0.8928 - val_loss: 0.1948 - val_acc: 0.9152\n",
      "Epoch 42/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2205 - acc: 0.9027 - val_loss: 0.1835 - val_acc: 0.9183\n",
      "Epoch 43/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2167 - acc: 0.8990 - val_loss: 0.1840 - val_acc: 0.9208\n",
      "Epoch 44/200\n",
      "1604/1604 [==============================] - 9s 6ms/step - loss: 0.2352 - acc: 0.8940 - val_loss: 0.2084 - val_acc: 0.9021\n",
      "Epoch 45/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2182 - acc: 0.9015 - val_loss: 0.1955 - val_acc: 0.9115\n",
      "Epoch 46/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2338 - acc: 0.8928 - val_loss: 0.1915 - val_acc: 0.9133\n",
      "Epoch 47/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2360 - acc: 0.8884 - val_loss: 0.1950 - val_acc: 0.9034\n",
      "Epoch 48/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2348 - acc: 0.8872 - val_loss: 0.1903 - val_acc: 0.9108\n",
      "Epoch 49/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2177 - acc: 0.9090 - val_loss: 0.2006 - val_acc: 0.9034\n",
      "Epoch 50/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2281 - acc: 0.8940 - val_loss: 0.2043 - val_acc: 0.9046\n",
      "Epoch 51/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2216 - acc: 0.8996 - val_loss: 0.2042 - val_acc: 0.8984\n",
      "Epoch 52/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2024 - acc: 0.9046 - val_loss: 0.1800 - val_acc: 0.9165\n",
      "Epoch 53/200\n",
      "1604/1604 [==============================] - 9s 5ms/step - loss: 0.2125 - acc: 0.9034 - val_loss: 0.1661 - val_acc: 0.9296\n",
      "Epoch 54/200\n",
      "1604/1604 [==============================] - 9s 6ms/step - loss: 0.1924 - acc: 0.9077 - val_loss: 0.1578 - val_acc: 0.9333\n",
      "Epoch 55/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2061 - acc: 0.9077 - val_loss: 0.1533 - val_acc: 0.9333\n",
      "Epoch 56/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1995 - acc: 0.9027 - val_loss: 0.2020 - val_acc: 0.8990\n",
      "Epoch 57/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.2033 - acc: 0.9115 - val_loss: 0.1565 - val_acc: 0.9339\n",
      "Epoch 58/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1960 - acc: 0.9090 - val_loss: 0.1541 - val_acc: 0.9364\n",
      "Epoch 59/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1885 - acc: 0.9121 - val_loss: 0.1539 - val_acc: 0.9320\n",
      "Epoch 60/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1818 - acc: 0.9258 - val_loss: 0.1473 - val_acc: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1941 - acc: 0.9077 - val_loss: 0.1802 - val_acc: 0.9146\n",
      "Epoch 62/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1973 - acc: 0.9146 - val_loss: 0.1469 - val_acc: 0.9426\n",
      "Epoch 63/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1857 - acc: 0.9152 - val_loss: 0.1390 - val_acc: 0.9401\n",
      "Epoch 64/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1997 - acc: 0.9127 - val_loss: 0.1445 - val_acc: 0.9408\n",
      "Epoch 65/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1755 - acc: 0.9264 - val_loss: 0.1466 - val_acc: 0.9358\n",
      "Epoch 66/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1654 - acc: 0.9183 - val_loss: 0.1283 - val_acc: 0.9439\n",
      "Epoch 67/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1782 - acc: 0.9171 - val_loss: 0.1594 - val_acc: 0.9289\n",
      "Epoch 68/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1848 - acc: 0.9196 - val_loss: 0.1445 - val_acc: 0.9327\n",
      "Epoch 69/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1848 - acc: 0.9121 - val_loss: 0.1395 - val_acc: 0.9401\n",
      "Epoch 70/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1738 - acc: 0.9271 - val_loss: 0.1276 - val_acc: 0.9514\n",
      "Epoch 71/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1767 - acc: 0.9246 - val_loss: 0.1403 - val_acc: 0.9408\n",
      "Epoch 72/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1649 - acc: 0.9308 - val_loss: 0.1329 - val_acc: 0.9420\n",
      "Epoch 73/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1727 - acc: 0.9258 - val_loss: 0.1387 - val_acc: 0.9439\n",
      "Epoch 74/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1705 - acc: 0.9252 - val_loss: 0.1562 - val_acc: 0.9314\n",
      "Epoch 75/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1644 - acc: 0.9296 - val_loss: 0.1467 - val_acc: 0.9302\n",
      "Epoch 76/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1554 - acc: 0.9308 - val_loss: 0.1214 - val_acc: 0.9532\n",
      "Epoch 77/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1512 - acc: 0.9345 - val_loss: 0.1126 - val_acc: 0.9501\n",
      "Epoch 78/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1655 - acc: 0.9252 - val_loss: 0.1102 - val_acc: 0.9545\n",
      "Epoch 79/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1692 - acc: 0.9289 - val_loss: 0.1223 - val_acc: 0.9483\n",
      "Epoch 80/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1552 - acc: 0.9314 - val_loss: 0.1045 - val_acc: 0.9551\n",
      "Epoch 81/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1562 - acc: 0.9271 - val_loss: 0.1112 - val_acc: 0.9539\n",
      "Epoch 82/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1538 - acc: 0.9358 - val_loss: 0.1310 - val_acc: 0.9433\n",
      "Epoch 83/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1368 - acc: 0.9420 - val_loss: 0.1097 - val_acc: 0.9613\n",
      "Epoch 84/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1694 - acc: 0.9227 - val_loss: 0.1187 - val_acc: 0.9476\n",
      "Epoch 85/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1487 - acc: 0.9414 - val_loss: 0.1021 - val_acc: 0.9613\n",
      "Epoch 86/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1475 - acc: 0.9308 - val_loss: 0.1133 - val_acc: 0.9520\n",
      "Epoch 87/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1353 - acc: 0.9414 - val_loss: 0.0916 - val_acc: 0.9613\n",
      "Epoch 88/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1417 - acc: 0.9352 - val_loss: 0.1030 - val_acc: 0.9526\n",
      "Epoch 89/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1478 - acc: 0.9327 - val_loss: 0.0910 - val_acc: 0.9651\n",
      "Epoch 90/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1357 - acc: 0.9451 - val_loss: 0.1024 - val_acc: 0.9670\n",
      "Epoch 91/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1290 - acc: 0.9445 - val_loss: 0.0855 - val_acc: 0.9670\n",
      "Epoch 92/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1332 - acc: 0.9433 - val_loss: 0.1008 - val_acc: 0.9626\n",
      "Epoch 93/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1287 - acc: 0.9445 - val_loss: 0.1085 - val_acc: 0.9520\n",
      "Epoch 94/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1214 - acc: 0.9464 - val_loss: 0.1161 - val_acc: 0.9489\n",
      "Epoch 95/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1861 - acc: 0.9183 - val_loss: 0.1024 - val_acc: 0.9645\n",
      "Epoch 96/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1371 - acc: 0.9414 - val_loss: 0.1207 - val_acc: 0.9470\n",
      "Epoch 97/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1204 - acc: 0.9514 - val_loss: 0.0881 - val_acc: 0.9601\n",
      "Epoch 98/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1261 - acc: 0.9445 - val_loss: 0.0971 - val_acc: 0.9632\n",
      "Epoch 99/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1355 - acc: 0.9426 - val_loss: 0.0811 - val_acc: 0.9707\n",
      "Epoch 100/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1174 - acc: 0.9551 - val_loss: 0.0702 - val_acc: 0.9744\n",
      "Epoch 101/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1214 - acc: 0.9470 - val_loss: 0.0872 - val_acc: 0.9589\n",
      "Epoch 102/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1218 - acc: 0.9389 - val_loss: 0.0894 - val_acc: 0.9613\n",
      "Epoch 103/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1424 - acc: 0.9377 - val_loss: 0.0889 - val_acc: 0.9645\n",
      "Epoch 104/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1353 - acc: 0.9401 - val_loss: 0.0768 - val_acc: 0.9744\n",
      "Epoch 105/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1217 - acc: 0.9514 - val_loss: 0.0920 - val_acc: 0.9576\n",
      "Epoch 106/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1097 - acc: 0.9501 - val_loss: 0.0649 - val_acc: 0.9776\n",
      "Epoch 107/200\n",
      "1604/1604 [==============================] - 9s 5ms/step - loss: 0.1042 - acc: 0.9626 - val_loss: 0.0639 - val_acc: 0.9719\n",
      "Epoch 108/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1119 - acc: 0.9464 - val_loss: 0.0590 - val_acc: 0.9769\n",
      "Epoch 109/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0972 - acc: 0.9589 - val_loss: 0.0554 - val_acc: 0.9757\n",
      "Epoch 110/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1228 - acc: 0.9458 - val_loss: 0.0586 - val_acc: 0.9838\n",
      "Epoch 111/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1281 - acc: 0.9439 - val_loss: 0.0730 - val_acc: 0.9776\n",
      "Epoch 112/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1044 - acc: 0.9576 - val_loss: 0.0607 - val_acc: 0.9782\n",
      "Epoch 113/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1041 - acc: 0.9589 - val_loss: 0.0761 - val_acc: 0.9688\n",
      "Epoch 114/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1047 - acc: 0.9501 - val_loss: 0.0603 - val_acc: 0.9819\n",
      "Epoch 115/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0915 - acc: 0.9607 - val_loss: 0.0842 - val_acc: 0.9645\n",
      "Epoch 116/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1188 - acc: 0.9439 - val_loss: 0.0591 - val_acc: 0.9751\n",
      "Epoch 117/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1083 - acc: 0.9501 - val_loss: 0.0536 - val_acc: 0.9832\n",
      "Epoch 118/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0939 - acc: 0.9570 - val_loss: 0.0764 - val_acc: 0.9651\n",
      "Epoch 119/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0957 - acc: 0.9620 - val_loss: 0.0657 - val_acc: 0.9850\n",
      "Epoch 120/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0965 - acc: 0.9564 - val_loss: 0.0491 - val_acc: 0.9875\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0889 - acc: 0.9670 - val_loss: 0.0467 - val_acc: 0.9882\n",
      "Epoch 122/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0795 - acc: 0.9626 - val_loss: 0.0462 - val_acc: 0.9825\n",
      "Epoch 123/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1003 - acc: 0.9570 - val_loss: 0.0423 - val_acc: 0.9869\n",
      "Epoch 124/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0782 - acc: 0.9670 - val_loss: 0.0404 - val_acc: 0.9869\n",
      "Epoch 125/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0902 - acc: 0.9645 - val_loss: 0.0418 - val_acc: 0.9894\n",
      "Epoch 126/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0826 - acc: 0.9676 - val_loss: 0.0416 - val_acc: 0.9869\n",
      "Epoch 127/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0900 - acc: 0.9620 - val_loss: 0.0392 - val_acc: 0.9913\n",
      "Epoch 128/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1027 - acc: 0.9551 - val_loss: 0.0466 - val_acc: 0.9900\n",
      "Epoch 129/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0877 - acc: 0.9595 - val_loss: 0.0400 - val_acc: 0.9882\n",
      "Epoch 130/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0956 - acc: 0.9564 - val_loss: 0.0455 - val_acc: 0.9875\n",
      "Epoch 131/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0954 - acc: 0.9601 - val_loss: 0.0398 - val_acc: 0.9888\n",
      "Epoch 132/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0889 - acc: 0.9651 - val_loss: 0.0473 - val_acc: 0.9863\n",
      "Epoch 133/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0771 - acc: 0.9701 - val_loss: 0.0378 - val_acc: 0.9863\n",
      "Epoch 134/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0699 - acc: 0.9707 - val_loss: 0.0369 - val_acc: 0.9875\n",
      "Epoch 135/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0685 - acc: 0.9719 - val_loss: 0.0292 - val_acc: 0.9913\n",
      "Epoch 136/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0631 - acc: 0.9738 - val_loss: 0.0374 - val_acc: 0.9863\n",
      "Epoch 137/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.1087 - acc: 0.9489 - val_loss: 0.0345 - val_acc: 0.9906\n",
      "Epoch 138/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0689 - acc: 0.9744 - val_loss: 0.0268 - val_acc: 0.9938\n",
      "Epoch 139/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0848 - acc: 0.9582 - val_loss: 0.0328 - val_acc: 0.9925\n",
      "Epoch 140/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0747 - acc: 0.9688 - val_loss: 0.0322 - val_acc: 0.9900\n",
      "Epoch 141/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0845 - acc: 0.9638 - val_loss: 0.0395 - val_acc: 0.9900\n",
      "Epoch 142/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0820 - acc: 0.9695 - val_loss: 0.0292 - val_acc: 0.9944\n",
      "Epoch 143/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0691 - acc: 0.9701 - val_loss: 0.0372 - val_acc: 0.9913\n",
      "Epoch 144/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0704 - acc: 0.9738 - val_loss: 0.0328 - val_acc: 0.9931\n",
      "Epoch 145/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0713 - acc: 0.9695 - val_loss: 0.0227 - val_acc: 0.9944\n",
      "Epoch 146/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0639 - acc: 0.9751 - val_loss: 0.0463 - val_acc: 0.9838\n",
      "Epoch 147/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0715 - acc: 0.9695 - val_loss: 0.0703 - val_acc: 0.9713\n",
      "Epoch 148/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0783 - acc: 0.9663 - val_loss: 0.0530 - val_acc: 0.9788\n",
      "Epoch 149/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0751 - acc: 0.9670 - val_loss: 0.0272 - val_acc: 0.9950\n",
      "Epoch 150/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0796 - acc: 0.9657 - val_loss: 0.0261 - val_acc: 0.9938\n",
      "Epoch 151/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0863 - acc: 0.9657 - val_loss: 0.0291 - val_acc: 0.9950\n",
      "Epoch 152/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0771 - acc: 0.9682 - val_loss: 0.0294 - val_acc: 0.9913\n",
      "Epoch 153/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0515 - acc: 0.9807 - val_loss: 0.0199 - val_acc: 0.9969\n",
      "Epoch 154/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0541 - acc: 0.9788 - val_loss: 0.0219 - val_acc: 0.9944\n",
      "Epoch 155/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0765 - acc: 0.9695 - val_loss: 0.0204 - val_acc: 0.9969\n",
      "Epoch 156/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0702 - acc: 0.9738 - val_loss: 0.0308 - val_acc: 0.9919\n",
      "Epoch 157/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0479 - acc: 0.9819 - val_loss: 0.0175 - val_acc: 0.9950\n",
      "Epoch 158/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0686 - acc: 0.9719 - val_loss: 0.0354 - val_acc: 0.9938\n",
      "Epoch 159/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0545 - acc: 0.9769 - val_loss: 0.0246 - val_acc: 0.9944\n",
      "Epoch 160/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0493 - acc: 0.9813 - val_loss: 0.0322 - val_acc: 0.9869\n",
      "Epoch 161/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0712 - acc: 0.9713 - val_loss: 0.0235 - val_acc: 0.9956\n",
      "Epoch 162/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0864 - acc: 0.9657 - val_loss: 0.0296 - val_acc: 0.9931\n",
      "Epoch 163/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0579 - acc: 0.9794 - val_loss: 0.0221 - val_acc: 0.9956\n",
      "Epoch 164/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0455 - acc: 0.9813 - val_loss: 0.0178 - val_acc: 0.9956\n",
      "Epoch 165/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0497 - acc: 0.9813 - val_loss: 0.0233 - val_acc: 0.9925\n",
      "Epoch 166/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0631 - acc: 0.9776 - val_loss: 0.0300 - val_acc: 0.9919\n",
      "Epoch 167/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0484 - acc: 0.9819 - val_loss: 0.0334 - val_acc: 0.9882\n",
      "Epoch 168/200\n",
      "1604/1604 [==============================] - 9s 5ms/step - loss: 0.0571 - acc: 0.9776 - val_loss: 0.0162 - val_acc: 0.9969\n",
      "Epoch 169/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0487 - acc: 0.9857 - val_loss: 0.0127 - val_acc: 0.9981\n",
      "Epoch 170/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0492 - acc: 0.9838 - val_loss: 0.0338 - val_acc: 0.9888\n",
      "Epoch 171/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0694 - acc: 0.9744 - val_loss: 0.0356 - val_acc: 0.9906\n",
      "Epoch 172/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0621 - acc: 0.9769 - val_loss: 0.0163 - val_acc: 0.9981\n",
      "Epoch 173/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0832 - acc: 0.9688 - val_loss: 0.0366 - val_acc: 0.9875\n",
      "Epoch 174/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0635 - acc: 0.9726 - val_loss: 0.0328 - val_acc: 0.9900\n",
      "Epoch 175/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0689 - acc: 0.9682 - val_loss: 0.0248 - val_acc: 0.9975\n",
      "Epoch 176/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0477 - acc: 0.9819 - val_loss: 0.0197 - val_acc: 0.9950\n",
      "Epoch 177/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0471 - acc: 0.9838 - val_loss: 0.0342 - val_acc: 0.9919\n",
      "Epoch 178/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0461 - acc: 0.9832 - val_loss: 0.0157 - val_acc: 0.9981\n",
      "Epoch 179/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0422 - acc: 0.9813 - val_loss: 0.0144 - val_acc: 0.9956\n",
      "Epoch 180/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0653 - acc: 0.9757 - val_loss: 0.0154 - val_acc: 0.9975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0401 - acc: 0.9863 - val_loss: 0.0170 - val_acc: 0.9969\n",
      "Epoch 182/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0410 - acc: 0.9875 - val_loss: 0.0085 - val_acc: 0.9994\n",
      "Epoch 183/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0535 - acc: 0.9825 - val_loss: 0.0186 - val_acc: 0.9938\n",
      "Epoch 184/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0311 - acc: 0.9894 - val_loss: 0.0134 - val_acc: 0.9963\n",
      "Epoch 185/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0680 - acc: 0.9688 - val_loss: 0.0238 - val_acc: 0.9963\n",
      "Epoch 186/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0506 - acc: 0.9788 - val_loss: 0.0097 - val_acc: 0.9988\n",
      "Epoch 187/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0317 - acc: 0.9888 - val_loss: 0.0122 - val_acc: 0.9981\n",
      "Epoch 188/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0526 - acc: 0.9782 - val_loss: 0.0121 - val_acc: 0.9975\n",
      "Epoch 189/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0337 - acc: 0.9844 - val_loss: 0.0092 - val_acc: 0.9975\n",
      "Epoch 190/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0413 - acc: 0.9844 - val_loss: 0.0093 - val_acc: 0.9975\n",
      "Epoch 191/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0548 - acc: 0.9807 - val_loss: 0.0196 - val_acc: 0.9963\n",
      "Epoch 192/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0253 - val_acc: 0.9913\n",
      "Epoch 193/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0539 - acc: 0.9825 - val_loss: 0.0143 - val_acc: 0.9969\n",
      "Epoch 194/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0502 - acc: 0.9807 - val_loss: 0.0115 - val_acc: 0.9975\n",
      "Epoch 195/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0449 - acc: 0.9825 - val_loss: 0.0074 - val_acc: 0.9988\n",
      "Epoch 196/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0448 - acc: 0.9825 - val_loss: 0.0181 - val_acc: 0.9956\n",
      "Epoch 197/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0439 - acc: 0.9844 - val_loss: 0.0070 - val_acc: 0.9988\n",
      "Epoch 198/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0403 - acc: 0.9869 - val_loss: 0.0086 - val_acc: 0.9981\n",
      "Epoch 199/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0308 - acc: 0.9875 - val_loss: 0.0062 - val_acc: 0.9994\n",
      "Epoch 200/200\n",
      "1604/1604 [==============================] - 8s 5ms/step - loss: 0.0370 - acc: 0.9875 - val_loss: 0.0135 - val_acc: 0.9969\n"
     ]
    }
   ],
   "source": [
    "result_Cnn = fitmodel(Cnnmodel,X_train,target_train,X_train,target_train,augment = False,epochs = 200,batch_size = 32,filepath = 'model save/Model 2-Advanced CNN with local TL,DA and CV5/TL source.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(result,name = 'fit_history.csv',path = os.getcwd()):\n",
    "    train_loss = result.history['loss']\n",
    "    val_loss = result.history['val_loss']\n",
    "    train_accuracy = result.history['acc']\n",
    "    val_accuracy = result.history['val_acc']\n",
    "    fit_history = pd.DataFrame({'train_loss':train_loss,'val_loss':val_loss,'train_accuracy':train_accuracy,'val_accuracy':val_accuracy})\n",
    "    fit_history.to_csv(os.path.join(path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_Cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-0f752ee40c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_Cnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result_Cnn' is not defined"
     ]
    }
   ],
   "source": [
    "save_history(result_Cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/40 [==============================] - 8s 191ms/step - loss: 0.5088 - acc: 0.8437 - val_loss: 0.1513 - val_acc: 0.9658\n",
      "Epoch 2/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3767 - acc: 0.8437 - val_loss: 0.1742 - val_acc: 0.9472\n",
      "Epoch 3/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3118 - acc: 0.8643 - val_loss: 0.1110 - val_acc: 0.9720\n",
      "Epoch 4/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3413 - acc: 0.8356 - val_loss: 0.1482 - val_acc: 0.9720\n",
      "Epoch 5/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3038 - acc: 0.8696 - val_loss: 0.1145 - val_acc: 0.9658\n",
      "Epoch 6/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2954 - acc: 0.8673 - val_loss: 0.0854 - val_acc: 0.9845\n",
      "Epoch 7/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2999 - acc: 0.8658 - val_loss: 0.0936 - val_acc: 0.9814\n",
      "Epoch 8/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2907 - acc: 0.8818 - val_loss: 0.0883 - val_acc: 0.9845\n",
      "Epoch 9/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2809 - acc: 0.8810 - val_loss: 0.0788 - val_acc: 0.9876\n",
      "Epoch 10/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2935 - acc: 0.8577 - val_loss: 0.0984 - val_acc: 0.9752\n",
      "Epoch 11/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2795 - acc: 0.8818 - val_loss: 0.0843 - val_acc: 0.9814\n",
      "Epoch 12/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3159 - acc: 0.8478 - val_loss: 0.2374 - val_acc: 0.9255\n",
      "Epoch 13/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3166 - acc: 0.8658 - val_loss: 0.1364 - val_acc: 0.9317\n",
      "Epoch 14/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2948 - acc: 0.8661 - val_loss: 0.1000 - val_acc: 0.9845\n",
      "Epoch 15/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2673 - acc: 0.8864 - val_loss: 0.1151 - val_acc: 0.9876\n",
      "Epoch 16/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2732 - acc: 0.8749 - val_loss: 0.0911 - val_acc: 0.9845\n",
      "Epoch 17/100\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2680 - acc: 0.8864 - val_loss: 0.0900 - val_acc: 0.9752\n",
      "Epoch 18/100\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.2414 - acc: 0.8970 - val_loss: 0.0954 - val_acc: 0.9596\n",
      "Epoch 19/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2549 - acc: 0.8871 - val_loss: 0.1167 - val_acc: 0.9845\n",
      "Epoch 20/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2360 - acc: 0.9031 - val_loss: 0.0871 - val_acc: 0.9814\n",
      "Epoch 21/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2667 - acc: 0.8841 - val_loss: 0.0841 - val_acc: 0.9876\n",
      "Epoch 22/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2569 - acc: 0.8866 - val_loss: 0.2000 - val_acc: 0.9130\n",
      "Epoch 23/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2982 - acc: 0.8523 - val_loss: 0.1370 - val_acc: 0.9472\n",
      "Epoch 24/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2806 - acc: 0.8722 - val_loss: 0.1079 - val_acc: 0.9720\n",
      "Epoch 25/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2696 - acc: 0.8856 - val_loss: 0.1425 - val_acc: 0.9534\n",
      "Epoch 26/100\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2504 - acc: 0.8909 - val_loss: 0.1335 - val_acc: 0.9565\n",
      "Epoch 27/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2754 - acc: 0.8856 - val_loss: 0.1143 - val_acc: 0.9658\n",
      "Epoch 28/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2417 - acc: 0.8909 - val_loss: 0.0776 - val_acc: 0.9814\n",
      "Epoch 29/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2461 - acc: 0.8970 - val_loss: 0.0985 - val_acc: 0.9845\n",
      "Epoch 30/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2511 - acc: 0.8902 - val_loss: 0.1199 - val_acc: 0.9814\n",
      "Epoch 31/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2631 - acc: 0.8848 - val_loss: 0.1078 - val_acc: 0.9876\n",
      "Epoch 32/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2220 - acc: 0.9184 - val_loss: 0.0875 - val_acc: 0.9814\n",
      "Epoch 33/100\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2369 - acc: 0.8978 - val_loss: 0.1174 - val_acc: 0.9658\n",
      "Epoch 34/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2375 - acc: 0.8970 - val_loss: 0.1109 - val_acc: 0.9658\n",
      "Epoch 35/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2290 - acc: 0.9009 - val_loss: 0.0882 - val_acc: 0.9752\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 6s 153ms/step - loss: 0.2506 - acc: 0.9092 - val_loss: 0.1252 - val_acc: 0.9720\n",
      "Epoch 37/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2411 - acc: 0.9047 - val_loss: 0.1046 - val_acc: 0.9627\n",
      "Epoch 38/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2139 - acc: 0.9085 - val_loss: 0.0966 - val_acc: 0.9627\n",
      "Epoch 39/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2273 - acc: 0.9001 - val_loss: 0.0931 - val_acc: 0.9689\n",
      "Epoch 40/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2311 - acc: 0.9123 - val_loss: 0.1012 - val_acc: 0.9783\n",
      "Epoch 41/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2228 - acc: 0.9009 - val_loss: 0.0959 - val_acc: 0.9845\n",
      "Epoch 42/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2274 - acc: 0.8978 - val_loss: 0.1105 - val_acc: 0.9720\n",
      "Epoch 43/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2480 - acc: 0.8828 - val_loss: 0.1370 - val_acc: 0.9534\n",
      "Epoch 44/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2420 - acc: 0.8986 - val_loss: 0.1177 - val_acc: 0.9596\n",
      "Epoch 45/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2111 - acc: 0.9054 - val_loss: 0.1116 - val_acc: 0.9752\n",
      "Epoch 46/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2099 - acc: 0.9054 - val_loss: 0.0992 - val_acc: 0.9658\n",
      "Epoch 47/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2242 - acc: 0.9047 - val_loss: 0.0982 - val_acc: 0.9752\n",
      "Epoch 48/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2300 - acc: 0.9031 - val_loss: 0.1220 - val_acc: 0.9689\n",
      "Epoch 49/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2265 - acc: 0.9047 - val_loss: 0.0991 - val_acc: 0.9752\n",
      "Epoch 50/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2382 - acc: 0.8897 - val_loss: 0.1205 - val_acc: 0.9534\n",
      "Epoch 51/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2355 - acc: 0.8966 - val_loss: 0.1167 - val_acc: 0.9503\n",
      "Epoch 52/100\n",
      "41/40 [==============================] - 6s 155ms/step - loss: 0.2125 - acc: 0.9108 - val_loss: 0.1501 - val_acc: 0.9286\n",
      "Epoch 53/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2341 - acc: 0.8935 - val_loss: 0.1441 - val_acc: 0.9627\n",
      "Epoch 54/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2847 - acc: 0.8767 - val_loss: 0.1318 - val_acc: 0.9627\n",
      "Epoch 55/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2300 - acc: 0.9054 - val_loss: 0.1244 - val_acc: 0.9596\n",
      "Epoch 56/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2312 - acc: 0.8828 - val_loss: 0.1226 - val_acc: 0.9627\n",
      "Epoch 57/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2159 - acc: 0.9100 - val_loss: 0.0981 - val_acc: 0.9720\n",
      "Epoch 58/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2059 - acc: 0.9115 - val_loss: 0.1227 - val_acc: 0.9596\n",
      "Epoch 59/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2153 - acc: 0.9131 - val_loss: 0.1074 - val_acc: 0.9783\n",
      "Epoch 60/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2110 - acc: 0.9070 - val_loss: 0.1102 - val_acc: 0.9565\n",
      "Epoch 61/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2178 - acc: 0.9039 - val_loss: 0.1275 - val_acc: 0.9503\n",
      "Epoch 62/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2176 - acc: 0.9153 - val_loss: 0.1508 - val_acc: 0.9565\n",
      "Epoch 63/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2185 - acc: 0.9054 - val_loss: 0.1054 - val_acc: 0.9627\n",
      "Epoch 64/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2043 - acc: 0.9199 - val_loss: 0.1237 - val_acc: 0.9503\n",
      "Epoch 65/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2100 - acc: 0.9123 - val_loss: 0.1132 - val_acc: 0.9689\n",
      "Epoch 66/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2079 - acc: 0.9108 - val_loss: 0.1031 - val_acc: 0.9752\n",
      "Epoch 67/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2064 - acc: 0.9153 - val_loss: 0.1102 - val_acc: 0.9689\n",
      "Epoch 68/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1946 - acc: 0.9161 - val_loss: 0.1107 - val_acc: 0.9596\n",
      "Epoch 69/100\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.2183 - acc: 0.9057 - val_loss: 0.1333 - val_acc: 0.9410\n",
      "Epoch 70/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2311 - acc: 0.8973 - val_loss: 0.1284 - val_acc: 0.9348\n",
      "Epoch 71/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2157 - acc: 0.9077 - val_loss: 0.1324 - val_acc: 0.9689\n",
      "Epoch 72/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2062 - acc: 0.9146 - val_loss: 0.1068 - val_acc: 0.9689\n",
      "Epoch 73/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2218 - acc: 0.9138 - val_loss: 0.1619 - val_acc: 0.9379\n",
      "Epoch 74/100\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.2086 - acc: 0.9062 - val_loss: 0.1107 - val_acc: 0.9658\n",
      "Epoch 75/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2163 - acc: 0.9054 - val_loss: 0.1606 - val_acc: 0.9286\n",
      "Epoch 76/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2114 - acc: 0.9070 - val_loss: 0.1107 - val_acc: 0.9534\n",
      "Epoch 77/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1908 - acc: 0.9184 - val_loss: 0.1200 - val_acc: 0.9503\n",
      "Epoch 78/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2084 - acc: 0.9215 - val_loss: 0.1169 - val_acc: 0.9658\n",
      "Epoch 79/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1847 - acc: 0.9283 - val_loss: 0.1081 - val_acc: 0.9720\n",
      "Epoch 80/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1983 - acc: 0.9108 - val_loss: 0.1759 - val_acc: 0.9255\n",
      "Epoch 81/100\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.1975 - acc: 0.9184 - val_loss: 0.1295 - val_acc: 0.9596\n",
      "Epoch 82/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2183 - acc: 0.9039 - val_loss: 0.1195 - val_acc: 0.9565\n",
      "Epoch 83/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1933 - acc: 0.9176 - val_loss: 0.1242 - val_acc: 0.9534\n",
      "Epoch 84/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1842 - acc: 0.9245 - val_loss: 0.1362 - val_acc: 0.9410\n",
      "Epoch 85/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1782 - acc: 0.9207 - val_loss: 0.1522 - val_acc: 0.9441\n",
      "Epoch 86/100\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2057 - acc: 0.9092 - val_loss: 0.1388 - val_acc: 0.9534\n",
      "Epoch 87/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1852 - acc: 0.9253 - val_loss: 0.1159 - val_acc: 0.9596\n",
      "Epoch 88/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1953 - acc: 0.9184 - val_loss: 0.1073 - val_acc: 0.9752\n",
      "Epoch 89/100\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2238 - acc: 0.9077 - val_loss: 0.1681 - val_acc: 0.9286\n",
      "Epoch 90/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2149 - acc: 0.8981 - val_loss: 0.1600 - val_acc: 0.9379\n",
      "Epoch 91/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1831 - acc: 0.9298 - val_loss: 0.1160 - val_acc: 0.9658\n",
      "Epoch 92/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2527 - acc: 0.8882 - val_loss: 0.1864 - val_acc: 0.9286\n",
      "Epoch 93/100\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2389 - acc: 0.8889 - val_loss: 0.1514 - val_acc: 0.9534\n",
      "Epoch 94/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2124 - acc: 0.9092 - val_loss: 0.1245 - val_acc: 0.9472\n",
      "Epoch 95/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1883 - acc: 0.9192 - val_loss: 0.1266 - val_acc: 0.9627\n",
      "Epoch 96/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2098 - acc: 0.9050 - val_loss: 0.1341 - val_acc: 0.9565\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2340 - acc: 0.9034 - val_loss: 0.1408 - val_acc: 0.9472\n",
      "Epoch 98/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2175 - acc: 0.9161 - val_loss: 0.1257 - val_acc: 0.9596\n",
      "Epoch 99/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2784 - acc: 0.8836 - val_loss: 0.1694 - val_acc: 0.9317\n",
      "Epoch 100/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2045 - acc: 0.9138 - val_loss: 0.1460 - val_acc: 0.9255\n",
      "322/322 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/40 [==============================] - 9s 222ms/step - loss: 0.5294 - acc: 0.8399 - val_loss: 0.1194 - val_acc: 0.9533\n",
      "Epoch 2/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.4088 - acc: 0.8132 - val_loss: 0.1411 - val_acc: 0.9564\n",
      "Epoch 3/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2996 - acc: 0.8571 - val_loss: 0.1281 - val_acc: 0.9533\n",
      "Epoch 4/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3187 - acc: 0.8650 - val_loss: 0.1134 - val_acc: 0.9595\n",
      "Epoch 5/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.3526 - acc: 0.8487 - val_loss: 0.1552 - val_acc: 0.9502\n",
      "Epoch 6/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2815 - acc: 0.8780 - val_loss: 0.1665 - val_acc: 0.9346\n",
      "Epoch 7/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.3010 - acc: 0.8643 - val_loss: 0.1452 - val_acc: 0.9377\n",
      "Epoch 8/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3049 - acc: 0.8551 - val_loss: 0.1203 - val_acc: 0.9595\n",
      "Epoch 9/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3036 - acc: 0.8719 - val_loss: 0.1306 - val_acc: 0.9657\n",
      "Epoch 10/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2582 - acc: 0.8826 - val_loss: 0.1121 - val_acc: 0.9595\n",
      "Epoch 11/100\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2763 - acc: 0.8818 - val_loss: 0.1248 - val_acc: 0.9564\n",
      "Epoch 12/100\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2799 - acc: 0.8841 - val_loss: 0.1341 - val_acc: 0.9657\n",
      "Epoch 13/100\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.2404 - acc: 0.8993 - val_loss: 0.1018 - val_acc: 0.9595\n",
      "Epoch 14/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2809 - acc: 0.8765 - val_loss: 0.1459 - val_acc: 0.9533\n",
      "Epoch 15/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2691 - acc: 0.8845 - val_loss: 0.1442 - val_acc: 0.9408\n",
      "Epoch 16/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2806 - acc: 0.8902 - val_loss: 0.1142 - val_acc: 0.9533\n",
      "Epoch 17/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2446 - acc: 0.8963 - val_loss: 0.1007 - val_acc: 0.9533\n",
      "Epoch 18/100\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.2523 - acc: 0.8986 - val_loss: 0.1448 - val_acc: 0.9408\n",
      "Epoch 19/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2682 - acc: 0.8906 - val_loss: 0.1097 - val_acc: 0.9595\n",
      "Epoch 20/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2602 - acc: 0.8940 - val_loss: 0.1181 - val_acc: 0.9751\n",
      "Epoch 21/100\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2312 - acc: 0.9039 - val_loss: 0.0995 - val_acc: 0.9720\n",
      "Epoch 22/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2433 - acc: 0.8917 - val_loss: 0.1246 - val_acc: 0.9470\n",
      "Epoch 23/100\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.2804 - acc: 0.8789 - val_loss: 0.1242 - val_acc: 0.9533\n",
      "Epoch 24/100\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2323 - acc: 0.9092 - val_loss: 0.1103 - val_acc: 0.9564\n",
      "Epoch 25/100\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.2330 - acc: 0.9009 - val_loss: 0.1076 - val_acc: 0.9595\n",
      "Epoch 26/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2421 - acc: 0.9047 - val_loss: 0.0989 - val_acc: 0.9533\n",
      "Epoch 27/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2394 - acc: 0.9009 - val_loss: 0.0984 - val_acc: 0.9626\n",
      "Epoch 28/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2347 - acc: 0.9092 - val_loss: 0.1155 - val_acc: 0.9377\n",
      "Epoch 29/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2289 - acc: 0.9031 - val_loss: 0.1628 - val_acc: 0.9283\n",
      "Epoch 30/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2286 - acc: 0.8909 - val_loss: 0.1095 - val_acc: 0.9533\n",
      "Epoch 31/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2893 - acc: 0.8891 - val_loss: 0.2053 - val_acc: 0.9097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3035 - acc: 0.8662 - val_loss: 0.1299 - val_acc: 0.9439\n",
      "Epoch 33/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2541 - acc: 0.8982 - val_loss: 0.1298 - val_acc: 0.9377\n",
      "Epoch 34/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2376 - acc: 0.8932 - val_loss: 0.1573 - val_acc: 0.9408\n",
      "Epoch 35/100\n",
      "41/40 [==============================] - 6s 152ms/step - loss: 0.2661 - acc: 0.8799 - val_loss: 0.1293 - val_acc: 0.9533\n",
      "Epoch 36/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2481 - acc: 0.8963 - val_loss: 0.1337 - val_acc: 0.9470\n",
      "Epoch 37/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2510 - acc: 0.8830 - val_loss: 0.1270 - val_acc: 0.9377\n",
      "Epoch 38/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2290 - acc: 0.9031 - val_loss: 0.1278 - val_acc: 0.9439\n",
      "Epoch 39/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2583 - acc: 0.9016 - val_loss: 0.1415 - val_acc: 0.9439\n",
      "Epoch 40/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2498 - acc: 0.9001 - val_loss: 0.1329 - val_acc: 0.9470\n",
      "Epoch 41/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2294 - acc: 0.8963 - val_loss: 0.1250 - val_acc: 0.9439\n",
      "Epoch 42/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2223 - acc: 0.9054 - val_loss: 0.1316 - val_acc: 0.9408\n",
      "Epoch 43/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2383 - acc: 0.8940 - val_loss: 0.1237 - val_acc: 0.9533\n",
      "Epoch 44/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2624 - acc: 0.8738 - val_loss: 0.1213 - val_acc: 0.9439\n",
      "Epoch 45/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2266 - acc: 0.9092 - val_loss: 0.1657 - val_acc: 0.9159\n",
      "Epoch 46/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2127 - acc: 0.9154 - val_loss: 0.1122 - val_acc: 0.9439\n",
      "Epoch 47/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2269 - acc: 0.9024 - val_loss: 0.1358 - val_acc: 0.9346\n",
      "Epoch 48/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2254 - acc: 0.9013 - val_loss: 0.1438 - val_acc: 0.9408\n",
      "Epoch 49/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2097 - acc: 0.9077 - val_loss: 0.1193 - val_acc: 0.9502\n",
      "Epoch 50/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2192 - acc: 0.9092 - val_loss: 0.1907 - val_acc: 0.9128\n",
      "Epoch 51/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2280 - acc: 0.9054 - val_loss: 0.1397 - val_acc: 0.9408\n",
      "Epoch 52/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2196 - acc: 0.9123 - val_loss: 0.1486 - val_acc: 0.9377\n",
      "Epoch 53/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2188 - acc: 0.8986 - val_loss: 0.1352 - val_acc: 0.9470\n",
      "Epoch 54/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2126 - acc: 0.9123 - val_loss: 0.1853 - val_acc: 0.9065\n",
      "Epoch 55/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2001 - acc: 0.9123 - val_loss: 0.1567 - val_acc: 0.9283\n",
      "Epoch 56/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2096 - acc: 0.9077 - val_loss: 0.1606 - val_acc: 0.9283\n",
      "Epoch 57/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2198 - acc: 0.8978 - val_loss: 0.1433 - val_acc: 0.9439\n",
      "Epoch 58/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1955 - acc: 0.9131 - val_loss: 0.1428 - val_acc: 0.9439\n",
      "Epoch 59/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2169 - acc: 0.9089 - val_loss: 0.1428 - val_acc: 0.9283\n",
      "Epoch 60/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2267 - acc: 0.9031 - val_loss: 0.1470 - val_acc: 0.9315\n",
      "Epoch 61/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2344 - acc: 0.8891 - val_loss: 0.1213 - val_acc: 0.9377\n",
      "Epoch 62/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2237 - acc: 0.9070 - val_loss: 0.1537 - val_acc: 0.9283\n",
      "Epoch 63/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2188 - acc: 0.9108 - val_loss: 0.1201 - val_acc: 0.9470\n",
      "Epoch 64/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2150 - acc: 0.9138 - val_loss: 0.1172 - val_acc: 0.9533\n",
      "Epoch 65/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2048 - acc: 0.9154 - val_loss: 0.1407 - val_acc: 0.9377\n",
      "Epoch 66/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2291 - acc: 0.8998 - val_loss: 0.1672 - val_acc: 0.9221\n",
      "Epoch 67/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2175 - acc: 0.9108 - val_loss: 0.1233 - val_acc: 0.9439\n",
      "Epoch 68/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2061 - acc: 0.9196 - val_loss: 0.1645 - val_acc: 0.9315\n",
      "Epoch 69/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2099 - acc: 0.9070 - val_loss: 0.1226 - val_acc: 0.9470\n",
      "Epoch 70/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1903 - acc: 0.9245 - val_loss: 0.1462 - val_acc: 0.9408\n",
      "Epoch 71/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1938 - acc: 0.9100 - val_loss: 0.1375 - val_acc: 0.9439\n",
      "Epoch 72/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1937 - acc: 0.9176 - val_loss: 0.1493 - val_acc: 0.9346\n",
      "Epoch 73/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2203 - acc: 0.9059 - val_loss: 0.1699 - val_acc: 0.9346\n",
      "Epoch 74/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2083 - acc: 0.9100 - val_loss: 0.1361 - val_acc: 0.9408\n",
      "Epoch 75/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1916 - acc: 0.9161 - val_loss: 0.1370 - val_acc: 0.9377\n",
      "Epoch 76/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2143 - acc: 0.9054 - val_loss: 0.1475 - val_acc: 0.9377\n",
      "Epoch 77/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2252 - acc: 0.8978 - val_loss: 0.1318 - val_acc: 0.9346\n",
      "Epoch 78/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2112 - acc: 0.9089 - val_loss: 0.1855 - val_acc: 0.9190\n",
      "Epoch 79/100\n",
      "41/40 [==============================] - 7s 161ms/step - loss: 0.2146 - acc: 0.9112 - val_loss: 0.1371 - val_acc: 0.9377\n",
      "Epoch 80/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1919 - acc: 0.9230 - val_loss: 0.1403 - val_acc: 0.9408\n",
      "Epoch 81/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2157 - acc: 0.9005 - val_loss: 0.1675 - val_acc: 0.9159\n",
      "Epoch 82/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2026 - acc: 0.9169 - val_loss: 0.1373 - val_acc: 0.9315\n",
      "Epoch 83/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1941 - acc: 0.9184 - val_loss: 0.1444 - val_acc: 0.9439\n",
      "Epoch 84/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2040 - acc: 0.9059 - val_loss: 0.1577 - val_acc: 0.9190\n",
      "Epoch 85/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2096 - acc: 0.9077 - val_loss: 0.1187 - val_acc: 0.9408\n",
      "Epoch 86/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2066 - acc: 0.9036 - val_loss: 0.1745 - val_acc: 0.9159\n",
      "Epoch 87/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2133 - acc: 0.9082 - val_loss: 0.1339 - val_acc: 0.9377\n",
      "Epoch 88/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2060 - acc: 0.9112 - val_loss: 0.1525 - val_acc: 0.9283\n",
      "Epoch 89/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1975 - acc: 0.9237 - val_loss: 0.1569 - val_acc: 0.9283\n",
      "Epoch 90/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1781 - acc: 0.9192 - val_loss: 0.1451 - val_acc: 0.9408\n",
      "Epoch 91/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1897 - acc: 0.9199 - val_loss: 0.1499 - val_acc: 0.9346\n",
      "Epoch 92/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2064 - acc: 0.9070 - val_loss: 0.1853 - val_acc: 0.9097\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1980 - acc: 0.9184 - val_loss: 0.1500 - val_acc: 0.9377\n",
      "Epoch 94/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2010 - acc: 0.9184 - val_loss: 0.1545 - val_acc: 0.9377\n",
      "Epoch 95/100\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.1845 - acc: 0.9199 - val_loss: 0.1823 - val_acc: 0.9159\n",
      "Epoch 96/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.1761 - acc: 0.9298 - val_loss: 0.1919 - val_acc: 0.9097\n",
      "Epoch 97/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2065 - acc: 0.9176 - val_loss: 0.1601 - val_acc: 0.9252\n",
      "Epoch 98/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1805 - acc: 0.9298 - val_loss: 0.1366 - val_acc: 0.9346\n",
      "Epoch 99/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2228 - acc: 0.9059 - val_loss: 0.1834 - val_acc: 0.9190\n",
      "Epoch 100/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2008 - acc: 0.9161 - val_loss: 0.1481 - val_acc: 0.9190\n",
      "321/321 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/40 [==============================] - 11s 268ms/step - loss: 0.5089 - acc: 0.8246 - val_loss: 0.1220 - val_acc: 0.9626\n",
      "Epoch 2/100\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.3622 - acc: 0.8345 - val_loss: 0.1393 - val_acc: 0.9626\n",
      "Epoch 3/100\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.3436 - acc: 0.8331 - val_loss: 0.1433 - val_acc: 0.9657\n",
      "Epoch 4/100\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.3238 - acc: 0.8513 - val_loss: 0.0760 - val_acc: 0.9875\n",
      "Epoch 5/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3382 - acc: 0.8548 - val_loss: 0.1250 - val_acc: 0.9751\n",
      "Epoch 6/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3255 - acc: 0.8421 - val_loss: 0.1070 - val_acc: 0.9782\n",
      "Epoch 7/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3111 - acc: 0.8505 - val_loss: 0.1183 - val_acc: 0.9907\n",
      "Epoch 8/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2931 - acc: 0.8643 - val_loss: 0.0862 - val_acc: 0.9907\n",
      "Epoch 9/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3067 - acc: 0.8627 - val_loss: 0.1058 - val_acc: 0.9907\n",
      "Epoch 10/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2958 - acc: 0.8757 - val_loss: 0.1619 - val_acc: 0.9377\n",
      "Epoch 11/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3057 - acc: 0.8609 - val_loss: 0.1116 - val_acc: 0.9844\n",
      "Epoch 12/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2756 - acc: 0.8879 - val_loss: 0.1173 - val_acc: 0.9720\n",
      "Epoch 13/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2802 - acc: 0.8772 - val_loss: 0.1193 - val_acc: 0.9564\n",
      "Epoch 14/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2864 - acc: 0.8807 - val_loss: 0.1152 - val_acc: 0.9720\n",
      "Epoch 15/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2654 - acc: 0.8856 - val_loss: 0.1151 - val_acc: 0.9751\n",
      "Epoch 16/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2620 - acc: 0.8864 - val_loss: 0.0969 - val_acc: 0.9782\n",
      "Epoch 17/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2739 - acc: 0.8963 - val_loss: 0.1066 - val_acc: 0.9813\n",
      "Epoch 18/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2503 - acc: 0.8879 - val_loss: 0.1252 - val_acc: 0.9720\n",
      "Epoch 19/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2517 - acc: 0.8917 - val_loss: 0.1153 - val_acc: 0.9688\n",
      "Epoch 20/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2426 - acc: 0.8970 - val_loss: 0.1099 - val_acc: 0.9626\n",
      "Epoch 21/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2627 - acc: 0.8864 - val_loss: 0.0898 - val_acc: 0.9813\n",
      "Epoch 22/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2798 - acc: 0.8734 - val_loss: 0.1051 - val_acc: 0.9782\n",
      "Epoch 23/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2367 - acc: 0.9001 - val_loss: 0.1086 - val_acc: 0.9688\n",
      "Epoch 24/100\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.2373 - acc: 0.9039 - val_loss: 0.1093 - val_acc: 0.9595\n",
      "Epoch 25/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2715 - acc: 0.8769 - val_loss: 0.1234 - val_acc: 0.9470\n",
      "Epoch 26/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2424 - acc: 0.8986 - val_loss: 0.1045 - val_acc: 0.9595\n",
      "Epoch 27/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2584 - acc: 0.8803 - val_loss: 0.1235 - val_acc: 0.9657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2440 - acc: 0.8955 - val_loss: 0.0974 - val_acc: 0.9782\n",
      "Epoch 29/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2295 - acc: 0.9100 - val_loss: 0.1035 - val_acc: 0.9782\n",
      "Epoch 30/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3955 - acc: 0.8403 - val_loss: 0.2816 - val_acc: 0.9377\n",
      "Epoch 31/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3328 - acc: 0.8594 - val_loss: 0.1085 - val_acc: 0.9813\n",
      "Epoch 32/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2452 - acc: 0.9001 - val_loss: 0.1133 - val_acc: 0.9533\n",
      "Epoch 33/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2463 - acc: 0.8978 - val_loss: 0.0961 - val_acc: 0.9751\n",
      "Epoch 34/100\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.2368 - acc: 0.9016 - val_loss: 0.1091 - val_acc: 0.9657\n",
      "Epoch 35/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2839 - acc: 0.8769 - val_loss: 0.1486 - val_acc: 0.9533\n",
      "Epoch 36/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2364 - acc: 0.9070 - val_loss: 0.1064 - val_acc: 0.9502\n",
      "Epoch 37/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2337 - acc: 0.8970 - val_loss: 0.1267 - val_acc: 0.9533\n",
      "Epoch 38/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2671 - acc: 0.8868 - val_loss: 0.1003 - val_acc: 0.9626\n",
      "Epoch 39/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2460 - acc: 0.9016 - val_loss: 0.1195 - val_acc: 0.9751\n",
      "Epoch 40/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2320 - acc: 0.8868 - val_loss: 0.1307 - val_acc: 0.9502\n",
      "Epoch 41/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2294 - acc: 0.9039 - val_loss: 0.1093 - val_acc: 0.9751\n",
      "Epoch 42/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2314 - acc: 0.9062 - val_loss: 0.0931 - val_acc: 0.9813\n",
      "Epoch 43/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2532 - acc: 0.8906 - val_loss: 0.1320 - val_acc: 0.9751\n",
      "Epoch 44/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2465 - acc: 0.8993 - val_loss: 0.1261 - val_acc: 0.9720\n",
      "Epoch 45/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2414 - acc: 0.8932 - val_loss: 0.1431 - val_acc: 0.9502\n",
      "Epoch 46/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2470 - acc: 0.8876 - val_loss: 0.1514 - val_acc: 0.9470\n",
      "Epoch 47/100\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.2189 - acc: 0.9070 - val_loss: 0.0794 - val_acc: 0.9782\n",
      "Epoch 48/100\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2597 - acc: 0.8799 - val_loss: 0.1483 - val_acc: 0.9439\n",
      "Epoch 49/100\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2364 - acc: 0.8948 - val_loss: 0.1202 - val_acc: 0.9595\n",
      "Epoch 50/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2121 - acc: 0.9031 - val_loss: 0.1036 - val_acc: 0.9657\n",
      "Epoch 51/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2507 - acc: 0.8960 - val_loss: 0.1077 - val_acc: 0.9626\n",
      "Epoch 52/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2416 - acc: 0.8970 - val_loss: 0.1082 - val_acc: 0.9813\n",
      "Epoch 53/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2116 - acc: 0.9077 - val_loss: 0.0898 - val_acc: 0.9844\n",
      "Epoch 54/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2193 - acc: 0.9047 - val_loss: 0.1006 - val_acc: 0.9720\n",
      "Epoch 55/100\n",
      "41/40 [==============================] - 6s 151ms/step - loss: 0.2093 - acc: 0.9108 - val_loss: 0.1190 - val_acc: 0.9720\n",
      "Epoch 56/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2218 - acc: 0.8998 - val_loss: 0.0963 - val_acc: 0.9626\n",
      "Epoch 57/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2800 - acc: 0.8807 - val_loss: 0.2017 - val_acc: 0.9159\n",
      "Epoch 58/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2375 - acc: 0.9024 - val_loss: 0.1066 - val_acc: 0.9657\n",
      "Epoch 59/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2201 - acc: 0.8998 - val_loss: 0.1044 - val_acc: 0.9657\n",
      "Epoch 60/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2319 - acc: 0.8993 - val_loss: 0.1039 - val_acc: 0.9782\n",
      "Epoch 61/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2059 - acc: 0.9100 - val_loss: 0.1344 - val_acc: 0.9502\n",
      "Epoch 62/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2025 - acc: 0.9108 - val_loss: 0.0936 - val_acc: 0.9782\n",
      "Epoch 63/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2058 - acc: 0.9199 - val_loss: 0.1014 - val_acc: 0.9782\n",
      "Epoch 64/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2276 - acc: 0.9043 - val_loss: 0.0985 - val_acc: 0.9657\n",
      "Epoch 65/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1974 - acc: 0.9199 - val_loss: 0.0972 - val_acc: 0.9751\n",
      "Epoch 66/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2170 - acc: 0.8993 - val_loss: 0.1082 - val_acc: 0.9564\n",
      "Epoch 67/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2490 - acc: 0.8990 - val_loss: 0.2095 - val_acc: 0.9533\n",
      "Epoch 68/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2398 - acc: 0.8940 - val_loss: 0.0879 - val_acc: 0.9720\n",
      "Epoch 69/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2233 - acc: 0.9092 - val_loss: 0.1173 - val_acc: 0.9657\n",
      "Epoch 70/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2149 - acc: 0.9123 - val_loss: 0.1191 - val_acc: 0.9626\n",
      "Epoch 71/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2040 - acc: 0.9077 - val_loss: 0.1190 - val_acc: 0.9688\n",
      "Epoch 72/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2153 - acc: 0.9131 - val_loss: 0.0966 - val_acc: 0.9751\n",
      "Epoch 73/100\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.2224 - acc: 0.9100 - val_loss: 0.1378 - val_acc: 0.9408\n",
      "Epoch 74/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2343 - acc: 0.9077 - val_loss: 0.0998 - val_acc: 0.9564\n",
      "Epoch 75/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2443 - acc: 0.8926 - val_loss: 0.1569 - val_acc: 0.9502\n",
      "Epoch 76/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2132 - acc: 0.9169 - val_loss: 0.0963 - val_acc: 0.9844\n",
      "Epoch 77/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2016 - acc: 0.9146 - val_loss: 0.1282 - val_acc: 0.9626\n",
      "Epoch 78/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2079 - acc: 0.9154 - val_loss: 0.0974 - val_acc: 0.9688\n",
      "Epoch 79/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2043 - acc: 0.9215 - val_loss: 0.0898 - val_acc: 0.9782\n",
      "Epoch 80/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2173 - acc: 0.9115 - val_loss: 0.1113 - val_acc: 0.9657\n",
      "Epoch 81/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1916 - acc: 0.9138 - val_loss: 0.1267 - val_acc: 0.9626\n",
      "Epoch 82/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2398 - acc: 0.8937 - val_loss: 0.1120 - val_acc: 0.9688\n",
      "Epoch 83/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2149 - acc: 0.9097 - val_loss: 0.1024 - val_acc: 0.9688\n",
      "Epoch 84/100\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2264 - acc: 0.9016 - val_loss: 0.1098 - val_acc: 0.9626\n",
      "Epoch 85/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2362 - acc: 0.8998 - val_loss: 0.1285 - val_acc: 0.9564\n",
      "Epoch 86/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2109 - acc: 0.9108 - val_loss: 0.1246 - val_acc: 0.9533\n",
      "Epoch 87/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2049 - acc: 0.9085 - val_loss: 0.1180 - val_acc: 0.9688\n",
      "Epoch 88/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2209 - acc: 0.9036 - val_loss: 0.1149 - val_acc: 0.9657\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1931 - acc: 0.9207 - val_loss: 0.1124 - val_acc: 0.9626\n",
      "Epoch 90/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1984 - acc: 0.9154 - val_loss: 0.1543 - val_acc: 0.9470\n",
      "Epoch 91/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1951 - acc: 0.9192 - val_loss: 0.1362 - val_acc: 0.9470\n",
      "Epoch 92/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1872 - acc: 0.9253 - val_loss: 0.1384 - val_acc: 0.9533\n",
      "Epoch 93/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2013 - acc: 0.9291 - val_loss: 0.1305 - val_acc: 0.9502\n",
      "Epoch 94/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2076 - acc: 0.9146 - val_loss: 0.1199 - val_acc: 0.9688\n",
      "Epoch 95/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2138 - acc: 0.9176 - val_loss: 0.1377 - val_acc: 0.9502\n",
      "Epoch 96/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2012 - acc: 0.9104 - val_loss: 0.1219 - val_acc: 0.9502\n",
      "Epoch 97/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2218 - acc: 0.8937 - val_loss: 0.1304 - val_acc: 0.9408\n",
      "Epoch 98/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1984 - acc: 0.9138 - val_loss: 0.1026 - val_acc: 0.9657\n",
      "Epoch 99/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1933 - acc: 0.9199 - val_loss: 0.1219 - val_acc: 0.9626\n",
      "Epoch 100/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1838 - acc: 0.9230 - val_loss: 0.1079 - val_acc: 0.9657\n",
      "321/321 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/40 [==============================] - 9s 226ms/step - loss: 0.5633 - acc: 0.8217 - val_loss: 0.1377 - val_acc: 0.9531\n",
      "Epoch 2/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3866 - acc: 0.8110 - val_loss: 0.0970 - val_acc: 0.9750\n",
      "Epoch 3/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.3246 - acc: 0.8552 - val_loss: 0.1199 - val_acc: 0.9656\n",
      "Epoch 4/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3249 - acc: 0.8447 - val_loss: 0.1065 - val_acc: 0.9625\n",
      "Epoch 5/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2836 - acc: 0.8757 - val_loss: 0.1246 - val_acc: 0.9500\n",
      "Epoch 6/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3383 - acc: 0.8407 - val_loss: 0.1194 - val_acc: 0.9812\n",
      "Epoch 7/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3286 - acc: 0.8406 - val_loss: 0.1119 - val_acc: 0.9844\n",
      "Epoch 8/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2731 - acc: 0.8728 - val_loss: 0.0865 - val_acc: 0.9812\n",
      "Epoch 9/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2902 - acc: 0.8621 - val_loss: 0.1168 - val_acc: 0.9625\n",
      "Epoch 10/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2804 - acc: 0.8810 - val_loss: 0.1147 - val_acc: 0.9656\n",
      "Epoch 11/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2827 - acc: 0.8772 - val_loss: 0.1082 - val_acc: 0.9812\n",
      "Epoch 12/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2804 - acc: 0.8795 - val_loss: 0.1154 - val_acc: 0.9594\n",
      "Epoch 13/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2884 - acc: 0.8726 - val_loss: 0.0897 - val_acc: 0.9844\n",
      "Epoch 14/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2662 - acc: 0.8827 - val_loss: 0.1306 - val_acc: 0.9500\n",
      "Epoch 15/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2789 - acc: 0.8765 - val_loss: 0.1158 - val_acc: 0.9750\n",
      "Epoch 16/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2752 - acc: 0.8696 - val_loss: 0.0927 - val_acc: 0.9844\n",
      "Epoch 17/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2775 - acc: 0.8772 - val_loss: 0.0771 - val_acc: 0.9875\n",
      "Epoch 18/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2524 - acc: 0.8932 - val_loss: 0.0921 - val_acc: 0.9875\n",
      "Epoch 19/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2635 - acc: 0.8887 - val_loss: 0.1067 - val_acc: 0.9688\n",
      "Epoch 20/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2907 - acc: 0.8690 - val_loss: 0.1240 - val_acc: 0.9688\n",
      "Epoch 21/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2569 - acc: 0.8850 - val_loss: 0.1047 - val_acc: 0.9719\n",
      "Epoch 22/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2594 - acc: 0.8857 - val_loss: 0.1004 - val_acc: 0.9656\n",
      "Epoch 23/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2352 - acc: 0.8940 - val_loss: 0.0924 - val_acc: 0.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2551 - acc: 0.8925 - val_loss: 0.1273 - val_acc: 0.9469\n",
      "Epoch 25/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2361 - acc: 0.8963 - val_loss: 0.1031 - val_acc: 0.9656\n",
      "Epoch 26/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2200 - acc: 0.9024 - val_loss: 0.1203 - val_acc: 0.9469\n",
      "Epoch 27/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2616 - acc: 0.8925 - val_loss: 0.1028 - val_acc: 0.9719\n",
      "Epoch 28/100\n",
      "41/40 [==============================] - 7s 177ms/step - loss: 0.2535 - acc: 0.8971 - val_loss: 0.1105 - val_acc: 0.9719\n",
      "Epoch 29/100\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.2495 - acc: 0.8948 - val_loss: 0.1059 - val_acc: 0.9750\n",
      "Epoch 30/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2588 - acc: 0.9025 - val_loss: 0.1069 - val_acc: 0.9719\n",
      "Epoch 31/100\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.2449 - acc: 0.8972 - val_loss: 0.0891 - val_acc: 0.9812\n",
      "Epoch 32/100\n",
      "41/40 [==============================] - 7s 162ms/step - loss: 0.2409 - acc: 0.9077 - val_loss: 0.0840 - val_acc: 0.9781\n",
      "Epoch 33/100\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2454 - acc: 0.8972 - val_loss: 0.1247 - val_acc: 0.9719\n",
      "Epoch 34/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2368 - acc: 0.8986 - val_loss: 0.0929 - val_acc: 0.9688\n",
      "Epoch 35/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2552 - acc: 0.9024 - val_loss: 0.0913 - val_acc: 0.9688\n",
      "Epoch 36/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2166 - acc: 0.9039 - val_loss: 0.1037 - val_acc: 0.9625\n",
      "Epoch 37/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2424 - acc: 0.8932 - val_loss: 0.1185 - val_acc: 0.9656\n",
      "Epoch 38/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2346 - acc: 0.9093 - val_loss: 0.1036 - val_acc: 0.9656\n",
      "Epoch 39/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2372 - acc: 0.8888 - val_loss: 0.1137 - val_acc: 0.9563\n",
      "Epoch 40/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2487 - acc: 0.8986 - val_loss: 0.1186 - val_acc: 0.9656\n",
      "Epoch 41/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2300 - acc: 0.9010 - val_loss: 0.1130 - val_acc: 0.9656\n",
      "Epoch 42/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2176 - acc: 0.9047 - val_loss: 0.0925 - val_acc: 0.9750\n",
      "Epoch 43/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2296 - acc: 0.9001 - val_loss: 0.0943 - val_acc: 0.9844\n",
      "Epoch 44/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2486 - acc: 0.8941 - val_loss: 0.0929 - val_acc: 0.9719\n",
      "Epoch 45/100\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.2336 - acc: 0.8972 - val_loss: 0.0945 - val_acc: 0.9781\n",
      "Epoch 46/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2315 - acc: 0.8972 - val_loss: 0.1028 - val_acc: 0.9719\n",
      "Epoch 47/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2163 - acc: 0.9138 - val_loss: 0.1163 - val_acc: 0.9625\n",
      "Epoch 48/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2250 - acc: 0.9002 - val_loss: 0.1031 - val_acc: 0.9656\n",
      "Epoch 49/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2354 - acc: 0.8971 - val_loss: 0.1223 - val_acc: 0.9563\n",
      "Epoch 50/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2510 - acc: 0.8880 - val_loss: 0.1270 - val_acc: 0.9625\n",
      "Epoch 51/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2330 - acc: 0.9016 - val_loss: 0.1281 - val_acc: 0.9531\n",
      "Epoch 52/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2322 - acc: 0.9047 - val_loss: 0.1051 - val_acc: 0.9719\n",
      "Epoch 53/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2322 - acc: 0.8963 - val_loss: 0.1328 - val_acc: 0.9563\n",
      "Epoch 54/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2152 - acc: 0.9138 - val_loss: 0.1173 - val_acc: 0.9688\n",
      "Epoch 55/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2245 - acc: 0.8986 - val_loss: 0.1390 - val_acc: 0.9469\n",
      "Epoch 56/100\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2027 - acc: 0.9154 - val_loss: 0.1079 - val_acc: 0.9688\n",
      "Epoch 57/100\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2141 - acc: 0.9131 - val_loss: 0.1153 - val_acc: 0.9625\n",
      "Epoch 58/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2444 - acc: 0.8873 - val_loss: 0.1231 - val_acc: 0.9531\n",
      "Epoch 59/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2320 - acc: 0.9024 - val_loss: 0.1164 - val_acc: 0.9750\n",
      "Epoch 60/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1996 - acc: 0.9108 - val_loss: 0.0907 - val_acc: 0.9750\n",
      "Epoch 61/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2579 - acc: 0.8866 - val_loss: 0.1230 - val_acc: 0.9625\n",
      "Epoch 62/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2270 - acc: 0.9002 - val_loss: 0.1271 - val_acc: 0.9469\n",
      "Epoch 63/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2098 - acc: 0.9010 - val_loss: 0.1109 - val_acc: 0.9594\n",
      "Epoch 64/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2205 - acc: 0.9085 - val_loss: 0.1169 - val_acc: 0.9563\n",
      "Epoch 65/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2055 - acc: 0.9146 - val_loss: 0.1202 - val_acc: 0.9531\n",
      "Epoch 66/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2320 - acc: 0.9047 - val_loss: 0.1178 - val_acc: 0.9656\n",
      "Epoch 67/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2089 - acc: 0.9085 - val_loss: 0.1136 - val_acc: 0.9625\n",
      "Epoch 68/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2140 - acc: 0.9100 - val_loss: 0.0976 - val_acc: 0.9750\n",
      "Epoch 69/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2197 - acc: 0.9039 - val_loss: 0.1207 - val_acc: 0.9625\n",
      "Epoch 70/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2266 - acc: 0.9018 - val_loss: 0.1264 - val_acc: 0.9594\n",
      "Epoch 71/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2120 - acc: 0.9131 - val_loss: 0.1381 - val_acc: 0.9531\n",
      "Epoch 72/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2347 - acc: 0.9025 - val_loss: 0.1244 - val_acc: 0.9625\n",
      "Epoch 73/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2198 - acc: 0.9047 - val_loss: 0.1084 - val_acc: 0.9656\n",
      "Epoch 74/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2401 - acc: 0.8996 - val_loss: 0.1402 - val_acc: 0.9531\n",
      "Epoch 75/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2093 - acc: 0.9184 - val_loss: 0.1048 - val_acc: 0.9656\n",
      "Epoch 76/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2211 - acc: 0.8979 - val_loss: 0.1556 - val_acc: 0.9406\n",
      "Epoch 77/100\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.2156 - acc: 0.9019 - val_loss: 0.1084 - val_acc: 0.9625\n",
      "Epoch 78/100\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2276 - acc: 0.8920 - val_loss: 0.1486 - val_acc: 0.9437\n",
      "Epoch 79/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2411 - acc: 0.8798 - val_loss: 0.1163 - val_acc: 0.9531\n",
      "Epoch 80/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1946 - acc: 0.9161 - val_loss: 0.1082 - val_acc: 0.9563\n",
      "Epoch 81/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2001 - acc: 0.9138 - val_loss: 0.1056 - val_acc: 0.9656\n",
      "Epoch 82/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1987 - acc: 0.9024 - val_loss: 0.1107 - val_acc: 0.9531\n",
      "Epoch 83/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2135 - acc: 0.9016 - val_loss: 0.1161 - val_acc: 0.9594\n",
      "Epoch 84/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1983 - acc: 0.9131 - val_loss: 0.0996 - val_acc: 0.9563\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2113 - acc: 0.9063 - val_loss: 0.1703 - val_acc: 0.9375\n",
      "Epoch 86/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2296 - acc: 0.8918 - val_loss: 0.1179 - val_acc: 0.9563\n",
      "Epoch 87/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2083 - acc: 0.9138 - val_loss: 0.1333 - val_acc: 0.9625\n",
      "Epoch 88/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2179 - acc: 0.9077 - val_loss: 0.1149 - val_acc: 0.9656\n",
      "Epoch 89/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2193 - acc: 0.8949 - val_loss: 0.1346 - val_acc: 0.9656\n",
      "Epoch 90/100\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1967 - acc: 0.9237 - val_loss: 0.1048 - val_acc: 0.9656\n",
      "Epoch 91/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2218 - acc: 0.9004 - val_loss: 0.1403 - val_acc: 0.9500\n",
      "Epoch 92/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2099 - acc: 0.9054 - val_loss: 0.1155 - val_acc: 0.9688\n",
      "Epoch 93/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2003 - acc: 0.9085 - val_loss: 0.1206 - val_acc: 0.9625\n",
      "Epoch 94/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2042 - acc: 0.9162 - val_loss: 0.1064 - val_acc: 0.9656\n",
      "Epoch 95/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2213 - acc: 0.9039 - val_loss: 0.1316 - val_acc: 0.9469\n",
      "Epoch 96/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2050 - acc: 0.9146 - val_loss: 0.1139 - val_acc: 0.9625\n",
      "Epoch 97/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1887 - acc: 0.9215 - val_loss: 0.1343 - val_acc: 0.9469\n",
      "Epoch 98/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2534 - acc: 0.8987 - val_loss: 0.1301 - val_acc: 0.9594\n",
      "Epoch 99/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1993 - acc: 0.9192 - val_loss: 0.1116 - val_acc: 0.9625\n",
      "Epoch 100/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2068 - acc: 0.9138 - val_loss: 0.1097 - val_acc: 0.9656\n",
      "320/320 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "41/40 [==============================] - 10s 232ms/step - loss: 0.5502 - acc: 0.8354 - val_loss: 0.1349 - val_acc: 0.9406\n",
      "Epoch 2/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3809 - acc: 0.8589 - val_loss: 0.1464 - val_acc: 0.9563\n",
      "Epoch 3/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3782 - acc: 0.8194 - val_loss: 0.1387 - val_acc: 0.9750\n",
      "Epoch 4/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3307 - acc: 0.8485 - val_loss: 0.1424 - val_acc: 0.9563\n",
      "Epoch 5/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3269 - acc: 0.8627 - val_loss: 0.1354 - val_acc: 0.9594\n",
      "Epoch 6/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3176 - acc: 0.8552 - val_loss: 0.1191 - val_acc: 0.9750\n",
      "Epoch 7/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2698 - acc: 0.8833 - val_loss: 0.1028 - val_acc: 0.9656\n",
      "Epoch 8/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2819 - acc: 0.8871 - val_loss: 0.1289 - val_acc: 0.9563\n",
      "Epoch 9/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2877 - acc: 0.8810 - val_loss: 0.1355 - val_acc: 0.9625\n",
      "Epoch 10/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2602 - acc: 0.8810 - val_loss: 0.0955 - val_acc: 0.9719\n",
      "Epoch 11/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2597 - acc: 0.8871 - val_loss: 0.1111 - val_acc: 0.9719\n",
      "Epoch 12/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2945 - acc: 0.8781 - val_loss: 0.1604 - val_acc: 0.9563\n",
      "Epoch 13/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2797 - acc: 0.8835 - val_loss: 0.0781 - val_acc: 0.9938\n",
      "Epoch 14/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2528 - acc: 0.8940 - val_loss: 0.1223 - val_acc: 0.9563\n",
      "Epoch 15/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2394 - acc: 0.8934 - val_loss: 0.1530 - val_acc: 0.9375\n",
      "Epoch 16/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2676 - acc: 0.8706 - val_loss: 0.1194 - val_acc: 0.9594\n",
      "Epoch 17/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2780 - acc: 0.8841 - val_loss: 0.1071 - val_acc: 0.9844\n",
      "Epoch 18/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2534 - acc: 0.8812 - val_loss: 0.0978 - val_acc: 0.9656\n",
      "Epoch 19/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2526 - acc: 0.8865 - val_loss: 0.1127 - val_acc: 0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "41/40 [==============================] - 6s 151ms/step - loss: 0.2341 - acc: 0.9032 - val_loss: 0.1047 - val_acc: 0.9688\n",
      "Epoch 21/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2226 - acc: 0.9039 - val_loss: 0.1025 - val_acc: 0.9719\n",
      "Epoch 22/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2638 - acc: 0.8955 - val_loss: 0.1461 - val_acc: 0.9531\n",
      "Epoch 23/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2400 - acc: 0.9054 - val_loss: 0.1083 - val_acc: 0.9719\n",
      "Epoch 24/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2465 - acc: 0.9054 - val_loss: 0.1164 - val_acc: 0.9719\n",
      "Epoch 25/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2434 - acc: 0.9001 - val_loss: 0.1317 - val_acc: 0.9594\n",
      "Epoch 26/100\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.2290 - acc: 0.8971 - val_loss: 0.1227 - val_acc: 0.9500\n",
      "Epoch 27/100\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2628 - acc: 0.8918 - val_loss: 0.2314 - val_acc: 0.9187\n",
      "Epoch 28/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2462 - acc: 0.8978 - val_loss: 0.1127 - val_acc: 0.9719\n",
      "Epoch 29/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2646 - acc: 0.8752 - val_loss: 0.1349 - val_acc: 0.9563\n",
      "Epoch 30/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2081 - acc: 0.9154 - val_loss: 0.1076 - val_acc: 0.9656\n",
      "Epoch 31/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2468 - acc: 0.8934 - val_loss: 0.1401 - val_acc: 0.9469\n",
      "Epoch 32/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2463 - acc: 0.8879 - val_loss: 0.1941 - val_acc: 0.9187\n",
      "Epoch 33/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2433 - acc: 0.8963 - val_loss: 0.1111 - val_acc: 0.9656\n",
      "Epoch 34/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2283 - acc: 0.9009 - val_loss: 0.0867 - val_acc: 0.9812\n",
      "Epoch 35/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2508 - acc: 0.8978 - val_loss: 0.1145 - val_acc: 0.9688\n",
      "Epoch 36/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2427 - acc: 0.8963 - val_loss: 0.1087 - val_acc: 0.9625\n",
      "Epoch 37/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2218 - acc: 0.9010 - val_loss: 0.1090 - val_acc: 0.9750\n",
      "Epoch 38/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2184 - acc: 0.9039 - val_loss: 0.1435 - val_acc: 0.9375\n",
      "Epoch 39/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2103 - acc: 0.9184 - val_loss: 0.1515 - val_acc: 0.9406\n",
      "Epoch 40/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2362 - acc: 0.9016 - val_loss: 0.1054 - val_acc: 0.9750\n",
      "Epoch 41/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2310 - acc: 0.9093 - val_loss: 0.1252 - val_acc: 0.9656\n",
      "Epoch 42/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2341 - acc: 0.9054 - val_loss: 0.1069 - val_acc: 0.9656\n",
      "Epoch 43/100\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.2361 - acc: 0.9077 - val_loss: 0.1109 - val_acc: 0.9656\n",
      "Epoch 44/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2417 - acc: 0.8993 - val_loss: 0.1694 - val_acc: 0.9437\n",
      "Epoch 45/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2272 - acc: 0.9085 - val_loss: 0.0921 - val_acc: 0.9875\n",
      "Epoch 46/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2190 - acc: 0.9154 - val_loss: 0.0955 - val_acc: 0.9781\n",
      "Epoch 47/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2094 - acc: 0.9176 - val_loss: 0.0826 - val_acc: 0.9875\n",
      "Epoch 48/100\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2618 - acc: 0.9040 - val_loss: 0.1054 - val_acc: 0.9719\n",
      "Epoch 49/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2188 - acc: 0.9085 - val_loss: 0.1128 - val_acc: 0.9750\n",
      "Epoch 50/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2272 - acc: 0.9047 - val_loss: 0.1341 - val_acc: 0.9594\n",
      "Epoch 51/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2216 - acc: 0.9039 - val_loss: 0.1727 - val_acc: 0.9125\n",
      "Epoch 52/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2341 - acc: 0.9024 - val_loss: 0.1240 - val_acc: 0.9563\n",
      "Epoch 53/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2005 - acc: 0.9176 - val_loss: 0.1277 - val_acc: 0.9469\n",
      "Epoch 54/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2335 - acc: 0.8964 - val_loss: 0.1244 - val_acc: 0.9656\n",
      "Epoch 55/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2170 - acc: 0.9016 - val_loss: 0.0962 - val_acc: 0.9812\n",
      "Epoch 56/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2249 - acc: 0.9024 - val_loss: 0.1105 - val_acc: 0.9531\n",
      "Epoch 57/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2124 - acc: 0.9093 - val_loss: 0.0981 - val_acc: 0.9594\n",
      "Epoch 58/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2303 - acc: 0.9018 - val_loss: 0.1316 - val_acc: 0.9531\n",
      "Epoch 59/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2146 - acc: 0.9077 - val_loss: 0.1002 - val_acc: 0.9688\n",
      "Epoch 60/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2112 - acc: 0.9115 - val_loss: 0.1324 - val_acc: 0.9563\n",
      "Epoch 61/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2254 - acc: 0.9040 - val_loss: 0.1111 - val_acc: 0.9656\n",
      "Epoch 62/100\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2099 - acc: 0.9054 - val_loss: 0.1215 - val_acc: 0.9688\n",
      "Epoch 63/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2191 - acc: 0.9117 - val_loss: 0.1097 - val_acc: 0.9688\n",
      "Epoch 64/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2109 - acc: 0.9094 - val_loss: 0.1150 - val_acc: 0.9594\n",
      "Epoch 65/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2178 - acc: 0.9047 - val_loss: 0.1141 - val_acc: 0.9719\n",
      "Epoch 66/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1847 - acc: 0.9245 - val_loss: 0.1164 - val_acc: 0.9563\n",
      "Epoch 67/100\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2094 - acc: 0.9093 - val_loss: 0.1373 - val_acc: 0.9469\n",
      "Epoch 68/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2185 - acc: 0.9086 - val_loss: 0.1765 - val_acc: 0.9344\n",
      "Epoch 69/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2373 - acc: 0.9025 - val_loss: 0.1510 - val_acc: 0.9531\n",
      "Epoch 70/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1982 - acc: 0.9245 - val_loss: 0.1398 - val_acc: 0.9469\n",
      "Epoch 71/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2242 - acc: 0.9010 - val_loss: 0.1354 - val_acc: 0.9500\n",
      "Epoch 72/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2187 - acc: 0.9079 - val_loss: 0.1107 - val_acc: 0.9688\n",
      "Epoch 73/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2061 - acc: 0.9115 - val_loss: 0.1090 - val_acc: 0.9563\n",
      "Epoch 74/100\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1990 - acc: 0.9169 - val_loss: 0.1064 - val_acc: 0.9781\n",
      "Epoch 75/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2211 - acc: 0.9010 - val_loss: 0.1521 - val_acc: 0.9375\n",
      "Epoch 76/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2092 - acc: 0.9109 - val_loss: 0.1018 - val_acc: 0.9656\n",
      "Epoch 77/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1928 - acc: 0.9199 - val_loss: 0.1317 - val_acc: 0.9531\n",
      "Epoch 78/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2090 - acc: 0.9138 - val_loss: 0.1327 - val_acc: 0.9563\n",
      "Epoch 79/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2205 - acc: 0.9009 - val_loss: 0.1397 - val_acc: 0.9531\n",
      "Epoch 80/100\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1992 - acc: 0.9237 - val_loss: 0.1169 - val_acc: 0.9563\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1969 - acc: 0.9199 - val_loss: 0.1106 - val_acc: 0.9625\n",
      "Epoch 82/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2164 - acc: 0.9124 - val_loss: 0.1352 - val_acc: 0.9531\n",
      "Epoch 83/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2080 - acc: 0.9108 - val_loss: 0.1436 - val_acc: 0.9437\n",
      "Epoch 84/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2135 - acc: 0.9123 - val_loss: 0.1208 - val_acc: 0.9625\n",
      "Epoch 85/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2139 - acc: 0.9109 - val_loss: 0.1367 - val_acc: 0.9531\n",
      "Epoch 86/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2134 - acc: 0.9100 - val_loss: 0.1604 - val_acc: 0.9531\n",
      "Epoch 87/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2021 - acc: 0.9231 - val_loss: 0.1066 - val_acc: 0.9531\n",
      "Epoch 88/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2057 - acc: 0.9237 - val_loss: 0.1462 - val_acc: 0.9594\n",
      "Epoch 89/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1996 - acc: 0.9162 - val_loss: 0.1269 - val_acc: 0.9594\n",
      "Epoch 90/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2196 - acc: 0.9170 - val_loss: 0.1558 - val_acc: 0.9344\n",
      "Epoch 91/100\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.1940 - acc: 0.9207 - val_loss: 0.1484 - val_acc: 0.9406\n",
      "Epoch 92/100\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2075 - acc: 0.9155 - val_loss: 0.1498 - val_acc: 0.9437\n",
      "Epoch 93/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2004 - acc: 0.9094 - val_loss: 0.1472 - val_acc: 0.9406\n",
      "Epoch 94/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1872 - acc: 0.9222 - val_loss: 0.1437 - val_acc: 0.9406\n",
      "Epoch 95/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2124 - acc: 0.9079 - val_loss: 0.2161 - val_acc: 0.9219\n",
      "Epoch 96/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2043 - acc: 0.9115 - val_loss: 0.1426 - val_acc: 0.9469\n",
      "Epoch 97/100\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2141 - acc: 0.9063 - val_loss: 0.1465 - val_acc: 0.9250\n",
      "Epoch 98/100\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1750 - acc: 0.9337 - val_loss: 0.1085 - val_acc: 0.9656\n",
      "Epoch 99/100\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1816 - acc: 0.9268 - val_loss: 0.1072 - val_acc: 0.9688\n",
      "Epoch 100/100\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1784 - acc: 0.9237 - val_loss: 0.1034 - val_acc: 0.9688\n",
      "320/320 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "Train_cv = StratifiedKFold(n_splits=5,shuffle = True,random_state=2).split(X_train,target_train)\n",
    "cv_val_list = []\n",
    "for i,masks in enumerate(Train_cv):\n",
    "    train_mask,valid_mask = masks\n",
    "    X_train_cv = X_train[train_mask]\n",
    "    y_train_cv = target_train[train_mask]\n",
    "    X_valid = X_train[valid_mask]\n",
    "    y_valid = target_train[valid_mask]\n",
    "    path = 'model save/Model 2-Advanced CNN with local TL,DA and CV5/'\n",
    "    modelseries = '.cv'+str(i+1)+'.hdf5'\n",
    "    modelpath = os.path.join(path,modelseries)\n",
    "    Cnnmodel=cnnmodel(input_shape = (75,75,3),lr = 0.0001)\n",
    "    Cnnmodel.load_weights('model save/Model 2-Advanced CNN with local TL,DA and CV5/TL source.hdf5')\n",
    "    result_Cnn = fitmodel(Cnnmodel,X_train_cv,y_train_cv,X_valid,y_valid,augment = True,epochs = 100,batch_size = 32,filepath = modelpath)\n",
    "    historyseries = 'cv'+str(i+1)+'.csv'\n",
    "    save_history(result_Cnn,name = historyseries,path = path)\n",
    "    Cnnmodel.load_weights(filepath=modelpath)\n",
    "    score = Cnnmodel.evaluate(X_valid, y_valid, verbose=1)\n",
    "    cv_val_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.14604590879464002, 0.92546583850931674],\n",
       " [0.14806677773304724, 0.9190031152647975],\n",
       " [0.10787337619196218, 0.96573208722741433],\n",
       " [0.10974582657217979, 0.96562499999999996],\n",
       " [0.10343162231147289, 0.96875]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('fit_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cv1.csv'\n",
    "path ='model save/Model 1-Advanced CNN with DA and CV5/'\n",
    "test.to_csv(os.path.join(path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
