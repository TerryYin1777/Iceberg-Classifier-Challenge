{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from subprocess import check_output\n",
    "#print(check_output([\"ls\", \"../input/\"]))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from os.path import join as opj\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, Activation,Add, ZeroPadding2D ,AveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras import initializers,regularizers\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "#K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_json(\"input/train.json\")\n",
    "#test = pd.read_json(\"input/test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_band_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "X_band_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "X_train = np.concatenate([X_band_1[:, :, :, np.newaxis], X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], axis=-1)\n",
    "target_train=train['is_iceberg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_band_test_1=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\n",
    "X_band_test_2=np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n",
    "X_test = np.concatenate([X_band_test_1[:, :, :, np.newaxis], X_band_test_2[:, :, :, np.newaxis], ((X_band_test_1+X_band_test_2)/2)[:, :, :, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_cv, X_valid, y_train_cv, y_valid = train_test_split(X_train, target_train, random_state=2,stratify = target_train, train_size=0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation(X_input,Y_input,batch_size = 32):\n",
    "    data_aug = ImageDataGenerator(#featurewise_center=True,\n",
    "                             #featurewise_std_normalization=True,\n",
    "                             #zca_whitening=True,\n",
    "                             rotation_range=0,\n",
    "                             width_shift_range = 0,\n",
    "                             height_shift_range = 0,\n",
    "                             zoom_range = 0,\n",
    "                             data_format = 'channels_last',\n",
    "                             horizontal_flip = True,\n",
    "                             vertical_flip = True)#,fill_mode = 'constant',cval = 0)\n",
    "    data_aug_batches = data_aug.flow(X_input,Y_input,batch_size = batch_size)\n",
    "    return data_aug_batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cbamd_layer(X_input,filter_num =64,kernel_size = (3,3),conv_padding = 'valid',pool_size =(2,2),pool_strides = (2,2),pool_padding = 'valid',dropout_rate = 0.2):\n",
    "    X = Conv2D(filter_num, kernel_size, padding = conv_padding)(X_input)\n",
    "    #X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D(pool_size,strides = pool_strides,padding = pool_padding)(X)\n",
    "    X = Dropout(rate = dropout_rate)(X)\n",
    "    return X\n",
    "\n",
    "def dense_layer(X_input, units = 1,activation = 'relu',dropout_rate = 0.2):\n",
    "    X = Dense(units = units,activation = activation)(X_input)\n",
    "    X = Dropout(rate = dropout_rate)(X)\n",
    "    return X\n",
    "#kernel_regularizer=regularizers.l2(0.01)\n",
    "def cnnmodel(input_shape,lr = 0.0001):\n",
    "    X_input = Input(input_shape)\n",
    "    #First composite layer\n",
    "    X = basic_cbamd_layer(X_input,\n",
    "                           filter_num =64,\n",
    "                           kernel_size = (5,5),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(3,3),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Second composite layer\n",
    "    X = basic_cbamd_layer(X,\n",
    "                           filter_num =128,\n",
    "                           kernel_size = (3,3),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(3,3),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Third composite layer\n",
    "    X = basic_cbamd_layer(X,\n",
    "                           filter_num =128,\n",
    "                           kernel_size = (3,3),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(2,2),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Forth composite layer\n",
    "    X = basic_cbamd_layer(X,\n",
    "                           filter_num =64,\n",
    "                           kernel_size = (3,3),\n",
    "                           conv_padding = 'valid',\n",
    "                           pool_size =(3,3),\n",
    "                           pool_strides = (2,2),\n",
    "                           pool_padding = 'valid',\n",
    "                           dropout_rate = 0.2)\n",
    "    #Flatten layer\n",
    "    X = Flatten()(X)\n",
    "    #First dense layer\n",
    "    X = dense_layer(X, units = 256,activation = 'relu',dropout_rate = 0.2)\n",
    "    #Second dense layer\n",
    "    X = dense_layer(X, units = 128,activation = 'relu',dropout_rate = 0.2)\n",
    "    #Decision layer\n",
    "    X = dense_layer(X, units = 1,activation = 'sigmoid',dropout_rate = 0)\n",
    "    \n",
    "    model = Model(inputs=X_input,outputs=X)\n",
    "    optimizer=Adam(lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    #optimizer = SGD(lr, decay=0, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def get_callbacks(filepath = \".model_weights.hdf5\", patience=7):\n",
    "    #es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [msave]\n",
    "\n",
    "#callbacks = get_callbacks(filepath=file_path, patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Cnnmodel=cnnmodel(input_shape = (75,75,3),lr = 0.0001)\n",
    "def fitmodel(model,X_train,y_train,X_valid,y_valid,augment = False,epochs = 50,batch_size = 32,filepath = \".model_weights.hdf5\"):\n",
    "    if augment == False:\n",
    "        result = model.fit(X_train, y_train,\n",
    "                          batch_size=batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=get_callbacks(filepath))\n",
    "    else:\n",
    "        result = model.fit_generator(data_augmentation(X_train,y_train,batch_size = batch_size),\n",
    "                          steps_per_epoch = len(X_train_cv)/batch_size,\n",
    "                          epochs=epochs,\n",
    "                          verbose=1,\n",
    "                          validation_data=(X_valid, y_valid),\n",
    "                          callbacks=get_callbacks(filepath))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv2d_9\n",
      "2 activation_9\n",
      "3 max_pooling2d_9\n",
      "4 dropout_15\n",
      "5 conv2d_10\n",
      "6 activation_10\n",
      "7 max_pooling2d_10\n",
      "8 dropout_16\n",
      "9 conv2d_11\n",
      "10 activation_11\n",
      "11 max_pooling2d_11\n",
      "12 dropout_17\n",
      "13 conv2d_12\n",
      "14 activation_12\n",
      "15 max_pooling2d_12\n",
      "16 dropout_18\n",
      "17 flatten_3\n",
      "18 dense_7\n",
      "19 dropout_19\n",
      "20 dense_8\n",
      "21 dropout_20\n",
      "22 dense_9\n",
      "23 dropout_21\n"
     ]
    }
   ],
   "source": [
    "for i,layer in enumerate(Cnnmodel.layers):\n",
    "    print(i,layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 699,009\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 300,096\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2740 - acc: 0.8688 - val_loss: 0.2555 - val_acc: 0.9003\n",
      "Epoch 2/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2831 - acc: 0.8677 - val_loss: 0.2313 - val_acc: 0.8972\n",
      "Epoch 3/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2551 - acc: 0.8970 - val_loss: 0.2525 - val_acc: 0.8910\n",
      "Epoch 4/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2875 - acc: 0.8578 - val_loss: 0.2784 - val_acc: 0.8629\n",
      "Epoch 5/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2568 - acc: 0.8902 - val_loss: 0.2429 - val_acc: 0.9003\n",
      "Epoch 6/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2283 - acc: 0.8925 - val_loss: 0.2782 - val_acc: 0.8629\n",
      "Epoch 7/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2432 - acc: 0.8960 - val_loss: 0.2509 - val_acc: 0.8785\n",
      "Epoch 8/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2301 - acc: 0.9085 - val_loss: 0.2716 - val_acc: 0.8847\n",
      "Epoch 9/200\n",
      "41/40 [==============================] - 6s 150ms/step - loss: 0.2465 - acc: 0.8986 - val_loss: 0.2332 - val_acc: 0.9034\n",
      "Epoch 10/200\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2288 - acc: 0.8993 - val_loss: 0.2161 - val_acc: 0.9065\n",
      "Epoch 11/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2306 - acc: 0.9031 - val_loss: 0.2184 - val_acc: 0.8972\n",
      "Epoch 12/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2470 - acc: 0.8838 - val_loss: 0.2538 - val_acc: 0.8723\n",
      "Epoch 13/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2472 - acc: 0.8921 - val_loss: 0.2828 - val_acc: 0.8723\n",
      "Epoch 14/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2550 - acc: 0.8754 - val_loss: 0.2123 - val_acc: 0.8972\n",
      "Epoch 15/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2176 - acc: 0.9077 - val_loss: 0.2339 - val_acc: 0.8972\n",
      "Epoch 16/200\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2214 - acc: 0.9161 - val_loss: 0.2429 - val_acc: 0.9003\n",
      "Epoch 17/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2616 - acc: 0.8792 - val_loss: 0.2822 - val_acc: 0.8785\n",
      "Epoch 18/200\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.2298 - acc: 0.9024 - val_loss: 0.2249 - val_acc: 0.9003\n",
      "Epoch 19/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2092 - acc: 0.9123 - val_loss: 0.2504 - val_acc: 0.8941\n",
      "Epoch 20/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2089 - acc: 0.9062 - val_loss: 0.2041 - val_acc: 0.9097\n",
      "Epoch 21/200\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2080 - acc: 0.9085 - val_loss: 0.2180 - val_acc: 0.9034\n",
      "Epoch 22/200\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.2050 - acc: 0.9024 - val_loss: 0.2304 - val_acc: 0.8972\n",
      "Epoch 23/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1893 - acc: 0.9161 - val_loss: 0.2132 - val_acc: 0.9065\n",
      "Epoch 24/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2099 - acc: 0.9146 - val_loss: 0.2239 - val_acc: 0.8972\n",
      "Epoch 25/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2236 - acc: 0.9013 - val_loss: 0.2231 - val_acc: 0.8972\n",
      "Epoch 26/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2079 - acc: 0.9028 - val_loss: 0.2733 - val_acc: 0.8567\n",
      "Epoch 27/200\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2505 - acc: 0.8841 - val_loss: 0.2198 - val_acc: 0.8941\n",
      "Epoch 28/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2148 - acc: 0.8987 - val_loss: 0.2215 - val_acc: 0.8941\n",
      "Epoch 29/200\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.2131 - acc: 0.9013 - val_loss: 0.2200 - val_acc: 0.9097\n",
      "Epoch 30/200\n",
      "41/40 [==============================] - 6s 152ms/step - loss: 0.1960 - acc: 0.9192 - val_loss: 0.2249 - val_acc: 0.9034\n",
      "Epoch 31/200\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1970 - acc: 0.9154 - val_loss: 0.2479 - val_acc: 0.8816\n",
      "Epoch 32/200\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2393 - acc: 0.9082 - val_loss: 0.2362 - val_acc: 0.9065\n",
      "Epoch 33/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2028 - acc: 0.9199 - val_loss: 0.2169 - val_acc: 0.9128\n",
      "Epoch 34/200\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1843 - acc: 0.9104 - val_loss: 0.2329 - val_acc: 0.9034\n",
      "Epoch 35/200\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.1952 - acc: 0.9169 - val_loss: 0.2261 - val_acc: 0.8941\n",
      "Epoch 36/200\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2003 - acc: 0.9176 - val_loss: 0.2207 - val_acc: 0.9003\n",
      "Epoch 37/200\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1834 - acc: 0.9199 - val_loss: 0.2044 - val_acc: 0.9097\n",
      "Epoch 38/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1929 - acc: 0.9207 - val_loss: 0.2180 - val_acc: 0.9034\n",
      "Epoch 39/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1885 - acc: 0.9222 - val_loss: 0.2113 - val_acc: 0.9159\n",
      "Epoch 40/200\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.2142 - acc: 0.9036 - val_loss: 0.2125 - val_acc: 0.9159\n",
      "Epoch 41/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1866 - acc: 0.9314 - val_loss: 0.2381 - val_acc: 0.9065\n",
      "Epoch 42/200\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1864 - acc: 0.9150 - val_loss: 0.2253 - val_acc: 0.9159\n",
      "Epoch 43/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2083 - acc: 0.9036 - val_loss: 0.2433 - val_acc: 0.9034\n",
      "Epoch 44/200\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2008 - acc: 0.9082 - val_loss: 0.2105 - val_acc: 0.9190\n",
      "Epoch 45/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1775 - acc: 0.9230 - val_loss: 0.2252 - val_acc: 0.8972\n",
      "Epoch 46/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1745 - acc: 0.9291 - val_loss: 0.2068 - val_acc: 0.9190\n",
      "Epoch 47/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1789 - acc: 0.9146 - val_loss: 0.2107 - val_acc: 0.9097\n",
      "Epoch 48/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1920 - acc: 0.9112 - val_loss: 0.2810 - val_acc: 0.8660\n",
      "Epoch 49/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1950 - acc: 0.9028 - val_loss: 0.2267 - val_acc: 0.9003\n",
      "Epoch 50/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2009 - acc: 0.9066 - val_loss: 0.1907 - val_acc: 0.9128\n",
      "Epoch 51/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1827 - acc: 0.9253 - val_loss: 0.2013 - val_acc: 0.9097\n",
      "Epoch 52/200\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.1860 - acc: 0.9222 - val_loss: 0.2371 - val_acc: 0.8816\n",
      "Epoch 53/200\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.1837 - acc: 0.9192 - val_loss: 0.2149 - val_acc: 0.9221\n",
      "Epoch 54/200\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1624 - acc: 0.9283 - val_loss: 0.2120 - val_acc: 0.9190\n",
      "Epoch 55/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1774 - acc: 0.9291 - val_loss: 0.2031 - val_acc: 0.9252\n",
      "Epoch 56/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1820 - acc: 0.9237 - val_loss: 0.2089 - val_acc: 0.9190\n",
      "Epoch 57/200\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1775 - acc: 0.9283 - val_loss: 0.2198 - val_acc: 0.9034\n",
      "Epoch 58/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1841 - acc: 0.9158 - val_loss: 0.2378 - val_acc: 0.9097\n",
      "Epoch 59/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1955 - acc: 0.9204 - val_loss: 0.2045 - val_acc: 0.9283\n",
      "Epoch 60/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1788 - acc: 0.9242 - val_loss: 0.2128 - val_acc: 0.9034\n",
      "Epoch 61/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1940 - acc: 0.9127 - val_loss: 0.2140 - val_acc: 0.9128\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1759 - acc: 0.9161 - val_loss: 0.2197 - val_acc: 0.9128\n",
      "Epoch 63/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1697 - acc: 0.9306 - val_loss: 0.2115 - val_acc: 0.9221\n",
      "Epoch 64/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1757 - acc: 0.9237 - val_loss: 0.2269 - val_acc: 0.9003\n",
      "Epoch 65/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1687 - acc: 0.9321 - val_loss: 0.2113 - val_acc: 0.9159\n",
      "Epoch 66/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1709 - acc: 0.9298 - val_loss: 0.2283 - val_acc: 0.9065\n",
      "Epoch 67/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1843 - acc: 0.9115 - val_loss: 0.2236 - val_acc: 0.9097\n",
      "Epoch 68/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1868 - acc: 0.9165 - val_loss: 0.2124 - val_acc: 0.9190\n",
      "Epoch 69/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1639 - acc: 0.9306 - val_loss: 0.2073 - val_acc: 0.9190\n",
      "Epoch 70/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1664 - acc: 0.9283 - val_loss: 0.2068 - val_acc: 0.9221\n",
      "Epoch 71/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1616 - acc: 0.9329 - val_loss: 0.1989 - val_acc: 0.9283\n",
      "Epoch 72/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1657 - acc: 0.9314 - val_loss: 0.2365 - val_acc: 0.8972\n",
      "Epoch 73/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1772 - acc: 0.9253 - val_loss: 0.2181 - val_acc: 0.9065\n",
      "Epoch 74/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1643 - acc: 0.9276 - val_loss: 0.1964 - val_acc: 0.9252\n",
      "Epoch 75/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1577 - acc: 0.9314 - val_loss: 0.2196 - val_acc: 0.9097\n",
      "Epoch 76/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1813 - acc: 0.9222 - val_loss: 0.2114 - val_acc: 0.9190\n",
      "Epoch 77/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1622 - acc: 0.9306 - val_loss: 0.2132 - val_acc: 0.9221\n",
      "Epoch 78/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1618 - acc: 0.9329 - val_loss: 0.2338 - val_acc: 0.8941\n",
      "Epoch 79/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1722 - acc: 0.9230 - val_loss: 0.1989 - val_acc: 0.9159\n",
      "Epoch 80/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1761 - acc: 0.9253 - val_loss: 0.2155 - val_acc: 0.9190\n",
      "Epoch 81/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1625 - acc: 0.9306 - val_loss: 0.1981 - val_acc: 0.9283\n",
      "Epoch 82/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1729 - acc: 0.9222 - val_loss: 0.2276 - val_acc: 0.8941\n",
      "Epoch 83/200\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1650 - acc: 0.9337 - val_loss: 0.2164 - val_acc: 0.9190\n",
      "Epoch 84/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1489 - acc: 0.9405 - val_loss: 0.1996 - val_acc: 0.9283\n",
      "Epoch 85/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1674 - acc: 0.9268 - val_loss: 0.2607 - val_acc: 0.8941\n",
      "Epoch 86/200\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.1623 - acc: 0.9306 - val_loss: 0.2229 - val_acc: 0.9252\n",
      "Epoch 87/200\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1590 - acc: 0.9375 - val_loss: 0.1918 - val_acc: 0.9315\n",
      "Epoch 88/200\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.1519 - acc: 0.9306 - val_loss: 0.1960 - val_acc: 0.9283\n",
      "Epoch 89/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1463 - acc: 0.9375 - val_loss: 0.2611 - val_acc: 0.9034\n",
      "Epoch 90/200\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2760 - acc: 0.8998 - val_loss: 0.3389 - val_acc: 0.8411\n",
      "Epoch 91/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2421 - acc: 0.8838 - val_loss: 0.2433 - val_acc: 0.9034\n",
      "Epoch 92/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1908 - acc: 0.9207 - val_loss: 0.2297 - val_acc: 0.9190\n",
      "Epoch 93/200\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1577 - acc: 0.9291 - val_loss: 0.2389 - val_acc: 0.8941\n",
      "Epoch 94/200\n",
      "41/40 [==============================] - 7s 164ms/step - loss: 0.1636 - acc: 0.9283 - val_loss: 0.2285 - val_acc: 0.9097\n",
      "Epoch 95/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1501 - acc: 0.9428 - val_loss: 0.2077 - val_acc: 0.9315\n",
      "Epoch 96/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1530 - acc: 0.9428 - val_loss: 0.2069 - val_acc: 0.9283\n",
      "Epoch 97/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1644 - acc: 0.9276 - val_loss: 0.2203 - val_acc: 0.9128\n",
      "Epoch 98/200\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.1572 - acc: 0.9298 - val_loss: 0.2142 - val_acc: 0.9221\n",
      "Epoch 99/200\n",
      "41/40 [==============================] - 6s 151ms/step - loss: 0.1402 - acc: 0.9413 - val_loss: 0.2121 - val_acc: 0.9252\n",
      "Epoch 100/200\n",
      "41/40 [==============================] - 6s 152ms/step - loss: 0.1415 - acc: 0.9375 - val_loss: 0.2159 - val_acc: 0.9252\n",
      "Epoch 101/200\n",
      "41/40 [==============================] - 7s 160ms/step - loss: 0.1497 - acc: 0.9375 - val_loss: 0.2208 - val_acc: 0.9097\n",
      "Epoch 102/200\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.1661 - acc: 0.9265 - val_loss: 0.2066 - val_acc: 0.9315\n",
      "Epoch 103/200\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1376 - acc: 0.9390 - val_loss: 0.2221 - val_acc: 0.9315\n",
      "Epoch 104/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1385 - acc: 0.9459 - val_loss: 0.2131 - val_acc: 0.9190\n",
      "Epoch 105/200\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.1543 - acc: 0.9382 - val_loss: 0.2274 - val_acc: 0.9159\n",
      "Epoch 106/200\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.1692 - acc: 0.9204 - val_loss: 0.2465 - val_acc: 0.8816\n",
      "Epoch 107/200\n",
      "41/40 [==============================] - 7s 175ms/step - loss: 0.1704 - acc: 0.9276 - val_loss: 0.2237 - val_acc: 0.9128\n",
      "Epoch 108/200\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.1619 - acc: 0.9314 - val_loss: 0.2207 - val_acc: 0.9346\n",
      "Epoch 109/200\n",
      "41/40 [==============================] - 8s 186ms/step - loss: 0.1538 - acc: 0.9382 - val_loss: 0.2210 - val_acc: 0.9315\n",
      "Epoch 110/200\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1396 - acc: 0.9451 - val_loss: 0.2119 - val_acc: 0.9252\n",
      "Epoch 111/200\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.1314 - acc: 0.9436 - val_loss: 0.2294 - val_acc: 0.9346\n",
      "Epoch 112/200\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1462 - acc: 0.9413 - val_loss: 0.2108 - val_acc: 0.9128\n",
      "Epoch 113/200\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1465 - acc: 0.9382 - val_loss: 0.2061 - val_acc: 0.9283\n",
      "Epoch 114/200\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.1598 - acc: 0.9260 - val_loss: 0.2117 - val_acc: 0.9377\n",
      "Epoch 115/200\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1497 - acc: 0.9410 - val_loss: 0.2197 - val_acc: 0.9159\n",
      "Epoch 116/200\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1432 - acc: 0.9367 - val_loss: 0.2187 - val_acc: 0.9252\n",
      "Epoch 117/200\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1389 - acc: 0.9451 - val_loss: 0.2278 - val_acc: 0.9315\n",
      "Epoch 118/200\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1319 - acc: 0.9481 - val_loss: 0.2009 - val_acc: 0.9346\n",
      "Epoch 119/200\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.1318 - acc: 0.9364 - val_loss: 0.2121 - val_acc: 0.9377\n",
      "Epoch 120/200\n",
      "41/40 [==============================] - 6s 150ms/step - loss: 0.1495 - acc: 0.9405 - val_loss: 0.2186 - val_acc: 0.9221\n",
      "Epoch 121/200\n",
      "40/40 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-a34507944748>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mCnnmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mresult_Cnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCnnmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train_cv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maugment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'model save/Model 1-Advanced CNN with DA and CV5/2018.1.1.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-23-b83ca54c8a01>\u001b[0m in \u001b[0;36mfitmodel\u001b[1;34m(model, X_train, y_train, X_valid, y_valid, augment, epochs, batch_size, filepath)\u001b[0m\n\u001b[0;32m     14\u001b[0m                           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                           callbacks=get_callbacks(filepath))\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2142\u001b[0m                                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2143\u001b[0m                                 \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_sample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2144\u001b[1;33m                                 verbose=0)\n\u001b[0m\u001b[0;32m   2145\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2146\u001b[0m                             \u001b[0mval_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1725\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1726\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1727\u001b[1;33m                                steps=steps)\n\u001b[0m\u001b[0;32m   1728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1729\u001b[0m     def predict(self, x,\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1368\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m                 \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yltbe\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Cnnmodel.load_weights('model save/Model 1-Advanced CNN with DA and CV5/2018.1.1_local0.2069OF.hdf5')\n",
    "for layer in Cnnmodel.layers[:14]:\n",
    "    layer.trainable = False\n",
    "Cnnmodel.summary()\n",
    "result_Cnn = fitmodel(Cnnmodel,X_train_cv,y_train_cv,X_valid,y_valid,augment = True,epochs = 200,batch_size = 32,filepath = 'model save/Model 1-Advanced CNN with DA and CV5/2018.1.1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321/321 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18129999453858855, 0.94392523364485981]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cnnmodel.load_weights('model save/Model 1-Advanced CNN with DA and CV5/2018.1.1.hdf5')\n",
    "Cnnmodel.evaluate(X_valid, y_valid)\n",
    "#Cnnmodel.evaluate(X_train_cv, y_train_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_history(result,name = 'fit_history.csv',path = os.getcwd()):\n",
    "    train_loss = result.history['loss']\n",
    "    val_loss = result.history['val_loss']\n",
    "    train_accuracy = result.history['acc']\n",
    "    val_accuracy = result.history['val_acc']\n",
    "    fit_history = pd.DataFrame({'train_loss':train_loss,'val_loss':val_loss,'train_accuracy':train_accuracy,'val_accuracy':val_accuracy})\n",
    "    fit_history.to_csv(os.path.join(path,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result_Cnn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-137-0f752ee40c5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msave_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_Cnn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'result_Cnn' is not defined"
     ]
    }
   ],
   "source": [
    "save_history(result_Cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "41/40 [==============================] - 9s 213ms/step - loss: 1.2741 - acc: 0.4949 - val_loss: 0.7057 - val_acc: 0.4814\n",
      "Epoch 2/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.7580 - acc: 0.5241 - val_loss: 0.6719 - val_acc: 0.6335\n",
      "Epoch 3/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.6500 - acc: 0.5763 - val_loss: 0.6176 - val_acc: 0.6615\n",
      "Epoch 4/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.6095 - acc: 0.6116 - val_loss: 0.5818 - val_acc: 0.6677\n",
      "Epoch 5/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.5696 - acc: 0.6327 - val_loss: 0.5640 - val_acc: 0.6739\n",
      "Epoch 6/150\n",
      "41/40 [==============================] - 5s 129ms/step - loss: 0.5465 - acc: 0.6617 - val_loss: 0.5672 - val_acc: 0.6801\n",
      "Epoch 7/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.5464 - acc: 0.7018 - val_loss: 0.5427 - val_acc: 0.7081\n",
      "Epoch 8/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.5283 - acc: 0.7026 - val_loss: 0.5288 - val_acc: 0.7174\n",
      "Epoch 9/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.5189 - acc: 0.7277 - val_loss: 0.5119 - val_acc: 0.7298\n",
      "Epoch 10/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.5027 - acc: 0.7422 - val_loss: 0.4902 - val_acc: 0.7609\n",
      "Epoch 11/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4927 - acc: 0.7590 - val_loss: 0.4752 - val_acc: 0.7702\n",
      "Epoch 12/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4727 - acc: 0.7720 - val_loss: 0.4540 - val_acc: 0.7795\n",
      "Epoch 13/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.4851 - acc: 0.7700 - val_loss: 0.5760 - val_acc: 0.6522\n",
      "Epoch 14/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.4648 - acc: 0.7720 - val_loss: 0.4421 - val_acc: 0.7981\n",
      "Epoch 15/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.4228 - acc: 0.7971 - val_loss: 0.4239 - val_acc: 0.7919\n",
      "Epoch 16/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4426 - acc: 0.7791 - val_loss: 0.4488 - val_acc: 0.7826\n",
      "Epoch 17/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4066 - acc: 0.8071 - val_loss: 0.4058 - val_acc: 0.8168\n",
      "Epoch 18/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3828 - acc: 0.8223 - val_loss: 0.4123 - val_acc: 0.8075\n",
      "Epoch 19/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3762 - acc: 0.8299 - val_loss: 0.3949 - val_acc: 0.8106\n",
      "Epoch 20/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4150 - acc: 0.8086 - val_loss: 0.3900 - val_acc: 0.8354\n",
      "Epoch 21/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3914 - acc: 0.8203 - val_loss: 0.3887 - val_acc: 0.8199\n",
      "Epoch 22/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3635 - acc: 0.8376 - val_loss: 0.4030 - val_acc: 0.8292\n",
      "Epoch 23/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3918 - acc: 0.8292 - val_loss: 0.3749 - val_acc: 0.8385\n",
      "Epoch 24/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3520 - acc: 0.8460 - val_loss: 0.3646 - val_acc: 0.8292\n",
      "Epoch 25/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3442 - acc: 0.8513 - val_loss: 0.3525 - val_acc: 0.8602\n",
      "Epoch 26/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3584 - acc: 0.8368 - val_loss: 0.3585 - val_acc: 0.8509\n",
      "Epoch 27/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3386 - acc: 0.8696 - val_loss: 0.3565 - val_acc: 0.8509\n",
      "Epoch 28/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3524 - acc: 0.8437 - val_loss: 0.3442 - val_acc: 0.8665\n",
      "Epoch 29/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3440 - acc: 0.8536 - val_loss: 0.3606 - val_acc: 0.8540\n",
      "Epoch 30/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3408 - acc: 0.8429 - val_loss: 0.3545 - val_acc: 0.8354\n",
      "Epoch 31/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3392 - acc: 0.8437 - val_loss: 0.3390 - val_acc: 0.8509\n",
      "Epoch 32/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3144 - acc: 0.8582 - val_loss: 0.3577 - val_acc: 0.8168\n",
      "Epoch 33/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3327 - acc: 0.8493 - val_loss: 0.3329 - val_acc: 0.8571\n",
      "Epoch 34/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3170 - acc: 0.8589 - val_loss: 0.3456 - val_acc: 0.8354\n",
      "Epoch 35/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2999 - acc: 0.8681 - val_loss: 0.3105 - val_acc: 0.8696\n",
      "Epoch 36/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 129ms/step - loss: 0.3026 - acc: 0.8665 - val_loss: 0.3925 - val_acc: 0.8292\n",
      "Epoch 37/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3642 - acc: 0.8152 - val_loss: 0.3348 - val_acc: 0.8509\n",
      "Epoch 38/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3224 - acc: 0.8404 - val_loss: 0.3338 - val_acc: 0.8354\n",
      "Epoch 39/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2998 - acc: 0.8536 - val_loss: 0.3116 - val_acc: 0.8696\n",
      "Epoch 40/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3055 - acc: 0.8673 - val_loss: 0.3641 - val_acc: 0.8385\n",
      "Epoch 41/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.3012 - acc: 0.8566 - val_loss: 0.3435 - val_acc: 0.8354\n",
      "Epoch 42/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3143 - acc: 0.8543 - val_loss: 0.3079 - val_acc: 0.8789\n",
      "Epoch 43/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2857 - acc: 0.8749 - val_loss: 0.3036 - val_acc: 0.8540\n",
      "Epoch 44/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2953 - acc: 0.8688 - val_loss: 0.3508 - val_acc: 0.8354\n",
      "Epoch 45/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2746 - acc: 0.8711 - val_loss: 0.2992 - val_acc: 0.8696\n",
      "Epoch 46/150\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2891 - acc: 0.8749 - val_loss: 0.3079 - val_acc: 0.8602\n",
      "Epoch 47/150\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2810 - acc: 0.8726 - val_loss: 0.3272 - val_acc: 0.8385\n",
      "Epoch 48/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2803 - acc: 0.8711 - val_loss: 0.2965 - val_acc: 0.8727\n",
      "Epoch 49/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2670 - acc: 0.8803 - val_loss: 0.3085 - val_acc: 0.8571\n",
      "Epoch 50/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2832 - acc: 0.8630 - val_loss: 0.3026 - val_acc: 0.8789\n",
      "Epoch 51/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2710 - acc: 0.8803 - val_loss: 0.2975 - val_acc: 0.8571\n",
      "Epoch 52/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2568 - acc: 0.8841 - val_loss: 0.2938 - val_acc: 0.8634\n",
      "Epoch 53/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2803 - acc: 0.8711 - val_loss: 0.2918 - val_acc: 0.8665\n",
      "Epoch 54/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2510 - acc: 0.8879 - val_loss: 0.2666 - val_acc: 0.8913\n",
      "Epoch 55/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2584 - acc: 0.8848 - val_loss: 0.3224 - val_acc: 0.8323\n",
      "Epoch 56/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2688 - acc: 0.8696 - val_loss: 0.2816 - val_acc: 0.8851\n",
      "Epoch 57/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2646 - acc: 0.8848 - val_loss: 0.3049 - val_acc: 0.8634\n",
      "Epoch 58/150\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2709 - acc: 0.8798 - val_loss: 0.2730 - val_acc: 0.8758\n",
      "Epoch 59/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3027 - acc: 0.8500 - val_loss: 0.2852 - val_acc: 0.8696\n",
      "Epoch 60/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2595 - acc: 0.8783 - val_loss: 0.2729 - val_acc: 0.8820\n",
      "Epoch 61/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2760 - acc: 0.8760 - val_loss: 0.3100 - val_acc: 0.8696\n",
      "Epoch 62/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2553 - acc: 0.8848 - val_loss: 0.2956 - val_acc: 0.8789\n",
      "Epoch 63/150\n",
      "41/40 [==============================] - 5s 129ms/step - loss: 0.2738 - acc: 0.8676 - val_loss: 0.3319 - val_acc: 0.8261\n",
      "Epoch 64/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2787 - acc: 0.8841 - val_loss: 0.2961 - val_acc: 0.8789\n",
      "Epoch 65/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2837 - acc: 0.8757 - val_loss: 0.3054 - val_acc: 0.8509\n",
      "Epoch 66/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2592 - acc: 0.8749 - val_loss: 0.2765 - val_acc: 0.8758\n",
      "Epoch 67/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2399 - acc: 0.8917 - val_loss: 0.2946 - val_acc: 0.8758\n",
      "Epoch 68/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2656 - acc: 0.8714 - val_loss: 0.2876 - val_acc: 0.8696\n",
      "Epoch 69/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2434 - acc: 0.8828 - val_loss: 0.2697 - val_acc: 0.8820\n",
      "Epoch 70/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2578 - acc: 0.8887 - val_loss: 0.3565 - val_acc: 0.8137\n",
      "Epoch 71/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2416 - acc: 0.8986 - val_loss: 0.2636 - val_acc: 0.8913\n",
      "Epoch 72/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2594 - acc: 0.8767 - val_loss: 0.2875 - val_acc: 0.8696\n",
      "Epoch 73/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2300 - acc: 0.8948 - val_loss: 0.2628 - val_acc: 0.8851\n",
      "Epoch 74/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2420 - acc: 0.8986 - val_loss: 0.2609 - val_acc: 0.8758\n",
      "Epoch 75/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2671 - acc: 0.8795 - val_loss: 0.2806 - val_acc: 0.8696\n",
      "Epoch 76/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2864 - acc: 0.8737 - val_loss: 0.3256 - val_acc: 0.8634\n",
      "Epoch 77/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2675 - acc: 0.8864 - val_loss: 0.2948 - val_acc: 0.8571\n",
      "Epoch 78/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2415 - acc: 0.8940 - val_loss: 0.2741 - val_acc: 0.8913\n",
      "Epoch 79/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2352 - acc: 0.8864 - val_loss: 0.2906 - val_acc: 0.8540\n",
      "Epoch 80/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2503 - acc: 0.8894 - val_loss: 0.2742 - val_acc: 0.8820\n",
      "Epoch 81/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2245 - acc: 0.9031 - val_loss: 0.2629 - val_acc: 0.8913\n",
      "Epoch 82/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2499 - acc: 0.8917 - val_loss: 0.2549 - val_acc: 0.9037\n",
      "Epoch 83/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2606 - acc: 0.8798 - val_loss: 0.2789 - val_acc: 0.8696\n",
      "Epoch 84/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2302 - acc: 0.8925 - val_loss: 0.2609 - val_acc: 0.8851\n",
      "Epoch 85/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2154 - acc: 0.8993 - val_loss: 0.2489 - val_acc: 0.9006\n",
      "Epoch 86/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2274 - acc: 0.8996 - val_loss: 0.2587 - val_acc: 0.8913\n",
      "Epoch 87/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2384 - acc: 0.8986 - val_loss: 0.2601 - val_acc: 0.8882\n",
      "Epoch 88/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2309 - acc: 0.8935 - val_loss: 0.3414 - val_acc: 0.8230\n",
      "Epoch 89/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2869 - acc: 0.8668 - val_loss: 0.2608 - val_acc: 0.8727\n",
      "Epoch 90/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2414 - acc: 0.8902 - val_loss: 0.2516 - val_acc: 0.8913\n",
      "Epoch 91/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2220 - acc: 0.9123 - val_loss: 0.2673 - val_acc: 0.8789\n",
      "Epoch 92/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2245 - acc: 0.8993 - val_loss: 0.2753 - val_acc: 0.8913\n",
      "Epoch 93/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2397 - acc: 0.8978 - val_loss: 0.2557 - val_acc: 0.8913\n",
      "Epoch 94/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2235 - acc: 0.8966 - val_loss: 0.2587 - val_acc: 0.8975\n",
      "Epoch 95/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2193 - acc: 0.9039 - val_loss: 0.2412 - val_acc: 0.9006\n",
      "Epoch 96/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2359 - acc: 0.8767 - val_loss: 0.2497 - val_acc: 0.8975\n",
      "Epoch 97/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2093 - acc: 0.9085 - val_loss: 0.2515 - val_acc: 0.8944\n",
      "Epoch 98/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2807 - acc: 0.8737 - val_loss: 0.2698 - val_acc: 0.8789\n",
      "Epoch 99/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2251 - acc: 0.9070 - val_loss: 0.2868 - val_acc: 0.8696\n",
      "Epoch 100/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2050 - acc: 0.9024 - val_loss: 0.2503 - val_acc: 0.8944\n",
      "Epoch 101/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2151 - acc: 0.8970 - val_loss: 0.2630 - val_acc: 0.8851\n",
      "Epoch 102/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2428 - acc: 0.8879 - val_loss: 0.2434 - val_acc: 0.9006\n",
      "Epoch 103/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2077 - acc: 0.9123 - val_loss: 0.3345 - val_acc: 0.8478\n",
      "Epoch 104/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2163 - acc: 0.9031 - val_loss: 0.2788 - val_acc: 0.8758\n",
      "Epoch 105/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2016 - acc: 0.9123 - val_loss: 0.3000 - val_acc: 0.8758\n",
      "Epoch 106/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2435 - acc: 0.8767 - val_loss: 0.2672 - val_acc: 0.8975\n",
      "Epoch 107/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2055 - acc: 0.9070 - val_loss: 0.2520 - val_acc: 0.9006\n",
      "Epoch 108/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2481 - acc: 0.8656 - val_loss: 0.3096 - val_acc: 0.8602\n",
      "Epoch 109/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2101 - acc: 0.9062 - val_loss: 0.2528 - val_acc: 0.9037\n",
      "Epoch 110/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2038 - acc: 0.9062 - val_loss: 0.2945 - val_acc: 0.8571\n",
      "Epoch 111/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2310 - acc: 0.8986 - val_loss: 0.2698 - val_acc: 0.8944\n",
      "Epoch 112/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2016 - acc: 0.9054 - val_loss: 0.2895 - val_acc: 0.8882\n",
      "Epoch 113/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2458 - acc: 0.8821 - val_loss: 0.2647 - val_acc: 0.8758\n",
      "Epoch 114/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2038 - acc: 0.9108 - val_loss: 0.2583 - val_acc: 0.9068\n",
      "Epoch 115/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2243 - acc: 0.8943 - val_loss: 0.2341 - val_acc: 0.9130\n",
      "Epoch 116/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2688 - acc: 0.8722 - val_loss: 0.2727 - val_acc: 0.8913\n",
      "Epoch 117/150\n",
      "41/40 [==============================] - 6s 157ms/step - loss: 0.2131 - acc: 0.9100 - val_loss: 0.2361 - val_acc: 0.9130\n",
      "Epoch 118/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1928 - acc: 0.9100 - val_loss: 0.2419 - val_acc: 0.9161\n",
      "Epoch 119/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2053 - acc: 0.9123 - val_loss: 0.2292 - val_acc: 0.9224\n",
      "Epoch 120/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2010 - acc: 0.9161 - val_loss: 0.2565 - val_acc: 0.9130\n",
      "Epoch 121/150\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.2032 - acc: 0.9024 - val_loss: 0.2842 - val_acc: 0.8758\n",
      "Epoch 122/150\n",
      "41/40 [==============================] - 7s 161ms/step - loss: 0.1957 - acc: 0.9138 - val_loss: 0.2892 - val_acc: 0.8789\n",
      "Epoch 123/150\n",
      "41/40 [==============================] - 6s 150ms/step - loss: 0.2106 - acc: 0.9047 - val_loss: 0.2538 - val_acc: 0.8975\n",
      "Epoch 124/150\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.2022 - acc: 0.9070 - val_loss: 0.2571 - val_acc: 0.9068\n",
      "Epoch 125/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2138 - acc: 0.9146 - val_loss: 0.2784 - val_acc: 0.8851\n",
      "Epoch 126/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2103 - acc: 0.9062 - val_loss: 0.2594 - val_acc: 0.8882\n",
      "Epoch 127/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1956 - acc: 0.9184 - val_loss: 0.2475 - val_acc: 0.9099\n",
      "Epoch 128/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1913 - acc: 0.9108 - val_loss: 0.2881 - val_acc: 0.8758\n",
      "Epoch 129/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2160 - acc: 0.9019 - val_loss: 0.2691 - val_acc: 0.8727\n",
      "Epoch 130/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2062 - acc: 0.9115 - val_loss: 0.2509 - val_acc: 0.8882\n",
      "Epoch 131/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2095 - acc: 0.9138 - val_loss: 0.2682 - val_acc: 0.8882\n",
      "Epoch 132/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1890 - acc: 0.9146 - val_loss: 0.2537 - val_acc: 0.8944\n",
      "Epoch 133/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1908 - acc: 0.9237 - val_loss: 0.2399 - val_acc: 0.9130\n",
      "Epoch 134/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1899 - acc: 0.9207 - val_loss: 0.2835 - val_acc: 0.8882\n",
      "Epoch 135/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1946 - acc: 0.9070 - val_loss: 0.3395 - val_acc: 0.8509\n",
      "Epoch 136/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1937 - acc: 0.9199 - val_loss: 0.2806 - val_acc: 0.8851\n",
      "Epoch 137/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1803 - acc: 0.9192 - val_loss: 0.2518 - val_acc: 0.8882\n",
      "Epoch 138/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1848 - acc: 0.9153 - val_loss: 0.2554 - val_acc: 0.9037\n",
      "Epoch 139/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1730 - acc: 0.9215 - val_loss: 0.2775 - val_acc: 0.8882\n",
      "Epoch 140/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2006 - acc: 0.9199 - val_loss: 0.2501 - val_acc: 0.8944\n",
      "Epoch 141/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1832 - acc: 0.9088 - val_loss: 0.2585 - val_acc: 0.9037\n",
      "Epoch 142/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1901 - acc: 0.9207 - val_loss: 0.2706 - val_acc: 0.8851\n",
      "Epoch 143/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1711 - acc: 0.9207 - val_loss: 0.2300 - val_acc: 0.9130\n",
      "Epoch 144/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1878 - acc: 0.9215 - val_loss: 0.2534 - val_acc: 0.9068\n",
      "Epoch 145/150\n",
      "41/40 [==============================] - 7s 159ms/step - loss: 0.1931 - acc: 0.9149 - val_loss: 0.2350 - val_acc: 0.9224\n",
      "Epoch 146/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2104 - acc: 0.9034 - val_loss: 0.2528 - val_acc: 0.9099\n",
      "Epoch 147/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1964 - acc: 0.9100 - val_loss: 0.2562 - val_acc: 0.8975\n",
      "Epoch 148/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1869 - acc: 0.9230 - val_loss: 0.2587 - val_acc: 0.8882\n",
      "Epoch 149/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1697 - acc: 0.9207 - val_loss: 0.2299 - val_acc: 0.9161\n",
      "Epoch 150/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1703 - acc: 0.9245 - val_loss: 0.2414 - val_acc: 0.9161\n",
      "322/322 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "41/40 [==============================] - 10s 244ms/step - loss: 1.2527 - acc: 0.4994 - val_loss: 0.6792 - val_acc: 0.5358\n",
      "Epoch 2/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.7273 - acc: 0.5364 - val_loss: 0.6434 - val_acc: 0.6417\n",
      "Epoch 3/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.6720 - acc: 0.5636 - val_loss: 0.6135 - val_acc: 0.5919\n",
      "Epoch 4/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.6335 - acc: 0.5741 - val_loss: 0.5777 - val_acc: 0.6324\n",
      "Epoch 5/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.5992 - acc: 0.6154 - val_loss: 0.5623 - val_acc: 0.6604\n",
      "Epoch 6/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.5692 - acc: 0.6568 - val_loss: 0.5554 - val_acc: 0.6916\n",
      "Epoch 7/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.5670 - acc: 0.6744 - val_loss: 0.5446 - val_acc: 0.6854\n",
      "Epoch 8/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.5628 - acc: 0.6551 - val_loss: 0.5374 - val_acc: 0.7072\n",
      "Epoch 9/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.5360 - acc: 0.6812 - val_loss: 0.5221 - val_acc: 0.7196\n",
      "Epoch 10/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.5248 - acc: 0.7018 - val_loss: 0.5062 - val_acc: 0.7539\n",
      "Epoch 11/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.5144 - acc: 0.7316 - val_loss: 0.4672 - val_acc: 0.7913\n",
      "Epoch 12/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.4931 - acc: 0.7506 - val_loss: 0.4473 - val_acc: 0.7850\n",
      "Epoch 13/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4463 - acc: 0.7831 - val_loss: 0.4198 - val_acc: 0.8224\n",
      "Epoch 14/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4627 - acc: 0.7701 - val_loss: 0.4229 - val_acc: 0.7975\n",
      "Epoch 15/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.4331 - acc: 0.7908 - val_loss: 0.3906 - val_acc: 0.8193\n",
      "Epoch 16/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.4156 - acc: 0.8154 - val_loss: 0.3841 - val_acc: 0.8224\n",
      "Epoch 17/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.4101 - acc: 0.8116 - val_loss: 0.3803 - val_acc: 0.8287\n",
      "Epoch 18/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.4364 - acc: 0.8003 - val_loss: 0.3963 - val_acc: 0.8100\n",
      "Epoch 19/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.4034 - acc: 0.8116 - val_loss: 0.4331 - val_acc: 0.7819\n",
      "Epoch 20/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.4089 - acc: 0.8040 - val_loss: 0.3852 - val_acc: 0.8224\n",
      "Epoch 21/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3988 - acc: 0.8231 - val_loss: 0.3740 - val_acc: 0.8380\n",
      "Epoch 22/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3974 - acc: 0.8269 - val_loss: 0.3739 - val_acc: 0.8224\n",
      "Epoch 23/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3858 - acc: 0.8281 - val_loss: 0.3651 - val_acc: 0.8349\n",
      "Epoch 24/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3761 - acc: 0.8345 - val_loss: 0.3531 - val_acc: 0.8442\n",
      "Epoch 25/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3810 - acc: 0.8185 - val_loss: 0.3572 - val_acc: 0.8411\n",
      "Epoch 26/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3521 - acc: 0.8505 - val_loss: 0.3516 - val_acc: 0.8318\n",
      "Epoch 27/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3741 - acc: 0.8342 - val_loss: 0.4015 - val_acc: 0.7944\n",
      "Epoch 28/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3709 - acc: 0.8296 - val_loss: 0.3494 - val_acc: 0.8474\n",
      "Epoch 29/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3556 - acc: 0.8273 - val_loss: 0.3307 - val_acc: 0.8411\n",
      "Epoch 30/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3267 - acc: 0.8582 - val_loss: 0.3414 - val_acc: 0.8318\n",
      "Epoch 31/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3324 - acc: 0.8460 - val_loss: 0.3131 - val_acc: 0.8598\n",
      "Epoch 32/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3294 - acc: 0.8415 - val_loss: 0.3098 - val_acc: 0.8536\n",
      "Epoch 33/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3372 - acc: 0.8543 - val_loss: 0.3272 - val_acc: 0.8287\n",
      "Epoch 34/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3236 - acc: 0.8548 - val_loss: 0.3037 - val_acc: 0.8598\n",
      "Epoch 35/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3133 - acc: 0.8677 - val_loss: 0.2940 - val_acc: 0.8754\n",
      "Epoch 36/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3484 - acc: 0.8372 - val_loss: 0.2990 - val_acc: 0.8692\n",
      "Epoch 37/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3283 - acc: 0.8513 - val_loss: 0.3312 - val_acc: 0.8349\n",
      "Epoch 38/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3098 - acc: 0.8612 - val_loss: 0.2932 - val_acc: 0.8692\n",
      "Epoch 39/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3164 - acc: 0.8471 - val_loss: 0.2975 - val_acc: 0.8816\n",
      "Epoch 40/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2843 - acc: 0.8795 - val_loss: 0.3435 - val_acc: 0.8131\n",
      "Epoch 41/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3192 - acc: 0.8551 - val_loss: 0.3424 - val_acc: 0.8224\n",
      "Epoch 42/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3139 - acc: 0.8548 - val_loss: 0.2861 - val_acc: 0.8567\n",
      "Epoch 43/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2968 - acc: 0.8681 - val_loss: 0.2795 - val_acc: 0.8692\n",
      "Epoch 44/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2947 - acc: 0.8627 - val_loss: 0.2846 - val_acc: 0.8598\n",
      "Epoch 45/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2998 - acc: 0.8742 - val_loss: 0.2962 - val_acc: 0.8474\n",
      "Epoch 46/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2947 - acc: 0.8711 - val_loss: 0.2774 - val_acc: 0.8692\n",
      "Epoch 47/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2840 - acc: 0.8726 - val_loss: 0.2743 - val_acc: 0.8692\n",
      "Epoch 48/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2780 - acc: 0.8757 - val_loss: 0.2667 - val_acc: 0.8660\n",
      "Epoch 49/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2770 - acc: 0.8719 - val_loss: 0.2694 - val_acc: 0.8629\n",
      "Epoch 50/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2693 - acc: 0.8795 - val_loss: 0.2907 - val_acc: 0.8660\n",
      "Epoch 51/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2844 - acc: 0.8734 - val_loss: 0.2942 - val_acc: 0.8474\n",
      "Epoch 52/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2834 - acc: 0.8632 - val_loss: 0.2642 - val_acc: 0.8660\n",
      "Epoch 53/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2858 - acc: 0.8639 - val_loss: 0.2791 - val_acc: 0.8536\n",
      "Epoch 54/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2902 - acc: 0.8749 - val_loss: 0.3022 - val_acc: 0.8474\n",
      "Epoch 55/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3198 - acc: 0.8392 - val_loss: 0.2746 - val_acc: 0.8692\n",
      "Epoch 56/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2771 - acc: 0.8818 - val_loss: 0.2653 - val_acc: 0.8629\n",
      "Epoch 57/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2684 - acc: 0.8738 - val_loss: 0.2831 - val_acc: 0.8536\n",
      "Epoch 58/150\n",
      "41/40 [==============================] - 6s 151ms/step - loss: 0.2799 - acc: 0.8795 - val_loss: 0.2543 - val_acc: 0.8785\n",
      "Epoch 59/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2739 - acc: 0.8757 - val_loss: 0.2617 - val_acc: 0.8723\n",
      "Epoch 60/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2986 - acc: 0.8761 - val_loss: 0.2861 - val_acc: 0.8598\n",
      "Epoch 61/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2742 - acc: 0.8769 - val_loss: 0.2932 - val_acc: 0.8442\n",
      "Epoch 62/150\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.2704 - acc: 0.8795 - val_loss: 0.2907 - val_acc: 0.8505\n",
      "Epoch 63/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2815 - acc: 0.8803 - val_loss: 0.2522 - val_acc: 0.8785\n",
      "Epoch 64/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2594 - acc: 0.8826 - val_loss: 0.2756 - val_acc: 0.8692\n",
      "Epoch 65/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2471 - acc: 0.8909 - val_loss: 0.2462 - val_acc: 0.8692\n",
      "Epoch 66/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2482 - acc: 0.8894 - val_loss: 0.2732 - val_acc: 0.8629\n",
      "Epoch 67/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2617 - acc: 0.8822 - val_loss: 0.2610 - val_acc: 0.8816\n",
      "Epoch 68/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2817 - acc: 0.8624 - val_loss: 0.2547 - val_acc: 0.8754\n",
      "Epoch 69/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2471 - acc: 0.8887 - val_loss: 0.2579 - val_acc: 0.8847\n",
      "Epoch 70/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2475 - acc: 0.8963 - val_loss: 0.2621 - val_acc: 0.8660\n",
      "Epoch 71/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2730 - acc: 0.8685 - val_loss: 0.2807 - val_acc: 0.8660\n",
      "Epoch 72/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2436 - acc: 0.8830 - val_loss: 0.2554 - val_acc: 0.8723\n",
      "Epoch 73/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2516 - acc: 0.8879 - val_loss: 0.2651 - val_acc: 0.8723\n",
      "Epoch 74/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2489 - acc: 0.8841 - val_loss: 0.2617 - val_acc: 0.8629\n",
      "Epoch 75/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2402 - acc: 0.9001 - val_loss: 0.2509 - val_acc: 0.8754\n",
      "Epoch 76/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2525 - acc: 0.8795 - val_loss: 0.2527 - val_acc: 0.8816\n",
      "Epoch 77/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2389 - acc: 0.8978 - val_loss: 0.2672 - val_acc: 0.8692\n",
      "Epoch 78/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2611 - acc: 0.8731 - val_loss: 0.2664 - val_acc: 0.8598\n",
      "Epoch 79/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2353 - acc: 0.8955 - val_loss: 0.2578 - val_acc: 0.8785\n",
      "Epoch 80/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2287 - acc: 0.8986 - val_loss: 0.2512 - val_acc: 0.8692\n",
      "Epoch 81/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2532 - acc: 0.8830 - val_loss: 0.2553 - val_acc: 0.8847\n",
      "Epoch 82/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2567 - acc: 0.8887 - val_loss: 0.2394 - val_acc: 0.8941\n",
      "Epoch 83/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2343 - acc: 0.9031 - val_loss: 0.2418 - val_acc: 0.8910\n",
      "Epoch 84/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2430 - acc: 0.8879 - val_loss: 0.2371 - val_acc: 0.8816\n",
      "Epoch 85/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2279 - acc: 0.8925 - val_loss: 0.2672 - val_acc: 0.8723\n",
      "Epoch 86/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2607 - acc: 0.8838 - val_loss: 0.2815 - val_acc: 0.8629\n",
      "Epoch 87/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2350 - acc: 0.8883 - val_loss: 0.2550 - val_acc: 0.8754\n",
      "Epoch 88/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2391 - acc: 0.8909 - val_loss: 0.2630 - val_acc: 0.8629\n",
      "Epoch 89/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2319 - acc: 0.8986 - val_loss: 0.2378 - val_acc: 0.8785\n",
      "Epoch 90/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2438 - acc: 0.8838 - val_loss: 0.2370 - val_acc: 0.8879\n",
      "Epoch 91/150\n",
      "41/40 [==============================] - 6s 150ms/step - loss: 0.2252 - acc: 0.8993 - val_loss: 0.2656 - val_acc: 0.8629\n",
      "Epoch 92/150\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.2290 - acc: 0.8948 - val_loss: 0.2320 - val_acc: 0.8879\n",
      "Epoch 93/150\n",
      "41/40 [==============================] - 6s 150ms/step - loss: 0.2210 - acc: 0.9092 - val_loss: 0.2225 - val_acc: 0.9065\n",
      "Epoch 94/150\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2360 - acc: 0.8955 - val_loss: 0.2467 - val_acc: 0.8910\n",
      "Epoch 95/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2327 - acc: 0.8891 - val_loss: 0.2849 - val_acc: 0.8598\n",
      "Epoch 96/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2327 - acc: 0.8978 - val_loss: 0.2603 - val_acc: 0.8972\n",
      "Epoch 97/150\n",
      "41/40 [==============================] - 6s 149ms/step - loss: 0.2352 - acc: 0.8917 - val_loss: 0.2262 - val_acc: 0.8941\n",
      "Epoch 98/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2243 - acc: 0.9013 - val_loss: 0.2447 - val_acc: 0.8879\n",
      "Epoch 99/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2184 - acc: 0.9085 - val_loss: 0.2439 - val_acc: 0.8816\n",
      "Epoch 100/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2379 - acc: 0.8932 - val_loss: 0.2523 - val_acc: 0.8754\n",
      "Epoch 101/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2388 - acc: 0.8895 - val_loss: 0.3434 - val_acc: 0.8131\n",
      "Epoch 102/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2334 - acc: 0.8948 - val_loss: 0.2313 - val_acc: 0.8847\n",
      "Epoch 103/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2260 - acc: 0.8986 - val_loss: 0.2530 - val_acc: 0.8723\n",
      "Epoch 104/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2339 - acc: 0.8967 - val_loss: 0.2701 - val_acc: 0.8536\n",
      "Epoch 105/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2745 - acc: 0.8708 - val_loss: 0.3248 - val_acc: 0.8255\n",
      "Epoch 106/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2405 - acc: 0.8864 - val_loss: 0.2278 - val_acc: 0.8910\n",
      "Epoch 107/150\n",
      "41/40 [==============================] - 6s 158ms/step - loss: 0.2281 - acc: 0.8986 - val_loss: 0.2303 - val_acc: 0.8847\n",
      "Epoch 108/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2432 - acc: 0.8978 - val_loss: 0.2287 - val_acc: 0.8972\n",
      "Epoch 109/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2203 - acc: 0.9001 - val_loss: 0.2457 - val_acc: 0.8879\n",
      "Epoch 110/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2133 - acc: 0.9138 - val_loss: 0.2529 - val_acc: 0.8754\n",
      "Epoch 111/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2046 - acc: 0.9054 - val_loss: 0.2264 - val_acc: 0.8816\n",
      "Epoch 112/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2100 - acc: 0.9062 - val_loss: 0.2472 - val_acc: 0.8847\n",
      "Epoch 113/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2173 - acc: 0.9001 - val_loss: 0.2380 - val_acc: 0.8941\n",
      "Epoch 114/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2226 - acc: 0.9031 - val_loss: 0.2536 - val_acc: 0.8754\n",
      "Epoch 115/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2010 - acc: 0.9154 - val_loss: 0.2202 - val_acc: 0.9065\n",
      "Epoch 116/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2268 - acc: 0.8986 - val_loss: 0.2521 - val_acc: 0.8629\n",
      "Epoch 117/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2501 - acc: 0.8833 - val_loss: 0.2565 - val_acc: 0.8785\n",
      "Epoch 118/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2232 - acc: 0.9039 - val_loss: 0.2267 - val_acc: 0.8910\n",
      "Epoch 119/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2183 - acc: 0.9062 - val_loss: 0.2392 - val_acc: 0.8910\n",
      "Epoch 120/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2298 - acc: 0.9001 - val_loss: 0.2382 - val_acc: 0.8785\n",
      "Epoch 121/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2131 - acc: 0.9009 - val_loss: 0.2865 - val_acc: 0.8598\n",
      "Epoch 122/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2664 - acc: 0.8807 - val_loss: 0.2464 - val_acc: 0.8816\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2190 - acc: 0.8982 - val_loss: 0.2453 - val_acc: 0.8941\n",
      "Epoch 124/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2209 - acc: 0.9039 - val_loss: 0.2386 - val_acc: 0.8879\n",
      "Epoch 125/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2266 - acc: 0.9009 - val_loss: 0.2339 - val_acc: 0.8879\n",
      "Epoch 126/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2243 - acc: 0.9013 - val_loss: 0.2307 - val_acc: 0.8879\n",
      "Epoch 127/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2038 - acc: 0.9074 - val_loss: 0.2278 - val_acc: 0.8754\n",
      "Epoch 128/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.1959 - acc: 0.9169 - val_loss: 0.2844 - val_acc: 0.8629\n",
      "Epoch 129/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2116 - acc: 0.9085 - val_loss: 0.2433 - val_acc: 0.8754\n",
      "Epoch 130/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2085 - acc: 0.9039 - val_loss: 0.2363 - val_acc: 0.8879\n",
      "Epoch 131/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2113 - acc: 0.9039 - val_loss: 0.2370 - val_acc: 0.8816\n",
      "Epoch 132/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2057 - acc: 0.9215 - val_loss: 0.2266 - val_acc: 0.8910\n",
      "Epoch 133/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1919 - acc: 0.9184 - val_loss: 0.2175 - val_acc: 0.8910\n",
      "Epoch 134/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2081 - acc: 0.9062 - val_loss: 0.2479 - val_acc: 0.8723\n",
      "Epoch 135/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2218 - acc: 0.8895 - val_loss: 0.2162 - val_acc: 0.8847\n",
      "Epoch 136/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1920 - acc: 0.9092 - val_loss: 0.2222 - val_acc: 0.8816\n",
      "Epoch 137/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1998 - acc: 0.9192 - val_loss: 0.2125 - val_acc: 0.8847\n",
      "Epoch 138/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2024 - acc: 0.9199 - val_loss: 0.2089 - val_acc: 0.8847\n",
      "Epoch 139/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2010 - acc: 0.9184 - val_loss: 0.2458 - val_acc: 0.8816\n",
      "Epoch 140/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1899 - acc: 0.9184 - val_loss: 0.2283 - val_acc: 0.8941\n",
      "Epoch 141/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2113 - acc: 0.9077 - val_loss: 0.2281 - val_acc: 0.8847\n",
      "Epoch 142/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2040 - acc: 0.9047 - val_loss: 0.2348 - val_acc: 0.8879\n",
      "Epoch 143/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1952 - acc: 0.9192 - val_loss: 0.2237 - val_acc: 0.8972\n",
      "Epoch 144/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1878 - acc: 0.9184 - val_loss: 0.2452 - val_acc: 0.8816\n",
      "Epoch 145/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1966 - acc: 0.9146 - val_loss: 0.2397 - val_acc: 0.8847\n",
      "Epoch 146/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1992 - acc: 0.9085 - val_loss: 0.2144 - val_acc: 0.8910\n",
      "Epoch 147/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2096 - acc: 0.9207 - val_loss: 0.2377 - val_acc: 0.8629\n",
      "Epoch 148/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1950 - acc: 0.9097 - val_loss: 0.2493 - val_acc: 0.8660\n",
      "Epoch 149/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1889 - acc: 0.9169 - val_loss: 0.2532 - val_acc: 0.8754\n",
      "Epoch 150/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1917 - acc: 0.9123 - val_loss: 0.2152 - val_acc: 0.9034\n",
      "321/321 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "41/40 [==============================] - 9s 230ms/step - loss: 1.3496 - acc: 0.5044 - val_loss: 0.6803 - val_acc: 0.5296\n",
      "Epoch 2/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.7562 - acc: 0.5128 - val_loss: 0.6758 - val_acc: 0.6075\n",
      "Epoch 3/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.6870 - acc: 0.5586 - val_loss: 0.6319 - val_acc: 0.5981\n",
      "Epoch 4/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.6578 - acc: 0.5841 - val_loss: 0.5815 - val_acc: 0.6947\n",
      "Epoch 5/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.6107 - acc: 0.6214 - val_loss: 0.5494 - val_acc: 0.6854\n",
      "Epoch 6/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.6002 - acc: 0.6147 - val_loss: 0.5373 - val_acc: 0.7165\n",
      "Epoch 7/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.5858 - acc: 0.6390 - val_loss: 0.5324 - val_acc: 0.7196\n",
      "Epoch 8/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.5561 - acc: 0.6835 - val_loss: 0.5222 - val_acc: 0.7477\n",
      "Epoch 9/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.5389 - acc: 0.6866 - val_loss: 0.5153 - val_acc: 0.7664\n",
      "Epoch 10/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.5930 - acc: 0.6821 - val_loss: 0.5185 - val_acc: 0.7259\n",
      "Epoch 11/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.5400 - acc: 0.6836 - val_loss: 0.5054 - val_acc: 0.7788\n",
      "Epoch 12/150\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.5210 - acc: 0.7084 - val_loss: 0.4867 - val_acc: 0.7913\n",
      "Epoch 13/150\n",
      "41/40 [==============================] - 7s 170ms/step - loss: 0.5081 - acc: 0.7389 - val_loss: 0.4706 - val_acc: 0.7788\n",
      "Epoch 14/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.5022 - acc: 0.7480 - val_loss: 0.4742 - val_acc: 0.7882\n",
      "Epoch 15/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.4894 - acc: 0.7549 - val_loss: 0.5371 - val_acc: 0.6573\n",
      "Epoch 16/150\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.4949 - acc: 0.7491 - val_loss: 0.4471 - val_acc: 0.8224\n",
      "Epoch 17/150\n",
      "41/40 [==============================] - 6s 150ms/step - loss: 0.4641 - acc: 0.7572 - val_loss: 0.4233 - val_acc: 0.8411\n",
      "Epoch 18/150\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.4362 - acc: 0.7842 - val_loss: 0.4088 - val_acc: 0.8224\n",
      "Epoch 19/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.4382 - acc: 0.7918 - val_loss: 0.4128 - val_acc: 0.8474\n",
      "Epoch 20/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.4390 - acc: 0.7869 - val_loss: 0.3958 - val_acc: 0.8474\n",
      "Epoch 21/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.4065 - acc: 0.8048 - val_loss: 0.4015 - val_acc: 0.8349\n",
      "Epoch 22/150\n",
      "41/40 [==============================] - 6s 154ms/step - loss: 0.4031 - acc: 0.8109 - val_loss: 0.3560 - val_acc: 0.8567\n",
      "Epoch 23/150\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.4012 - acc: 0.8055 - val_loss: 0.3912 - val_acc: 0.8411\n",
      "Epoch 24/150\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.3855 - acc: 0.8186 - val_loss: 0.3460 - val_acc: 0.8536\n",
      "Epoch 25/150\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.3798 - acc: 0.8182 - val_loss: 0.3329 - val_acc: 0.8567\n",
      "Epoch 26/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.3617 - acc: 0.8376 - val_loss: 0.3756 - val_acc: 0.8411\n",
      "Epoch 27/150\n",
      "41/40 [==============================] - 6s 152ms/step - loss: 0.3524 - acc: 0.8421 - val_loss: 0.3365 - val_acc: 0.8629\n",
      "Epoch 28/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3630 - acc: 0.8205 - val_loss: 0.3888 - val_acc: 0.7975\n",
      "Epoch 29/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3678 - acc: 0.8185 - val_loss: 0.3487 - val_acc: 0.8536\n",
      "Epoch 30/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.3318 - acc: 0.8482 - val_loss: 0.3229 - val_acc: 0.8629\n",
      "Epoch 31/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3313 - acc: 0.8437 - val_loss: 0.3600 - val_acc: 0.8162\n",
      "Epoch 32/150\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.3567 - acc: 0.8311 - val_loss: 0.3113 - val_acc: 0.8567\n",
      "Epoch 33/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3252 - acc: 0.8551 - val_loss: 0.3172 - val_acc: 0.8660\n",
      "Epoch 34/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2965 - acc: 0.8566 - val_loss: 0.2883 - val_acc: 0.8660\n",
      "Epoch 35/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3056 - acc: 0.8597 - val_loss: 0.3029 - val_acc: 0.8567\n",
      "Epoch 36/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3194 - acc: 0.8380 - val_loss: 0.3791 - val_acc: 0.7944\n",
      "Epoch 37/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3409 - acc: 0.8426 - val_loss: 0.3006 - val_acc: 0.8598\n",
      "Epoch 38/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2861 - acc: 0.8780 - val_loss: 0.3249 - val_acc: 0.8318\n",
      "Epoch 39/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3125 - acc: 0.8551 - val_loss: 0.3213 - val_acc: 0.8505\n",
      "Epoch 40/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3087 - acc: 0.8536 - val_loss: 0.3242 - val_acc: 0.8162\n",
      "Epoch 41/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2895 - acc: 0.8719 - val_loss: 0.2712 - val_acc: 0.8692\n",
      "Epoch 42/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.3052 - acc: 0.8490 - val_loss: 0.2906 - val_acc: 0.8723\n",
      "Epoch 43/150\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.2702 - acc: 0.8742 - val_loss: 0.2896 - val_acc: 0.8629\n",
      "Epoch 44/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2834 - acc: 0.8620 - val_loss: 0.3080 - val_acc: 0.8411\n",
      "Epoch 45/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2733 - acc: 0.8688 - val_loss: 0.2810 - val_acc: 0.8536\n",
      "Epoch 46/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2732 - acc: 0.8826 - val_loss: 0.2952 - val_acc: 0.8629\n",
      "Epoch 47/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2968 - acc: 0.8670 - val_loss: 0.2803 - val_acc: 0.8567\n",
      "Epoch 48/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2772 - acc: 0.8757 - val_loss: 0.2938 - val_acc: 0.8660\n",
      "Epoch 49/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2788 - acc: 0.8696 - val_loss: 0.3229 - val_acc: 0.8692\n",
      "Epoch 50/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2816 - acc: 0.8688 - val_loss: 0.3080 - val_acc: 0.8567\n",
      "Epoch 51/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2745 - acc: 0.8685 - val_loss: 0.2794 - val_acc: 0.8692\n",
      "Epoch 52/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2534 - acc: 0.8894 - val_loss: 0.3249 - val_acc: 0.8193\n",
      "Epoch 53/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2647 - acc: 0.8864 - val_loss: 0.2608 - val_acc: 0.8754\n",
      "Epoch 54/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2643 - acc: 0.8803 - val_loss: 0.2612 - val_acc: 0.8723\n",
      "Epoch 55/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2593 - acc: 0.8803 - val_loss: 0.2521 - val_acc: 0.8847\n",
      "Epoch 56/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2579 - acc: 0.8841 - val_loss: 0.2597 - val_acc: 0.8847\n",
      "Epoch 57/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2541 - acc: 0.8833 - val_loss: 0.2718 - val_acc: 0.8692\n",
      "Epoch 58/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2557 - acc: 0.8925 - val_loss: 0.3123 - val_acc: 0.8442\n",
      "Epoch 59/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2654 - acc: 0.8799 - val_loss: 0.2636 - val_acc: 0.8754\n",
      "Epoch 60/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2804 - acc: 0.8723 - val_loss: 0.2778 - val_acc: 0.8660\n",
      "Epoch 61/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2677 - acc: 0.8769 - val_loss: 0.2849 - val_acc: 0.8598\n",
      "Epoch 62/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2469 - acc: 0.8803 - val_loss: 0.2643 - val_acc: 0.8816\n",
      "Epoch 63/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2617 - acc: 0.8787 - val_loss: 0.3034 - val_acc: 0.8536\n",
      "Epoch 64/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2610 - acc: 0.8787 - val_loss: 0.2753 - val_acc: 0.8598\n",
      "Epoch 65/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2685 - acc: 0.8708 - val_loss: 0.3472 - val_acc: 0.8193\n",
      "Epoch 66/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2679 - acc: 0.8734 - val_loss: 0.2540 - val_acc: 0.8879\n",
      "Epoch 67/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2410 - acc: 0.9024 - val_loss: 0.2620 - val_acc: 0.8785\n",
      "Epoch 68/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2935 - acc: 0.8502 - val_loss: 0.2585 - val_acc: 0.8723\n",
      "Epoch 69/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2545 - acc: 0.8925 - val_loss: 0.2705 - val_acc: 0.8816\n",
      "Epoch 70/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2280 - acc: 0.8925 - val_loss: 0.2668 - val_acc: 0.8816\n",
      "Epoch 71/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2522 - acc: 0.8876 - val_loss: 0.2661 - val_acc: 0.8723\n",
      "Epoch 72/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2419 - acc: 0.8970 - val_loss: 0.2582 - val_acc: 0.8816\n",
      "Epoch 73/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2503 - acc: 0.8815 - val_loss: 0.2835 - val_acc: 0.8598\n",
      "Epoch 74/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2277 - acc: 0.9031 - val_loss: 0.2788 - val_acc: 0.8879\n",
      "Epoch 75/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2625 - acc: 0.8860 - val_loss: 0.2488 - val_acc: 0.8910\n",
      "Epoch 76/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2424 - acc: 0.8963 - val_loss: 0.2615 - val_acc: 0.8847\n",
      "Epoch 77/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2445 - acc: 0.8864 - val_loss: 0.2620 - val_acc: 0.8754\n",
      "Epoch 78/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2317 - acc: 0.8917 - val_loss: 0.2608 - val_acc: 0.8785\n",
      "Epoch 79/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2459 - acc: 0.8883 - val_loss: 0.3030 - val_acc: 0.8692\n",
      "Epoch 80/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2506 - acc: 0.8841 - val_loss: 0.2697 - val_acc: 0.8816\n",
      "Epoch 81/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2351 - acc: 0.8986 - val_loss: 0.2527 - val_acc: 0.8847\n",
      "Epoch 82/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2531 - acc: 0.8899 - val_loss: 0.2621 - val_acc: 0.8754\n",
      "Epoch 83/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2404 - acc: 0.9001 - val_loss: 0.2639 - val_acc: 0.8754\n",
      "Epoch 84/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2282 - acc: 0.9039 - val_loss: 0.2613 - val_acc: 0.8816\n",
      "Epoch 85/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2410 - acc: 0.8864 - val_loss: 0.2439 - val_acc: 0.8910\n",
      "Epoch 86/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2176 - acc: 0.9085 - val_loss: 0.2567 - val_acc: 0.8785\n",
      "Epoch 87/150\n",
      "41/40 [==============================] - 6s 148ms/step - loss: 0.2229 - acc: 0.8986 - val_loss: 0.2776 - val_acc: 0.8816\n",
      "Epoch 88/150\n",
      "41/40 [==============================] - 7s 166ms/step - loss: 0.2362 - acc: 0.9031 - val_loss: 0.2601 - val_acc: 0.8847\n",
      "Epoch 89/150\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.2203 - acc: 0.8993 - val_loss: 0.2599 - val_acc: 0.8816\n",
      "Epoch 90/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2496 - acc: 0.8784 - val_loss: 0.2501 - val_acc: 0.8910\n",
      "Epoch 91/150\n",
      "41/40 [==============================] - 7s 171ms/step - loss: 0.2129 - acc: 0.9077 - val_loss: 0.2547 - val_acc: 0.9003\n",
      "Epoch 92/150\n",
      "41/40 [==============================] - 6s 151ms/step - loss: 0.2269 - acc: 0.9001 - val_loss: 0.2778 - val_acc: 0.8754\n",
      "Epoch 93/150\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2267 - acc: 0.9005 - val_loss: 0.2658 - val_acc: 0.8910\n",
      "Epoch 94/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2065 - acc: 0.9039 - val_loss: 0.2497 - val_acc: 0.8847\n",
      "Epoch 95/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2324 - acc: 0.8906 - val_loss: 0.2679 - val_acc: 0.8816\n",
      "Epoch 96/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2368 - acc: 0.8937 - val_loss: 0.2745 - val_acc: 0.8629\n",
      "Epoch 97/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2417 - acc: 0.9070 - val_loss: 0.2669 - val_acc: 0.8785\n",
      "Epoch 98/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2198 - acc: 0.9047 - val_loss: 0.2454 - val_acc: 0.8941\n",
      "Epoch 99/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2152 - acc: 0.9146 - val_loss: 0.2631 - val_acc: 0.8910\n",
      "Epoch 100/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2158 - acc: 0.9123 - val_loss: 0.2609 - val_acc: 0.8754\n",
      "Epoch 101/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2175 - acc: 0.9016 - val_loss: 0.2433 - val_acc: 0.9003\n",
      "Epoch 102/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2229 - acc: 0.9047 - val_loss: 0.2572 - val_acc: 0.8816\n",
      "Epoch 103/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2559 - acc: 0.8708 - val_loss: 0.2722 - val_acc: 0.8847\n",
      "Epoch 104/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2216 - acc: 0.9047 - val_loss: 0.2788 - val_acc: 0.8723\n",
      "Epoch 105/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2284 - acc: 0.8948 - val_loss: 0.2775 - val_acc: 0.8598\n",
      "Epoch 106/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2264 - acc: 0.8932 - val_loss: 0.2780 - val_acc: 0.8785\n",
      "Epoch 107/150\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2461 - acc: 0.9021 - val_loss: 0.3412 - val_acc: 0.8131\n",
      "Epoch 108/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2643 - acc: 0.8749 - val_loss: 0.2566 - val_acc: 0.8785\n",
      "Epoch 109/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2027 - acc: 0.9077 - val_loss: 0.2638 - val_acc: 0.8879\n",
      "Epoch 110/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2080 - acc: 0.9092 - val_loss: 0.2848 - val_acc: 0.8598\n",
      "Epoch 111/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2173 - acc: 0.9009 - val_loss: 0.2499 - val_acc: 0.8941\n",
      "Epoch 112/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2054 - acc: 0.9100 - val_loss: 0.2480 - val_acc: 0.8941\n",
      "Epoch 113/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2040 - acc: 0.9108 - val_loss: 0.3147 - val_acc: 0.8505\n",
      "Epoch 114/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2205 - acc: 0.8998 - val_loss: 0.3151 - val_acc: 0.8505\n",
      "Epoch 115/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2235 - acc: 0.8978 - val_loss: 0.2490 - val_acc: 0.8910\n",
      "Epoch 116/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2057 - acc: 0.9009 - val_loss: 0.2456 - val_acc: 0.8785\n",
      "Epoch 117/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1962 - acc: 0.9077 - val_loss: 0.2542 - val_acc: 0.9003\n",
      "Epoch 118/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2332 - acc: 0.9025 - val_loss: 0.2604 - val_acc: 0.8785\n",
      "Epoch 119/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2490 - acc: 0.8841 - val_loss: 0.2599 - val_acc: 0.8910\n",
      "Epoch 120/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2087 - acc: 0.9176 - val_loss: 0.2772 - val_acc: 0.8692\n",
      "Epoch 121/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2025 - acc: 0.9108 - val_loss: 0.2356 - val_acc: 0.9065\n",
      "Epoch 122/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2122 - acc: 0.9070 - val_loss: 0.2501 - val_acc: 0.8972\n",
      "Epoch 123/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2070 - acc: 0.9108 - val_loss: 0.2467 - val_acc: 0.9003\n",
      "Epoch 124/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1965 - acc: 0.9161 - val_loss: 0.2505 - val_acc: 0.8910\n",
      "Epoch 125/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1932 - acc: 0.9146 - val_loss: 0.2395 - val_acc: 0.8972\n",
      "Epoch 126/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1933 - acc: 0.9199 - val_loss: 0.2437 - val_acc: 0.8941\n",
      "Epoch 127/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1884 - acc: 0.9253 - val_loss: 0.2442 - val_acc: 0.8847\n",
      "Epoch 128/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2161 - acc: 0.9054 - val_loss: 0.2449 - val_acc: 0.8910\n",
      "Epoch 129/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1949 - acc: 0.9154 - val_loss: 0.2424 - val_acc: 0.8754\n",
      "Epoch 130/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1966 - acc: 0.9131 - val_loss: 0.2237 - val_acc: 0.9128\n",
      "Epoch 131/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1867 - acc: 0.9123 - val_loss: 0.2675 - val_acc: 0.8754\n",
      "Epoch 132/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1933 - acc: 0.9154 - val_loss: 0.2498 - val_acc: 0.8879\n",
      "Epoch 133/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2424 - acc: 0.8888 - val_loss: 0.2775 - val_acc: 0.8660\n",
      "Epoch 134/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2164 - acc: 0.9036 - val_loss: 0.2488 - val_acc: 0.8692\n",
      "Epoch 135/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2131 - acc: 0.8986 - val_loss: 0.2415 - val_acc: 0.8972\n",
      "Epoch 136/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1980 - acc: 0.9161 - val_loss: 0.2496 - val_acc: 0.8910\n",
      "Epoch 137/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1905 - acc: 0.9143 - val_loss: 0.2732 - val_acc: 0.8847\n",
      "Epoch 138/150\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.2130 - acc: 0.9173 - val_loss: 0.2487 - val_acc: 0.9003\n",
      "Epoch 139/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2017 - acc: 0.9131 - val_loss: 0.2648 - val_acc: 0.8879\n",
      "Epoch 140/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1913 - acc: 0.9085 - val_loss: 0.2762 - val_acc: 0.8692\n",
      "Epoch 141/150\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.1980 - acc: 0.9176 - val_loss: 0.3078 - val_acc: 0.8692\n",
      "Epoch 142/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1888 - acc: 0.9222 - val_loss: 0.2272 - val_acc: 0.8941\n",
      "Epoch 143/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1952 - acc: 0.9169 - val_loss: 0.2239 - val_acc: 0.9128\n",
      "Epoch 144/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1805 - acc: 0.9192 - val_loss: 0.2439 - val_acc: 0.9003\n",
      "Epoch 145/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1948 - acc: 0.9154 - val_loss: 0.2208 - val_acc: 0.9128\n",
      "Epoch 146/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1890 - acc: 0.9169 - val_loss: 0.2566 - val_acc: 0.8879\n",
      "Epoch 147/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1860 - acc: 0.9199 - val_loss: 0.2567 - val_acc: 0.8941\n",
      "Epoch 148/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1979 - acc: 0.9154 - val_loss: 0.2277 - val_acc: 0.9034\n",
      "Epoch 149/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1722 - acc: 0.9283 - val_loss: 0.2370 - val_acc: 0.9097\n",
      "Epoch 150/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2083 - acc: 0.9028 - val_loss: 0.2496 - val_acc: 0.9034\n",
      "321/321 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_84 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "41/40 [==============================] - 11s 280ms/step - loss: 1.6171 - acc: 0.4809 - val_loss: 0.6805 - val_acc: 0.6312\n",
      "Epoch 2/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.7889 - acc: 0.5053 - val_loss: 0.6803 - val_acc: 0.5375\n",
      "Epoch 3/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.6999 - acc: 0.5502 - val_loss: 0.6696 - val_acc: 0.6219\n",
      "Epoch 4/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.6930 - acc: 0.5458 - val_loss: 0.6558 - val_acc: 0.6531\n",
      "Epoch 5/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.6662 - acc: 0.5707 - val_loss: 0.6063 - val_acc: 0.6781\n",
      "Epoch 6/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.6340 - acc: 0.5846 - val_loss: 0.5734 - val_acc: 0.6719\n",
      "Epoch 7/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.5872 - acc: 0.6409 - val_loss: 0.5667 - val_acc: 0.6750\n",
      "Epoch 8/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.5765 - acc: 0.6304 - val_loss: 0.5637 - val_acc: 0.6844\n",
      "Epoch 9/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.5670 - acc: 0.6472 - val_loss: 0.5581 - val_acc: 0.6906\n",
      "Epoch 10/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.5552 - acc: 0.6675 - val_loss: 0.5658 - val_acc: 0.6875\n",
      "Epoch 11/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.5383 - acc: 0.6919 - val_loss: 0.5501 - val_acc: 0.6906\n",
      "Epoch 12/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.5457 - acc: 0.6821 - val_loss: 0.5693 - val_acc: 0.7031\n",
      "Epoch 13/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.5453 - acc: 0.6693 - val_loss: 0.5501 - val_acc: 0.7063\n",
      "Epoch 14/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.5238 - acc: 0.7163 - val_loss: 0.5529 - val_acc: 0.7469\n",
      "Epoch 15/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.5371 - acc: 0.6932 - val_loss: 0.5286 - val_acc: 0.7281\n",
      "Epoch 16/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.5086 - acc: 0.7369 - val_loss: 0.5148 - val_acc: 0.7438\n",
      "Epoch 17/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4983 - acc: 0.7431 - val_loss: 0.5894 - val_acc: 0.7406\n",
      "Epoch 18/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4837 - acc: 0.7567 - val_loss: 0.5558 - val_acc: 0.7531\n",
      "Epoch 19/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4808 - acc: 0.7607 - val_loss: 0.5351 - val_acc: 0.7656\n",
      "Epoch 20/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.4477 - acc: 0.7849 - val_loss: 0.4747 - val_acc: 0.7906\n",
      "Epoch 21/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.4629 - acc: 0.7744 - val_loss: 0.4675 - val_acc: 0.8000\n",
      "Epoch 22/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.4235 - acc: 0.7950 - val_loss: 0.4792 - val_acc: 0.7812\n",
      "Epoch 23/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.4384 - acc: 0.7927 - val_loss: 0.4857 - val_acc: 0.8094\n",
      "Epoch 24/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4116 - acc: 0.8055 - val_loss: 0.4644 - val_acc: 0.8094\n",
      "Epoch 25/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4121 - acc: 0.8011 - val_loss: 0.4459 - val_acc: 0.8313\n",
      "Epoch 26/150\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.4287 - acc: 0.8027 - val_loss: 0.4787 - val_acc: 0.8156\n",
      "Epoch 27/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3928 - acc: 0.8200 - val_loss: 0.3945 - val_acc: 0.8313\n",
      "Epoch 28/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.4068 - acc: 0.8171 - val_loss: 0.4197 - val_acc: 0.8250\n",
      "Epoch 29/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3806 - acc: 0.8284 - val_loss: 0.4333 - val_acc: 0.8281\n",
      "Epoch 30/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.3690 - acc: 0.8316 - val_loss: 0.3899 - val_acc: 0.8438\n",
      "Epoch 31/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3717 - acc: 0.8238 - val_loss: 0.3645 - val_acc: 0.8531\n",
      "Epoch 32/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.3497 - acc: 0.8482 - val_loss: 0.3505 - val_acc: 0.8594\n",
      "Epoch 33/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3544 - acc: 0.8513 - val_loss: 0.4019 - val_acc: 0.8219\n",
      "Epoch 34/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3450 - acc: 0.8460 - val_loss: 0.3744 - val_acc: 0.8375\n",
      "Epoch 35/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3309 - acc: 0.8514 - val_loss: 0.3837 - val_acc: 0.8406\n",
      "Epoch 36/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3352 - acc: 0.8522 - val_loss: 0.3474 - val_acc: 0.8531\n",
      "Epoch 37/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3420 - acc: 0.8340 - val_loss: 0.3313 - val_acc: 0.8562\n",
      "Epoch 38/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2966 - acc: 0.8612 - val_loss: 0.3050 - val_acc: 0.8688\n",
      "Epoch 39/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3148 - acc: 0.8635 - val_loss: 0.3340 - val_acc: 0.8375\n",
      "Epoch 40/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3058 - acc: 0.8620 - val_loss: 0.4194 - val_acc: 0.8187\n",
      "Epoch 41/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3207 - acc: 0.8430 - val_loss: 0.3064 - val_acc: 0.8750\n",
      "Epoch 42/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3054 - acc: 0.8552 - val_loss: 0.3365 - val_acc: 0.8500\n",
      "Epoch 43/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3060 - acc: 0.8613 - val_loss: 0.3162 - val_acc: 0.8531\n",
      "Epoch 44/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.3204 - acc: 0.8566 - val_loss: 0.3037 - val_acc: 0.8750\n",
      "Epoch 45/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2991 - acc: 0.8757 - val_loss: 0.3133 - val_acc: 0.8625\n",
      "Epoch 46/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2740 - acc: 0.8787 - val_loss: 0.3464 - val_acc: 0.8406\n",
      "Epoch 47/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2912 - acc: 0.8629 - val_loss: 0.3586 - val_acc: 0.8250\n",
      "Epoch 48/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3063 - acc: 0.8491 - val_loss: 0.3840 - val_acc: 0.8281\n",
      "Epoch 49/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2781 - acc: 0.8665 - val_loss: 0.3421 - val_acc: 0.8438\n",
      "Epoch 50/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2799 - acc: 0.8704 - val_loss: 0.3131 - val_acc: 0.8656\n",
      "Epoch 51/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2715 - acc: 0.8757 - val_loss: 0.2847 - val_acc: 0.8750\n",
      "Epoch 52/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2965 - acc: 0.8704 - val_loss: 0.3769 - val_acc: 0.8250\n",
      "Epoch 53/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3026 - acc: 0.8582 - val_loss: 0.3083 - val_acc: 0.8688\n",
      "Epoch 54/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2743 - acc: 0.8757 - val_loss: 0.3213 - val_acc: 0.8469\n",
      "Epoch 55/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2861 - acc: 0.8673 - val_loss: 0.2904 - val_acc: 0.8969\n",
      "Epoch 56/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3046 - acc: 0.8568 - val_loss: 0.2832 - val_acc: 0.8844\n",
      "Epoch 57/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2739 - acc: 0.8706 - val_loss: 0.2562 - val_acc: 0.9062\n",
      "Epoch 58/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2581 - acc: 0.8827 - val_loss: 0.2621 - val_acc: 0.9000\n",
      "Epoch 59/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2741 - acc: 0.8742 - val_loss: 0.2717 - val_acc: 0.8969\n",
      "Epoch 60/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2498 - acc: 0.8826 - val_loss: 0.2615 - val_acc: 0.8875\n",
      "Epoch 61/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2608 - acc: 0.8826 - val_loss: 0.3536 - val_acc: 0.8313\n",
      "Epoch 62/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2681 - acc: 0.8726 - val_loss: 0.3157 - val_acc: 0.8625\n",
      "Epoch 63/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2537 - acc: 0.8810 - val_loss: 0.2905 - val_acc: 0.8688\n",
      "Epoch 64/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2666 - acc: 0.8803 - val_loss: 0.3073 - val_acc: 0.8469\n",
      "Epoch 65/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2626 - acc: 0.8766 - val_loss: 0.3654 - val_acc: 0.8375\n",
      "Epoch 66/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2574 - acc: 0.8826 - val_loss: 0.2753 - val_acc: 0.8969\n",
      "Epoch 67/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2484 - acc: 0.8841 - val_loss: 0.3668 - val_acc: 0.8344\n",
      "Epoch 68/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2504 - acc: 0.8857 - val_loss: 0.2490 - val_acc: 0.9031\n",
      "Epoch 69/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2550 - acc: 0.8911 - val_loss: 0.2940 - val_acc: 0.8625\n",
      "Epoch 70/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2434 - acc: 0.8757 - val_loss: 0.3011 - val_acc: 0.8688\n",
      "Epoch 71/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2621 - acc: 0.8804 - val_loss: 0.2662 - val_acc: 0.8875\n",
      "Epoch 72/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2477 - acc: 0.8729 - val_loss: 0.2661 - val_acc: 0.8938\n",
      "Epoch 73/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2501 - acc: 0.8871 - val_loss: 0.2687 - val_acc: 0.8906\n",
      "Epoch 74/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2565 - acc: 0.8887 - val_loss: 0.2757 - val_acc: 0.8781\n",
      "Epoch 75/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2595 - acc: 0.8743 - val_loss: 0.2684 - val_acc: 0.9000\n",
      "Epoch 76/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2398 - acc: 0.8879 - val_loss: 0.3211 - val_acc: 0.8406\n",
      "Epoch 77/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2497 - acc: 0.8819 - val_loss: 0.2866 - val_acc: 0.8844\n",
      "Epoch 78/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2430 - acc: 0.8835 - val_loss: 0.2645 - val_acc: 0.9062\n",
      "Epoch 79/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2277 - acc: 0.8948 - val_loss: 0.2722 - val_acc: 0.8938\n",
      "Epoch 80/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2406 - acc: 0.8826 - val_loss: 0.2640 - val_acc: 0.9000\n",
      "Epoch 81/150\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.2493 - acc: 0.8798 - val_loss: 0.2541 - val_acc: 0.8969\n",
      "Epoch 82/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2535 - acc: 0.8888 - val_loss: 0.3167 - val_acc: 0.8375\n",
      "Epoch 83/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2630 - acc: 0.8735 - val_loss: 0.2535 - val_acc: 0.9031\n",
      "Epoch 84/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2926 - acc: 0.8660 - val_loss: 0.2690 - val_acc: 0.8906\n",
      "Epoch 85/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2439 - acc: 0.8896 - val_loss: 0.2726 - val_acc: 0.8875\n",
      "Epoch 86/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2315 - acc: 0.8978 - val_loss: 0.2812 - val_acc: 0.8719\n",
      "Epoch 87/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2212 - acc: 0.9009 - val_loss: 0.2470 - val_acc: 0.9156\n",
      "Epoch 88/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2274 - acc: 0.8925 - val_loss: 0.2798 - val_acc: 0.8969\n",
      "Epoch 89/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2305 - acc: 0.8927 - val_loss: 0.2542 - val_acc: 0.9031\n",
      "Epoch 90/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2370 - acc: 0.8850 - val_loss: 0.2924 - val_acc: 0.8688\n",
      "Epoch 91/150\n",
      "41/40 [==============================] - 6s 146ms/step - loss: 0.2316 - acc: 0.8902 - val_loss: 0.2511 - val_acc: 0.9094\n",
      "Epoch 92/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2237 - acc: 0.9032 - val_loss: 0.2447 - val_acc: 0.9000\n",
      "Epoch 93/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2191 - acc: 0.8963 - val_loss: 0.2523 - val_acc: 0.9094\n",
      "Epoch 94/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2299 - acc: 0.8986 - val_loss: 0.2497 - val_acc: 0.9156\n",
      "Epoch 95/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2294 - acc: 0.9016 - val_loss: 0.2789 - val_acc: 0.8875\n",
      "Epoch 96/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2438 - acc: 0.8979 - val_loss: 0.2581 - val_acc: 0.8906\n",
      "Epoch 97/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2344 - acc: 0.8896 - val_loss: 0.2502 - val_acc: 0.9000\n",
      "Epoch 98/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2382 - acc: 0.8963 - val_loss: 0.2580 - val_acc: 0.9000\n",
      "Epoch 99/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2135 - acc: 0.9070 - val_loss: 0.2515 - val_acc: 0.9062\n",
      "Epoch 100/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2329 - acc: 0.8949 - val_loss: 0.2702 - val_acc: 0.8969\n",
      "Epoch 101/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2222 - acc: 0.8957 - val_loss: 0.2531 - val_acc: 0.9062\n",
      "Epoch 102/150\n",
      "41/40 [==============================] - 7s 162ms/step - loss: 0.2082 - acc: 0.9123 - val_loss: 0.2516 - val_acc: 0.9062\n",
      "Epoch 103/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2184 - acc: 0.8993 - val_loss: 0.2513 - val_acc: 0.9062\n",
      "Epoch 104/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2330 - acc: 0.8911 - val_loss: 0.2461 - val_acc: 0.9094\n",
      "Epoch 105/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2307 - acc: 0.8911 - val_loss: 0.2803 - val_acc: 0.8875\n",
      "Epoch 106/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2373 - acc: 0.8934 - val_loss: 0.2441 - val_acc: 0.9062\n",
      "Epoch 107/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2142 - acc: 0.9024 - val_loss: 0.2786 - val_acc: 0.8875\n",
      "Epoch 108/150\n",
      "41/40 [==============================] - 6s 144ms/step - loss: 0.2128 - acc: 0.9131 - val_loss: 0.2441 - val_acc: 0.9125\n",
      "Epoch 109/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2058 - acc: 0.9039 - val_loss: 0.2684 - val_acc: 0.8969\n",
      "Epoch 110/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2417 - acc: 0.8896 - val_loss: 0.2506 - val_acc: 0.9156\n",
      "Epoch 111/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2286 - acc: 0.8972 - val_loss: 0.2389 - val_acc: 0.9062\n",
      "Epoch 112/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2116 - acc: 0.9070 - val_loss: 0.2505 - val_acc: 0.9031\n",
      "Epoch 113/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2053 - acc: 0.9094 - val_loss: 0.2549 - val_acc: 0.9000\n",
      "Epoch 114/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2113 - acc: 0.9100 - val_loss: 0.2738 - val_acc: 0.8969\n",
      "Epoch 115/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2244 - acc: 0.9056 - val_loss: 0.2499 - val_acc: 0.8906\n",
      "Epoch 116/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2077 - acc: 0.9100 - val_loss: 0.2463 - val_acc: 0.9094\n",
      "Epoch 117/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2053 - acc: 0.9062 - val_loss: 0.2493 - val_acc: 0.9031\n",
      "Epoch 118/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2477 - acc: 0.8758 - val_loss: 0.2483 - val_acc: 0.9000\n",
      "Epoch 119/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1957 - acc: 0.9109 - val_loss: 0.2492 - val_acc: 0.9094\n",
      "Epoch 120/150\n",
      "41/40 [==============================] - 6s 153ms/step - loss: 0.1991 - acc: 0.9169 - val_loss: 0.2758 - val_acc: 0.8844\n",
      "Epoch 121/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1906 - acc: 0.9146 - val_loss: 0.2513 - val_acc: 0.9125\n",
      "Epoch 122/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.2154 - acc: 0.9047 - val_loss: 0.3550 - val_acc: 0.8156\n",
      "Epoch 123/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2418 - acc: 0.8790 - val_loss: 0.2428 - val_acc: 0.9125\n",
      "Epoch 124/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2130 - acc: 0.8986 - val_loss: 0.2668 - val_acc: 0.8969\n",
      "Epoch 125/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2081 - acc: 0.9047 - val_loss: 0.2664 - val_acc: 0.9000\n",
      "Epoch 126/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2160 - acc: 0.9108 - val_loss: 0.2744 - val_acc: 0.8938\n",
      "Epoch 127/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1969 - acc: 0.9207 - val_loss: 0.2564 - val_acc: 0.9031\n",
      "Epoch 128/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2103 - acc: 0.9108 - val_loss: 0.2568 - val_acc: 0.9062\n",
      "Epoch 129/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2102 - acc: 0.9065 - val_loss: 0.2653 - val_acc: 0.8812\n",
      "Epoch 130/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2069 - acc: 0.9176 - val_loss: 0.2517 - val_acc: 0.9094\n",
      "Epoch 131/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2041 - acc: 0.9108 - val_loss: 0.2525 - val_acc: 0.8969\n",
      "Epoch 132/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2012 - acc: 0.9184 - val_loss: 0.2613 - val_acc: 0.9000\n",
      "Epoch 133/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2373 - acc: 0.9034 - val_loss: 0.2472 - val_acc: 0.9062\n",
      "Epoch 134/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2138 - acc: 0.9040 - val_loss: 0.2471 - val_acc: 0.8969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1856 - acc: 0.9138 - val_loss: 0.2599 - val_acc: 0.9094\n",
      "Epoch 136/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2071 - acc: 0.9093 - val_loss: 0.2464 - val_acc: 0.9125\n",
      "Epoch 137/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1799 - acc: 0.9169 - val_loss: 0.2719 - val_acc: 0.9094\n",
      "Epoch 138/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2072 - acc: 0.9079 - val_loss: 0.2557 - val_acc: 0.8969\n",
      "Epoch 139/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1964 - acc: 0.9154 - val_loss: 0.2435 - val_acc: 0.9219\n",
      "Epoch 140/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.1929 - acc: 0.9185 - val_loss: 0.2616 - val_acc: 0.9031\n",
      "Epoch 141/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1929 - acc: 0.9223 - val_loss: 0.2579 - val_acc: 0.9125\n",
      "Epoch 142/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1984 - acc: 0.9146 - val_loss: 0.2552 - val_acc: 0.9125\n",
      "Epoch 143/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1917 - acc: 0.9230 - val_loss: 0.2472 - val_acc: 0.9187\n",
      "Epoch 144/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1836 - acc: 0.9169 - val_loss: 0.2551 - val_acc: 0.9156\n",
      "Epoch 145/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1799 - acc: 0.9176 - val_loss: 0.2956 - val_acc: 0.8844\n",
      "Epoch 146/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.1967 - acc: 0.9176 - val_loss: 0.2566 - val_acc: 0.9094\n",
      "Epoch 147/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1993 - acc: 0.9154 - val_loss: 0.2618 - val_acc: 0.8906\n",
      "Epoch 148/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1915 - acc: 0.9207 - val_loss: 0.2805 - val_acc: 0.8781\n",
      "Epoch 149/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2101 - acc: 0.9079 - val_loss: 0.2460 - val_acc: 0.9062\n",
      "Epoch 150/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1826 - acc: 0.9192 - val_loss: 0.2412 - val_acc: 0.9187\n",
      "320/320 [==============================] - 0s 1ms/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 75, 75, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 71, 71, 64)        4864      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 71, 71, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_85 (Dropout)         (None, 35, 35, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 33, 33, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 33, 33, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_86 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 5, 5, 64)          73792     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 1)                 129       \n",
      "_________________________________________________________________\n",
      "dropout_91 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 398,913\n",
      "Trainable params: 398,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/150\n",
      "41/40 [==============================] - 11s 257ms/step - loss: 1.2338 - acc: 0.4864 - val_loss: 0.6780 - val_acc: 0.6312\n",
      "Epoch 2/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.7569 - acc: 0.5221 - val_loss: 0.6837 - val_acc: 0.5531\n",
      "Epoch 3/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.7117 - acc: 0.5447 - val_loss: 0.6689 - val_acc: 0.6687\n",
      "Epoch 4/150\n",
      "41/40 [==============================] - 6s 142ms/step - loss: 0.6755 - acc: 0.5670 - val_loss: 0.6210 - val_acc: 0.5312\n",
      "Epoch 5/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.6418 - acc: 0.5953 - val_loss: 0.5898 - val_acc: 0.6656\n",
      "Epoch 6/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.5822 - acc: 0.6396 - val_loss: 0.5620 - val_acc: 0.6844\n",
      "Epoch 7/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.5832 - acc: 0.6309 - val_loss: 0.5540 - val_acc: 0.6906\n",
      "Epoch 8/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.5544 - acc: 0.6776 - val_loss: 0.5464 - val_acc: 0.6937\n",
      "Epoch 9/150\n",
      "41/40 [==============================] - 6s 145ms/step - loss: 0.5484 - acc: 0.6881 - val_loss: 0.5386 - val_acc: 0.6969\n",
      "Epoch 10/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.5279 - acc: 0.7079 - val_loss: 0.5273 - val_acc: 0.7125\n",
      "Epoch 11/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.5311 - acc: 0.7049 - val_loss: 0.5095 - val_acc: 0.7312\n",
      "Epoch 12/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.5341 - acc: 0.7083 - val_loss: 0.5169 - val_acc: 0.7312\n",
      "Epoch 13/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.5135 - acc: 0.7334 - val_loss: 0.4904 - val_acc: 0.7688\n",
      "Epoch 14/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4709 - acc: 0.7674 - val_loss: 0.4586 - val_acc: 0.7844\n",
      "Epoch 15/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4771 - acc: 0.7529 - val_loss: 0.4529 - val_acc: 0.7937\n",
      "Epoch 16/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4534 - acc: 0.7736 - val_loss: 0.4178 - val_acc: 0.8187\n",
      "Epoch 17/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.4360 - acc: 0.7898 - val_loss: 0.4572 - val_acc: 0.7594\n",
      "Epoch 18/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4206 - acc: 0.8019 - val_loss: 0.3826 - val_acc: 0.8313\n",
      "Epoch 19/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.4310 - acc: 0.8048 - val_loss: 0.3894 - val_acc: 0.8375\n",
      "Epoch 20/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.4209 - acc: 0.7994 - val_loss: 0.3892 - val_acc: 0.8313\n",
      "Epoch 21/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.4183 - acc: 0.8095 - val_loss: 0.3696 - val_acc: 0.8406\n",
      "Epoch 22/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.4050 - acc: 0.8132 - val_loss: 0.3770 - val_acc: 0.8250\n",
      "Epoch 23/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.4368 - acc: 0.7950 - val_loss: 0.3648 - val_acc: 0.8406\n",
      "Epoch 24/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.4096 - acc: 0.8033 - val_loss: 0.3695 - val_acc: 0.8375\n",
      "Epoch 25/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3980 - acc: 0.8141 - val_loss: 0.3505 - val_acc: 0.8500\n",
      "Epoch 26/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3882 - acc: 0.8293 - val_loss: 0.3364 - val_acc: 0.8500\n",
      "Epoch 27/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3961 - acc: 0.8180 - val_loss: 0.3474 - val_acc: 0.8531\n",
      "Epoch 28/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3630 - acc: 0.8360 - val_loss: 0.3250 - val_acc: 0.8500\n",
      "Epoch 29/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3495 - acc: 0.8444 - val_loss: 0.4045 - val_acc: 0.7937\n",
      "Epoch 30/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3859 - acc: 0.8127 - val_loss: 0.3304 - val_acc: 0.8438\n",
      "Epoch 31/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.3494 - acc: 0.8383 - val_loss: 0.3790 - val_acc: 0.8000\n",
      "Epoch 32/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3582 - acc: 0.8269 - val_loss: 0.3136 - val_acc: 0.8406\n",
      "Epoch 33/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.3496 - acc: 0.8316 - val_loss: 0.3120 - val_acc: 0.8344\n",
      "Epoch 34/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3617 - acc: 0.8195 - val_loss: 0.2899 - val_acc: 0.8750\n",
      "Epoch 35/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3652 - acc: 0.8272 - val_loss: 0.2959 - val_acc: 0.8750\n",
      "Epoch 36/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3478 - acc: 0.8346 - val_loss: 0.2947 - val_acc: 0.8656\n",
      "Epoch 37/150\n",
      "41/40 [==============================] - 6s 147ms/step - loss: 0.3156 - acc: 0.8575 - val_loss: 0.2800 - val_acc: 0.8812\n",
      "Epoch 38/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3221 - acc: 0.8437 - val_loss: 0.2668 - val_acc: 0.8906\n",
      "Epoch 39/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.3008 - acc: 0.8597 - val_loss: 0.2563 - val_acc: 0.8938\n",
      "Epoch 40/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.3785 - acc: 0.8087 - val_loss: 0.3438 - val_acc: 0.8562\n",
      "Epoch 41/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3264 - acc: 0.8421 - val_loss: 0.2763 - val_acc: 0.8625\n",
      "Epoch 42/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.3133 - acc: 0.8582 - val_loss: 0.2578 - val_acc: 0.8875\n",
      "Epoch 43/150\n",
      "41/40 [==============================] - 6s 139ms/step - loss: 0.3114 - acc: 0.8629 - val_loss: 0.2691 - val_acc: 0.8656\n",
      "Epoch 44/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3083 - acc: 0.8629 - val_loss: 0.2745 - val_acc: 0.8812\n",
      "Epoch 45/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.3384 - acc: 0.8400 - val_loss: 0.2941 - val_acc: 0.8656\n",
      "Epoch 46/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3339 - acc: 0.8484 - val_loss: 0.2640 - val_acc: 0.8938\n",
      "Epoch 47/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.3198 - acc: 0.8574 - val_loss: 0.2800 - val_acc: 0.8625\n",
      "Epoch 48/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3191 - acc: 0.8441 - val_loss: 0.2618 - val_acc: 0.8750\n",
      "Epoch 49/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2971 - acc: 0.8598 - val_loss: 0.2820 - val_acc: 0.8531\n",
      "Epoch 50/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.3058 - acc: 0.8516 - val_loss: 0.2887 - val_acc: 0.8625\n",
      "Epoch 51/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2975 - acc: 0.8665 - val_loss: 0.2642 - val_acc: 0.9000\n",
      "Epoch 52/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2867 - acc: 0.8582 - val_loss: 0.2582 - val_acc: 0.8875\n",
      "Epoch 53/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2903 - acc: 0.8726 - val_loss: 0.2592 - val_acc: 0.8812\n",
      "Epoch 54/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2827 - acc: 0.8765 - val_loss: 0.2742 - val_acc: 0.8688\n",
      "Epoch 55/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2796 - acc: 0.8667 - val_loss: 0.2538 - val_acc: 0.8750\n",
      "Epoch 56/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2867 - acc: 0.8552 - val_loss: 0.2597 - val_acc: 0.9031\n",
      "Epoch 57/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.3034 - acc: 0.8552 - val_loss: 0.2663 - val_acc: 0.8719\n",
      "Epoch 58/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2861 - acc: 0.8643 - val_loss: 0.3383 - val_acc: 0.8000\n",
      "Epoch 59/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2864 - acc: 0.8681 - val_loss: 0.2470 - val_acc: 0.8938\n",
      "Epoch 60/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2632 - acc: 0.8704 - val_loss: 0.2428 - val_acc: 0.8875\n",
      "Epoch 61/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2587 - acc: 0.8781 - val_loss: 0.2743 - val_acc: 0.8750\n",
      "Epoch 62/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2449 - acc: 0.8879 - val_loss: 0.2456 - val_acc: 0.8719\n",
      "Epoch 63/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2837 - acc: 0.8682 - val_loss: 0.2439 - val_acc: 0.8812\n",
      "Epoch 64/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2900 - acc: 0.8688 - val_loss: 0.2758 - val_acc: 0.8688\n",
      "Epoch 65/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2768 - acc: 0.8818 - val_loss: 0.2628 - val_acc: 0.9062\n",
      "Epoch 66/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2898 - acc: 0.8598 - val_loss: 0.2663 - val_acc: 0.9000\n",
      "Epoch 67/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2463 - acc: 0.8835 - val_loss: 0.2579 - val_acc: 0.9000\n",
      "Epoch 68/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2503 - acc: 0.8826 - val_loss: 0.2912 - val_acc: 0.8469\n",
      "Epoch 69/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2512 - acc: 0.8818 - val_loss: 0.2542 - val_acc: 0.8844\n",
      "Epoch 70/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2532 - acc: 0.8835 - val_loss: 0.2638 - val_acc: 0.9000\n",
      "Epoch 71/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2656 - acc: 0.8818 - val_loss: 0.2707 - val_acc: 0.8938\n",
      "Epoch 72/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2465 - acc: 0.8774 - val_loss: 0.2533 - val_acc: 0.8969\n",
      "Epoch 73/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2417 - acc: 0.8841 - val_loss: 0.2634 - val_acc: 0.8938\n",
      "Epoch 74/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2617 - acc: 0.8934 - val_loss: 0.2623 - val_acc: 0.8969\n",
      "Epoch 75/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2677 - acc: 0.8850 - val_loss: 0.2612 - val_acc: 0.8844\n",
      "Epoch 76/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2569 - acc: 0.8826 - val_loss: 0.2535 - val_acc: 0.8781\n",
      "Epoch 77/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2333 - acc: 0.8963 - val_loss: 0.2633 - val_acc: 0.9000\n",
      "Epoch 78/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2335 - acc: 0.9009 - val_loss: 0.2513 - val_acc: 0.8906\n",
      "Epoch 79/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2414 - acc: 0.8932 - val_loss: 0.2641 - val_acc: 0.8938\n",
      "Epoch 80/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2498 - acc: 0.8902 - val_loss: 0.2525 - val_acc: 0.9094\n",
      "Epoch 81/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2336 - acc: 0.8909 - val_loss: 0.2493 - val_acc: 0.8750\n",
      "Epoch 82/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.2573 - acc: 0.8857 - val_loss: 0.2447 - val_acc: 0.8844\n",
      "Epoch 83/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2487 - acc: 0.8879 - val_loss: 0.2378 - val_acc: 0.9219\n",
      "Epoch 84/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2358 - acc: 0.8948 - val_loss: 0.2495 - val_acc: 0.9156\n",
      "Epoch 85/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2404 - acc: 0.8909 - val_loss: 0.2689 - val_acc: 0.8906\n",
      "Epoch 86/150\n",
      "41/40 [==============================] - 6s 143ms/step - loss: 0.2343 - acc: 0.8971 - val_loss: 0.2404 - val_acc: 0.9156\n",
      "Epoch 87/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2300 - acc: 0.8971 - val_loss: 0.2508 - val_acc: 0.9187\n",
      "Epoch 88/150\n",
      "41/40 [==============================] - 5s 130ms/step - loss: 0.2239 - acc: 0.8940 - val_loss: 0.3149 - val_acc: 0.8781\n",
      "Epoch 89/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2542 - acc: 0.8781 - val_loss: 0.2558 - val_acc: 0.8656\n",
      "Epoch 90/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2364 - acc: 0.9009 - val_loss: 0.2576 - val_acc: 0.9094\n",
      "Epoch 91/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2169 - acc: 0.9062 - val_loss: 0.2704 - val_acc: 0.9031\n",
      "Epoch 92/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2324 - acc: 0.8887 - val_loss: 0.2502 - val_acc: 0.9219\n",
      "Epoch 93/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2091 - acc: 0.9047 - val_loss: 0.2505 - val_acc: 0.9031\n",
      "Epoch 94/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2136 - acc: 0.9077 - val_loss: 0.2566 - val_acc: 0.8906\n",
      "Epoch 95/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2359 - acc: 0.8917 - val_loss: 0.2522 - val_acc: 0.9000\n",
      "Epoch 96/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2735 - acc: 0.8735 - val_loss: 0.2633 - val_acc: 0.8562\n",
      "Epoch 97/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.2471 - acc: 0.8819 - val_loss: 0.2606 - val_acc: 0.8656\n",
      "Epoch 98/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2364 - acc: 0.8925 - val_loss: 0.2623 - val_acc: 0.9000\n",
      "Epoch 99/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2526 - acc: 0.8857 - val_loss: 0.2364 - val_acc: 0.9156\n",
      "Epoch 100/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2222 - acc: 0.9024 - val_loss: 0.2506 - val_acc: 0.8781\n",
      "Epoch 101/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2377 - acc: 0.8964 - val_loss: 0.2447 - val_acc: 0.8938\n",
      "Epoch 102/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2155 - acc: 0.9009 - val_loss: 0.2681 - val_acc: 0.9062\n",
      "Epoch 103/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2190 - acc: 0.8995 - val_loss: 0.2683 - val_acc: 0.8812\n",
      "Epoch 104/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2215 - acc: 0.9070 - val_loss: 0.2443 - val_acc: 0.8875\n",
      "Epoch 105/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2181 - acc: 0.9024 - val_loss: 0.2410 - val_acc: 0.8812\n",
      "Epoch 106/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2348 - acc: 0.9039 - val_loss: 0.2393 - val_acc: 0.8875\n",
      "Epoch 107/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2273 - acc: 0.9123 - val_loss: 0.2348 - val_acc: 0.9156\n",
      "Epoch 108/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2236 - acc: 0.9039 - val_loss: 0.2330 - val_acc: 0.9187\n",
      "Epoch 109/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2227 - acc: 0.8972 - val_loss: 0.2643 - val_acc: 0.8594\n",
      "Epoch 110/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2282 - acc: 0.8917 - val_loss: 0.2482 - val_acc: 0.9094\n",
      "Epoch 111/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2137 - acc: 0.9146 - val_loss: 0.2416 - val_acc: 0.9156\n",
      "Epoch 112/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2051 - acc: 0.9047 - val_loss: 0.2522 - val_acc: 0.9344\n",
      "Epoch 113/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2438 - acc: 0.8888 - val_loss: 0.2446 - val_acc: 0.9219\n",
      "Epoch 114/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2478 - acc: 0.8813 - val_loss: 0.2499 - val_acc: 0.8781\n",
      "Epoch 115/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2228 - acc: 0.8978 - val_loss: 0.2369 - val_acc: 0.9125\n",
      "Epoch 116/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1995 - acc: 0.8979 - val_loss: 0.2414 - val_acc: 0.9000\n",
      "Epoch 117/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2039 - acc: 0.9009 - val_loss: 0.2364 - val_acc: 0.9031\n",
      "Epoch 118/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2039 - acc: 0.9138 - val_loss: 0.2376 - val_acc: 0.9094\n",
      "Epoch 119/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2032 - acc: 0.9123 - val_loss: 0.2508 - val_acc: 0.8844\n",
      "Epoch 120/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2072 - acc: 0.9077 - val_loss: 0.2593 - val_acc: 0.8906\n",
      "Epoch 121/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2079 - acc: 0.9032 - val_loss: 0.2397 - val_acc: 0.9187\n",
      "Epoch 122/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.1933 - acc: 0.9154 - val_loss: 0.2317 - val_acc: 0.9219\n",
      "Epoch 123/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.2106 - acc: 0.9071 - val_loss: 0.2606 - val_acc: 0.9156\n",
      "Epoch 124/150\n",
      "41/40 [==============================] - 6s 140ms/step - loss: 0.2048 - acc: 0.9070 - val_loss: 0.2395 - val_acc: 0.9187\n",
      "Epoch 125/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2052 - acc: 0.9071 - val_loss: 0.2437 - val_acc: 0.9187\n",
      "Epoch 126/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2110 - acc: 0.9070 - val_loss: 0.2763 - val_acc: 0.9125\n",
      "Epoch 127/150\n",
      "41/40 [==============================] - 6s 137ms/step - loss: 0.2025 - acc: 0.9100 - val_loss: 0.2449 - val_acc: 0.9250\n",
      "Epoch 128/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2069 - acc: 0.9085 - val_loss: 0.2414 - val_acc: 0.9000\n",
      "Epoch 129/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1889 - acc: 0.9138 - val_loss: 0.2425 - val_acc: 0.9062\n",
      "Epoch 130/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.2030 - acc: 0.9054 - val_loss: 0.2409 - val_acc: 0.9094\n",
      "Epoch 131/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2276 - acc: 0.8903 - val_loss: 0.2589 - val_acc: 0.9156\n",
      "Epoch 132/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.2038 - acc: 0.9079 - val_loss: 0.3509 - val_acc: 0.8875\n",
      "Epoch 133/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.2067 - acc: 0.9062 - val_loss: 0.2369 - val_acc: 0.9250\n",
      "Epoch 134/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1959 - acc: 0.9146 - val_loss: 0.2468 - val_acc: 0.8812\n",
      "Epoch 135/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.2071 - acc: 0.9002 - val_loss: 0.2374 - val_acc: 0.9219\n",
      "Epoch 136/150\n",
      "41/40 [==============================] - 5s 134ms/step - loss: 0.1898 - acc: 0.9154 - val_loss: 0.2350 - val_acc: 0.8969\n",
      "Epoch 137/150\n",
      "41/40 [==============================] - 6s 138ms/step - loss: 0.1880 - acc: 0.9199 - val_loss: 0.2480 - val_acc: 0.9094\n",
      "Epoch 138/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1930 - acc: 0.9123 - val_loss: 0.2493 - val_acc: 0.9125\n",
      "Epoch 139/150\n",
      "41/40 [==============================] - 6s 136ms/step - loss: 0.1869 - acc: 0.9169 - val_loss: 0.2462 - val_acc: 0.9156\n",
      "Epoch 140/150\n",
      "41/40 [==============================] - 6s 134ms/step - loss: 0.1867 - acc: 0.9192 - val_loss: 0.2974 - val_acc: 0.8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1866 - acc: 0.9253 - val_loss: 0.2446 - val_acc: 0.9281\n",
      "Epoch 142/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.2039 - acc: 0.9054 - val_loss: 0.2434 - val_acc: 0.8844\n",
      "Epoch 143/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1664 - acc: 0.9268 - val_loss: 0.2475 - val_acc: 0.9156\n",
      "Epoch 144/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1843 - acc: 0.9077 - val_loss: 0.2761 - val_acc: 0.9187\n",
      "Epoch 145/150\n",
      "41/40 [==============================] - 6s 135ms/step - loss: 0.1880 - acc: 0.9086 - val_loss: 0.2392 - val_acc: 0.8844\n",
      "Epoch 146/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.1811 - acc: 0.9176 - val_loss: 0.2517 - val_acc: 0.9062\n",
      "Epoch 147/150\n",
      "41/40 [==============================] - 5s 132ms/step - loss: 0.1899 - acc: 0.9215 - val_loss: 0.2373 - val_acc: 0.9062\n",
      "Epoch 148/150\n",
      "41/40 [==============================] - 5s 131ms/step - loss: 0.2100 - acc: 0.9108 - val_loss: 0.2356 - val_acc: 0.8969\n",
      "Epoch 149/150\n",
      "41/40 [==============================] - 6s 141ms/step - loss: 0.1979 - acc: 0.9146 - val_loss: 0.2211 - val_acc: 0.9094\n",
      "Epoch 150/150\n",
      "41/40 [==============================] - 5s 133ms/step - loss: 0.1932 - acc: 0.9154 - val_loss: 0.2378 - val_acc: 0.9094\n",
      "320/320 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "Train_cv = StratifiedKFold(n_splits=5,shuffle = True,random_state=4).split(X_train,target_train)\n",
    "cv_val_list = []\n",
    "for i,masks in enumerate(Train_cv):\n",
    "    train_mask,valid_mask = masks\n",
    "    X_train_cv = X_train[train_mask]\n",
    "    y_train_cv = target_train[train_mask]\n",
    "    X_valid = X_train[valid_mask]\n",
    "    y_valid = target_train[valid_mask]\n",
    "    path = 'model save/Model 1-Advanced CNN with DA and CV5/'\n",
    "    modelseries = '.cv'+str(i+1)+'.hdf5'\n",
    "    modelpath = os.path.join(path,modelseries)\n",
    "    Cnnmodel=cnnmodel(input_shape = (75,75,3),lr = 0.0001)\n",
    "    result_Cnn = fitmodel(Cnnmodel,X_train_cv,y_train_cv,X_valid,y_valid,augment = True,epochs = 150,batch_size = 32,filepath = modelpath)\n",
    "    historyseries = 'cv'+str(i+1)+'.csv'\n",
    "    save_history(result_Cnn,name = historyseries,path = path)\n",
    "    Cnnmodel.load_weights(filepath=modelpath)\n",
    "    score = Cnnmodel.evaluate(X_valid, y_valid, verbose=1)\n",
    "    cv_val_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.22919706774728013, 0.92236024844720499],\n",
       " [0.20885347976491458, 0.88473520249221183],\n",
       " [0.22079534935431316, 0.91277258566978192],\n",
       " [0.2388879343867302, 0.90625],\n",
       " [0.22113464772701263, 0.90937500000000004]]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_val_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'prediction/model1+two 0.17/'\n",
    "model_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame()\n",
    "prediction['id']=test['id']\n",
    "for name in model_list:\n",
    "    Cnnmodel.load_weights(os.path.join(path,name))\n",
    "    pred = Cnnmodel.predict(X_test)\n",
    "    prediction[name] = np.squeeze(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['is_iceberg'] = np.where(np.all(prediction[prediction.columns[1:]]>0.9,axis = 1),\n",
    "                                    np.max(prediction[prediction.columns[1:]],axis = 1),\n",
    "                                     np.where(np.all(prediction[prediction.columns[1:]]<0.1,axis = 1),np.min(prediction[prediction.columns[1:]],axis = 1),np.median(prediction[prediction.columns[1:]],axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = prediction.drop(prediction.columns[1:-1],axis = 1)\n",
    "prediction.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'prediction/model1+two 0.17/'\n",
    "model_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = pd.DataFrame()\n",
    "ins['id']=train['id']\n",
    "ins['true'] = train['is_iceberg']\n",
    "for name in model_list:\n",
    "    Cnnmodel.load_weights(os.path.join(path,name))\n",
    "    pred = Cnnmodel.predict(X_train)\n",
    "    ins[name] = np.squeeze(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins['gap'] = np.max(ins[ins.columns[2:]],axis = 1)-np.min(ins[ins.columns[2:]],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(((ins['gap']>0.2)*1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2        True\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7        True\n",
       "8       False\n",
       "9       False\n",
       "10       True\n",
       "11      False\n",
       "12       True\n",
       "13       True\n",
       "14      False\n",
       "15      False\n",
       "16       True\n",
       "17      False\n",
       "18       True\n",
       "19       True\n",
       "20      False\n",
       "21       True\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26       True\n",
       "27      False\n",
       "28       True\n",
       "29      False\n",
       "        ...  \n",
       "1574     True\n",
       "1575    False\n",
       "1576    False\n",
       "1577    False\n",
       "1578    False\n",
       "1579     True\n",
       "1580    False\n",
       "1581     True\n",
       "1582     True\n",
       "1583     True\n",
       "1584    False\n",
       "1585    False\n",
       "1586     True\n",
       "1587    False\n",
       "1588    False\n",
       "1589    False\n",
       "1590    False\n",
       "1591     True\n",
       "1592    False\n",
       "1593     True\n",
       "1594    False\n",
       "1595    False\n",
       "1596    False\n",
       "1597    False\n",
       "1598    False\n",
       "1599    False\n",
       "1600    False\n",
       "1601     True\n",
       "1602     True\n",
       "1603     True\n",
       "Name: gap, Length: 1604, dtype: bool"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ins['gap']<0.2) and (np.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.all(((ins[ins.columns[2:-1]]<0.5) & (ins[ins.columns[2:-1]]>0.1)),axis = 1)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4273"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.all(prediction[prediction.columns[1:]]<0.2,axis = 1)*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
